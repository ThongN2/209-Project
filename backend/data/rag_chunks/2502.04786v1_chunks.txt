.

JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 1
Enhancing SQL Injection Detection and Prevention
Using Generative Models
Naga Sai Dasari
Dept.of Computer Science,
University of Reading, UK
nagasai.dasari@reading.ac.ukAtta Badii
Dept.of Computer Science,
University of Reading, UK
atta.badii@reading.ac.ukArmin Moin
Dept.of Computer Science,
University of Colorado
Colorodo Springs,CO, USA
amoin@uccs.eduAhmed Ashlam
Dept.of Computer Science,
University of Reading, UK
a.ashlam@pgr.reading.ac.uk
Abstract —SQL Injection (SQLi) continues to pose a significant
threat to the security of web applications, enabling attackers
to manipulate databases and access sensitive information with-
out authorisation.

JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 1
Enhancing SQL Injection Detection and Prevention
Using Generative Models
Naga Sai Dasari
Dept.of Computer Science,
University of Reading, UK
nagasai.dasari@reading.ac.ukAtta Badii
Dept.of Computer Science,
University of Reading, UK
atta.badii@reading.ac.ukArmin Moin
Dept.of Computer Science,
University of Colorado
Colorodo Springs,CO, USA
amoin@uccs.eduAhmed Ashlam
Dept.of Computer Science,
University of Reading, UK
a.ashlam@pgr.reading.ac.uk
Abstract —SQL Injection (SQLi) continues to pose a significant
threat to the security of web applications, enabling attackers
to manipulate databases and access sensitive information with-
out authorisation. Although advancements have been made in
detection techniques, traditional signature-based methods still
struggle to identify sophisticated SQL injection attacks that
evade predefined patterns.

JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 1
Enhancing SQL Injection Detection and Prevention
Using Generative Models
Naga Sai Dasari
Dept.of Computer Science,
University of Reading, UK
nagasai.dasari@reading.ac.ukAtta Badii
Dept.of Computer Science,
University of Reading, UK
atta.badii@reading.ac.ukArmin Moin
Dept.of Computer Science,
University of Colorado
Colorodo Springs,CO, USA
amoin@uccs.eduAhmed Ashlam
Dept.of Computer Science,
University of Reading, UK
a.ashlam@pgr.reading.ac.uk
Abstract —SQL Injection (SQLi) continues to pose a significant
threat to the security of web applications, enabling attackers
to manipulate databases and access sensitive information with-
out authorisation. Although advancements have been made in
detection techniques, traditional signature-based methods still
struggle to identify sophisticated SQL injection attacks that
evade predefined patterns. As SQLi attacks evolve, the need for
more adaptive detection systems becomes crucial.

JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 1
Enhancing SQL Injection Detection and Prevention
Using Generative Models
Naga Sai Dasari
Dept.of Computer Science,
University of Reading, UK
nagasai.dasari@reading.ac.ukAtta Badii
Dept.of Computer Science,
University of Reading, UK
atta.badii@reading.ac.ukArmin Moin
Dept.of Computer Science,
University of Colorado
Colorodo Springs,CO, USA
amoin@uccs.eduAhmed Ashlam
Dept.of Computer Science,
University of Reading, UK
a.ashlam@pgr.reading.ac.uk
Abstract —SQL Injection (SQLi) continues to pose a significant
threat to the security of web applications, enabling attackers
to manipulate databases and access sensitive information with-
out authorisation. Although advancements have been made in
detection techniques, traditional signature-based methods still
struggle to identify sophisticated SQL injection attacks that
evade predefined patterns. As SQLi attacks evolve, the need for
more adaptive detection systems becomes crucial. This paper
introduces an innovative approach that leverages generative
models to enhance SQLi detection and prevention mechanisms.
By incorporating Variational Autoencoders (V AE), Conditional
Wasserstein GAN with Gradient Penalty (CWGAN-GP), and U-
Net, synthetic SQL queries were generated to augment training
datasets for machine learning models.

JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 1
Enhancing SQL Injection Detection and Prevention
Using Generative Models
Naga Sai Dasari
Dept.of Computer Science,
University of Reading, UK
nagasai.dasari@reading.ac.ukAtta Badii
Dept.of Computer Science,
University of Reading, UK
atta.badii@reading.ac.ukArmin Moin
Dept.of Computer Science,
University of Colorado
Colorodo Springs,CO, USA
amoin@uccs.eduAhmed Ashlam
Dept.of Computer Science,
University of Reading, UK
a.ashlam@pgr.reading.ac.uk
Abstract —SQL Injection (SQLi) continues to pose a significant
threat to the security of web applications, enabling attackers
to manipulate databases and access sensitive information with-
out authorisation. Although advancements have been made in
detection techniques, traditional signature-based methods still
struggle to identify sophisticated SQL injection attacks that
evade predefined patterns. As SQLi attacks evolve, the need for
more adaptive detection systems becomes crucial. This paper
introduces an innovative approach that leverages generative
models to enhance SQLi detection and prevention mechanisms.
By incorporating Variational Autoencoders (V AE), Conditional
Wasserstein GAN with Gradient Penalty (CWGAN-GP), and U-
Net, synthetic SQL queries were generated to augment training
datasets for machine learning models. The proposed method
demonstrated improved accuracy in SQLi detection systems
by reducing both false positives and false negatives.

JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 1
Enhancing SQL Injection Detection and Prevention
Using Generative Models
Naga Sai Dasari
Dept.of Computer Science,
University of Reading, UK
nagasai.dasari@reading.ac.ukAtta Badii
Dept.of Computer Science,
University of Reading, UK
atta.badii@reading.ac.ukArmin Moin
Dept.of Computer Science,
University of Colorado
Colorodo Springs,CO, USA
amoin@uccs.eduAhmed Ashlam
Dept.of Computer Science,
University of Reading, UK
a.ashlam@pgr.reading.ac.uk
Abstract —SQL Injection (SQLi) continues to pose a significant
threat to the security of web applications, enabling attackers
to manipulate databases and access sensitive information with-
out authorisation. Although advancements have been made in
detection techniques, traditional signature-based methods still
struggle to identify sophisticated SQL injection attacks that
evade predefined patterns. As SQLi attacks evolve, the need for
more adaptive detection systems becomes crucial. This paper
introduces an innovative approach that leverages generative
models to enhance SQLi detection and prevention mechanisms.
By incorporating Variational Autoencoders (V AE), Conditional
Wasserstein GAN with Gradient Penalty (CWGAN-GP), and U-
Net, synthetic SQL queries were generated to augment training
datasets for machine learning models. The proposed method
demonstrated improved accuracy in SQLi detection systems
by reducing both false positives and false negatives. Extensive
empirical testing further illustrated the ability of the system to
adapt to evolving SQLi attack patterns, resulting in enhanced
precision and robustness.
Index Terms —SQL Injection, Machine Learning, Generative
Models, Variational Autoencoder (V AE), U-Net, CWGAN-GP,
Data Augmentation, Cybersecurity.
I.INTRODUCTION
SQL Injection (SQLi) remains one of the most critical
security vulnerabilities affecting web applications today.

Although advancements have been made in
detection techniques, traditional signature-based methods still
struggle to identify sophisticated SQL injection attacks that
evade predefined patterns. As SQLi attacks evolve, the need for
more adaptive detection systems becomes crucial. This paper
introduces an innovative approach that leverages generative
models to enhance SQLi detection and prevention mechanisms.
By incorporating Variational Autoencoders (V AE), Conditional
Wasserstein GAN with Gradient Penalty (CWGAN-GP), and U-
Net, synthetic SQL queries were generated to augment training
datasets for machine learning models. The proposed method
demonstrated improved accuracy in SQLi detection systems
by reducing both false positives and false negatives. Extensive
empirical testing further illustrated the ability of the system to
adapt to evolving SQLi attack patterns, resulting in enhanced
precision and robustness.
Index Terms —SQL Injection, Machine Learning, Generative
Models, Variational Autoencoder (V AE), U-Net, CWGAN-GP,
Data Augmentation, Cybersecurity.
I.INTRODUCTION
SQL Injection (SQLi) remains one of the most critical
security vulnerabilities affecting web applications today. As
cyber threats evolve, attackers continuously exploit input han-
dling weaknesses, injecting malicious SQL commands into
legitimate queries.

As SQLi attacks evolve, the need for
more adaptive detection systems becomes crucial. This paper
introduces an innovative approach that leverages generative
models to enhance SQLi detection and prevention mechanisms.
By incorporating Variational Autoencoders (V AE), Conditional
Wasserstein GAN with Gradient Penalty (CWGAN-GP), and U-
Net, synthetic SQL queries were generated to augment training
datasets for machine learning models. The proposed method
demonstrated improved accuracy in SQLi detection systems
by reducing both false positives and false negatives. Extensive
empirical testing further illustrated the ability of the system to
adapt to evolving SQLi attack patterns, resulting in enhanced
precision and robustness.
Index Terms —SQL Injection, Machine Learning, Generative
Models, Variational Autoencoder (V AE), U-Net, CWGAN-GP,
Data Augmentation, Cybersecurity.
I.INTRODUCTION
SQL Injection (SQLi) remains one of the most critical
security vulnerabilities affecting web applications today. As
cyber threats evolve, attackers continuously exploit input han-
dling weaknesses, injecting malicious SQL commands into
legitimate queries. These attacks, often launched through input
fields such as login forms or URL parameters, enable unau-
thorised access to sensitive data or, in severe cases, complete
control over the database.
The Open Web Application Security Project (OWASP) con-
tinues to rank SQLi among the top security risks, reinforcing
its prevalence and severity in the landscape of web vulnerabil-
ities [1].

This paper
introduces an innovative approach that leverages generative
models to enhance SQLi detection and prevention mechanisms.
By incorporating Variational Autoencoders (V AE), Conditional
Wasserstein GAN with Gradient Penalty (CWGAN-GP), and U-
Net, synthetic SQL queries were generated to augment training
datasets for machine learning models. The proposed method
demonstrated improved accuracy in SQLi detection systems
by reducing both false positives and false negatives. Extensive
empirical testing further illustrated the ability of the system to
adapt to evolving SQLi attack patterns, resulting in enhanced
precision and robustness.
Index Terms —SQL Injection, Machine Learning, Generative
Models, Variational Autoencoder (V AE), U-Net, CWGAN-GP,
Data Augmentation, Cybersecurity.
I.INTRODUCTION
SQL Injection (SQLi) remains one of the most critical
security vulnerabilities affecting web applications today. As
cyber threats evolve, attackers continuously exploit input han-
dling weaknesses, injecting malicious SQL commands into
legitimate queries. These attacks, often launched through input
fields such as login forms or URL parameters, enable unau-
thorised access to sensitive data or, in severe cases, complete
control over the database.
The Open Web Application Security Project (OWASP) con-
tinues to rank SQLi among the top security risks, reinforcing
its prevalence and severity in the landscape of web vulnerabil-
ities [1]. The impact of SQLi attacks is often severe, leading
to data breaches, financial loss, and reputational damage to
affected organisations.
Traditional defence mechanisms, such as input validation
and signature-based detection systems, have been widely em-
ployed to combat SQLi attacks.

The proposed method
demonstrated improved accuracy in SQLi detection systems
by reducing both false positives and false negatives. Extensive
empirical testing further illustrated the ability of the system to
adapt to evolving SQLi attack patterns, resulting in enhanced
precision and robustness.
Index Terms —SQL Injection, Machine Learning, Generative
Models, Variational Autoencoder (V AE), U-Net, CWGAN-GP,
Data Augmentation, Cybersecurity.
I.INTRODUCTION
SQL Injection (SQLi) remains one of the most critical
security vulnerabilities affecting web applications today. As
cyber threats evolve, attackers continuously exploit input han-
dling weaknesses, injecting malicious SQL commands into
legitimate queries. These attacks, often launched through input
fields such as login forms or URL parameters, enable unau-
thorised access to sensitive data or, in severe cases, complete
control over the database.
The Open Web Application Security Project (OWASP) con-
tinues to rank SQLi among the top security risks, reinforcing
its prevalence and severity in the landscape of web vulnerabil-
ities [1]. The impact of SQLi attacks is often severe, leading
to data breaches, financial loss, and reputational damage to
affected organisations.
Traditional defence mechanisms, such as input validation
and signature-based detection systems, have been widely em-
ployed to combat SQLi attacks. However, these methods often
fall short when confronting the evolving techniques used by
attackers.

Extensive
empirical testing further illustrated the ability of the system to
adapt to evolving SQLi attack patterns, resulting in enhanced
precision and robustness.
Index Terms —SQL Injection, Machine Learning, Generative
Models, Variational Autoencoder (V AE), U-Net, CWGAN-GP,
Data Augmentation, Cybersecurity.
I.INTRODUCTION
SQL Injection (SQLi) remains one of the most critical
security vulnerabilities affecting web applications today. As
cyber threats evolve, attackers continuously exploit input han-
dling weaknesses, injecting malicious SQL commands into
legitimate queries. These attacks, often launched through input
fields such as login forms or URL parameters, enable unau-
thorised access to sensitive data or, in severe cases, complete
control over the database.
The Open Web Application Security Project (OWASP) con-
tinues to rank SQLi among the top security risks, reinforcing
its prevalence and severity in the landscape of web vulnerabil-
ities [1]. The impact of SQLi attacks is often severe, leading
to data breaches, financial loss, and reputational damage to
affected organisations.
Traditional defence mechanisms, such as input validation
and signature-based detection systems, have been widely em-
ployed to combat SQLi attacks. However, these methods often
fall short when confronting the evolving techniques used by
attackers. Signature-based systems, in particular, struggle with
false positives and false negatives, especially when attackers
use obfuscation or innovative variations of SQLi that deviate
from known patterns [2], [3], [4].Several major challenges have made SQLi detection diffi-
cult: the lack of data diversity, static detection systems, and
the high error rates of existing solutions.

As
cyber threats evolve, attackers continuously exploit input han-
dling weaknesses, injecting malicious SQL commands into
legitimate queries. These attacks, often launched through input
fields such as login forms or URL parameters, enable unau-
thorised access to sensitive data or, in severe cases, complete
control over the database.
The Open Web Application Security Project (OWASP) con-
tinues to rank SQLi among the top security risks, reinforcing
its prevalence and severity in the landscape of web vulnerabil-
ities [1]. The impact of SQLi attacks is often severe, leading
to data breaches, financial loss, and reputational damage to
affected organisations.
Traditional defence mechanisms, such as input validation
and signature-based detection systems, have been widely em-
ployed to combat SQLi attacks. However, these methods often
fall short when confronting the evolving techniques used by
attackers. Signature-based systems, in particular, struggle with
false positives and false negatives, especially when attackers
use obfuscation or innovative variations of SQLi that deviate
from known patterns [2], [3], [4].Several major challenges have made SQLi detection diffi-
cult: the lack of data diversity, static detection systems, and
the high error rates of existing solutions. These limitations
prevent traditional methods from adapting to the broad range
of SQL Injection Attack (SQLIA) types, particularly the more
complex ones.
To address these limitations, this research introduces a
dynamic approach that combines synthetic data generation
with advanced deep learning models.

These attacks, often launched through input
fields such as login forms or URL parameters, enable unau-
thorised access to sensitive data or, in severe cases, complete
control over the database.
The Open Web Application Security Project (OWASP) con-
tinues to rank SQLi among the top security risks, reinforcing
its prevalence and severity in the landscape of web vulnerabil-
ities [1]. The impact of SQLi attacks is often severe, leading
to data breaches, financial loss, and reputational damage to
affected organisations.
Traditional defence mechanisms, such as input validation
and signature-based detection systems, have been widely em-
ployed to combat SQLi attacks. However, these methods often
fall short when confronting the evolving techniques used by
attackers. Signature-based systems, in particular, struggle with
false positives and false negatives, especially when attackers
use obfuscation or innovative variations of SQLi that deviate
from known patterns [2], [3], [4].Several major challenges have made SQLi detection diffi-
cult: the lack of data diversity, static detection systems, and
the high error rates of existing solutions. These limitations
prevent traditional methods from adapting to the broad range
of SQL Injection Attack (SQLIA) types, particularly the more
complex ones.
To address these limitations, this research introduces a
dynamic approach that combines synthetic data generation
with advanced deep learning models. Specifically, Variational
Autoencoders (V AE), U-Net, and Conditional Wasserstein
GAN with Gradient Penalty (CWGAN-GP) are leveraged to
generate diverse synthetic SQL data.

The impact of SQLi attacks is often severe, leading
to data breaches, financial loss, and reputational damage to
affected organisations.
Traditional defence mechanisms, such as input validation
and signature-based detection systems, have been widely em-
ployed to combat SQLi attacks. However, these methods often
fall short when confronting the evolving techniques used by
attackers. Signature-based systems, in particular, struggle with
false positives and false negatives, especially when attackers
use obfuscation or innovative variations of SQLi that deviate
from known patterns [2], [3], [4].Several major challenges have made SQLi detection diffi-
cult: the lack of data diversity, static detection systems, and
the high error rates of existing solutions. These limitations
prevent traditional methods from adapting to the broad range
of SQL Injection Attack (SQLIA) types, particularly the more
complex ones.
To address these limitations, this research introduces a
dynamic approach that combines synthetic data generation
with advanced deep learning models. Specifically, Variational
Autoencoders (V AE), U-Net, and Conditional Wasserstein
GAN with Gradient Penalty (CWGAN-GP) are leveraged to
generate diverse synthetic SQL data. This enriched dataset
helps improve generalisation and provides better identification
of both traditional and modern SQLi attacks [5], [6], [7].
The aim of this research is to enhance SQLIA detection by
integrating synthetic data generation with advanced machine
learning models to improve accuracy, adaptability, and overall
system robustness.

However, these methods often
fall short when confronting the evolving techniques used by
attackers. Signature-based systems, in particular, struggle with
false positives and false negatives, especially when attackers
use obfuscation or innovative variations of SQLi that deviate
from known patterns [2], [3], [4].Several major challenges have made SQLi detection diffi-
cult: the lack of data diversity, static detection systems, and
the high error rates of existing solutions. These limitations
prevent traditional methods from adapting to the broad range
of SQL Injection Attack (SQLIA) types, particularly the more
complex ones.
To address these limitations, this research introduces a
dynamic approach that combines synthetic data generation
with advanced deep learning models. Specifically, Variational
Autoencoders (V AE), U-Net, and Conditional Wasserstein
GAN with Gradient Penalty (CWGAN-GP) are leveraged to
generate diverse synthetic SQL data. This enriched dataset
helps improve generalisation and provides better identification
of both traditional and modern SQLi attacks [5], [6], [7].
The aim of this research is to enhance SQLIA detection by
integrating synthetic data generation with advanced machine
learning models to improve accuracy, adaptability, and overall
system robustness. By preprocessing and embedding SQL
queries and using synthetic data to diversify the training set,
the study focuses on optimising key performance metrics such
as accuracy, precision, recall, and F1-score.

Signature-based systems, in particular, struggle with
false positives and false negatives, especially when attackers
use obfuscation or innovative variations of SQLi that deviate
from known patterns [2], [3], [4].Several major challenges have made SQLi detection diffi-
cult: the lack of data diversity, static detection systems, and
the high error rates of existing solutions. These limitations
prevent traditional methods from adapting to the broad range
of SQL Injection Attack (SQLIA) types, particularly the more
complex ones.
To address these limitations, this research introduces a
dynamic approach that combines synthetic data generation
with advanced deep learning models. Specifically, Variational
Autoencoders (V AE), U-Net, and Conditional Wasserstein
GAN with Gradient Penalty (CWGAN-GP) are leveraged to
generate diverse synthetic SQL data. This enriched dataset
helps improve generalisation and provides better identification
of both traditional and modern SQLi attacks [5], [6], [7].
The aim of this research is to enhance SQLIA detection by
integrating synthetic data generation with advanced machine
learning models to improve accuracy, adaptability, and overall
system robustness. By preprocessing and embedding SQL
queries and using synthetic data to diversify the training set,
the study focuses on optimising key performance metrics such
as accuracy, precision, recall, and F1-score. The remainder
of this paper is organised as follows.

These limitations
prevent traditional methods from adapting to the broad range
of SQL Injection Attack (SQLIA) types, particularly the more
complex ones.
To address these limitations, this research introduces a
dynamic approach that combines synthetic data generation
with advanced deep learning models. Specifically, Variational
Autoencoders (V AE), U-Net, and Conditional Wasserstein
GAN with Gradient Penalty (CWGAN-GP) are leveraged to
generate diverse synthetic SQL data. This enriched dataset
helps improve generalisation and provides better identification
of both traditional and modern SQLi attacks [5], [6], [7].
The aim of this research is to enhance SQLIA detection by
integrating synthetic data generation with advanced machine
learning models to improve accuracy, adaptability, and overall
system robustness. By preprocessing and embedding SQL
queries and using synthetic data to diversify the training set,
the study focuses on optimising key performance metrics such
as accuracy, precision, recall, and F1-score. The remainder
of this paper is organised as follows. Section II covers the
literature review; Section III presents the implementation to
develop the SQLi detection solution.

Specifically, Variational
Autoencoders (V AE), U-Net, and Conditional Wasserstein
GAN with Gradient Penalty (CWGAN-GP) are leveraged to
generate diverse synthetic SQL data. This enriched dataset
helps improve generalisation and provides better identification
of both traditional and modern SQLi attacks [5], [6], [7].
The aim of this research is to enhance SQLIA detection by
integrating synthetic data generation with advanced machine
learning models to improve accuracy, adaptability, and overall
system robustness. By preprocessing and embedding SQL
queries and using synthetic data to diversify the training set,
the study focuses on optimising key performance metrics such
as accuracy, precision, recall, and F1-score. The remainder
of this paper is organised as follows. Section II covers the
literature review; Section III presents the implementation to
develop the SQLi detection solution. In Section IV , results and
analysis are discussed, followed by the conclusion in Section
V.

This enriched dataset
helps improve generalisation and provides better identification
of both traditional and modern SQLi attacks [5], [6], [7].
The aim of this research is to enhance SQLIA detection by
integrating synthetic data generation with advanced machine
learning models to improve accuracy, adaptability, and overall
system robustness. By preprocessing and embedding SQL
queries and using synthetic data to diversify the training set,
the study focuses on optimising key performance metrics such
as accuracy, precision, recall, and F1-score. The remainder
of this paper is organised as follows. Section II covers the
literature review; Section III presents the implementation to
develop the SQLi detection solution. In Section IV , results and
analysis are discussed, followed by the conclusion in Section
V. Finally, Section VI outlines the limitations and future scope
of the work.
II.LITERATURE REVIEW
A.

By preprocessing and embedding SQL
queries and using synthetic data to diversify the training set,
the study focuses on optimising key performance metrics such
as accuracy, precision, recall, and F1-score. The remainder
of this paper is organised as follows. Section II covers the
literature review; Section III presents the implementation to
develop the SQLi detection solution. In Section IV , results and
analysis are discussed, followed by the conclusion in Section
V. Finally, Section VI outlines the limitations and future scope
of the work.
II.LITERATURE REVIEW
A. SQL Injection
Traditional SQL Injection (SQLi) prevention methods pri-
marily focused on fundamental coding practices such as input
validation and parameterised queries, which aimed to mitigate
attacks by sanitising user inputs.

The remainder
of this paper is organised as follows. Section II covers the
literature review; Section III presents the implementation to
develop the SQLi detection solution. In Section IV , results and
analysis are discussed, followed by the conclusion in Section
V. Finally, Section VI outlines the limitations and future scope
of the work.
II.LITERATURE REVIEW
A. SQL Injection
Traditional SQL Injection (SQLi) prevention methods pri-
marily focused on fundamental coding practices such as input
validation and parameterised queries, which aimed to mitigate
attacks by sanitising user inputs. Although these methods were
effective for basic attacks, more sophisticated techniques, such
as time-based, blind, and second-order SQL injections, enabled
malicious inputs to bypass traditional validation mechanisms
and execute the payload at a later stage [2].

Section II covers the
literature review; Section III presents the implementation to
develop the SQLi detection solution. In Section IV , results and
analysis are discussed, followed by the conclusion in Section
V. Finally, Section VI outlines the limitations and future scope
of the work.
II.LITERATURE REVIEW
A. SQL Injection
Traditional SQL Injection (SQLi) prevention methods pri-
marily focused on fundamental coding practices such as input
validation and parameterised queries, which aimed to mitigate
attacks by sanitising user inputs. Although these methods were
effective for basic attacks, more sophisticated techniques, such
as time-based, blind, and second-order SQL injections, enabled
malicious inputs to bypass traditional validation mechanisms
and execute the payload at a later stage [2]. As SQLi threats
evolved, signature-based detection systems were introduced,
relying on known attack patterns to identify malicious queries
in real time.

In Section IV , results and
analysis are discussed, followed by the conclusion in Section
V. Finally, Section VI outlines the limitations and future scope
of the work.
II.LITERATURE REVIEW
A. SQL Injection
Traditional SQL Injection (SQLi) prevention methods pri-
marily focused on fundamental coding practices such as input
validation and parameterised queries, which aimed to mitigate
attacks by sanitising user inputs. Although these methods were
effective for basic attacks, more sophisticated techniques, such
as time-based, blind, and second-order SQL injections, enabled
malicious inputs to bypass traditional validation mechanisms
and execute the payload at a later stage [2]. As SQLi threats
evolved, signature-based detection systems were introduced,
relying on known attack patterns to identify malicious queries
in real time. However, these systems encountered significant
difficulties in handling novel and obfuscated attacks that devi-
ated from predefined patterns, resulting in high false-positivearXiv:2502.04786v1  [cs.CR]  7 Feb 2025
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 2
and false-negative rates [3].

Finally, Section VI outlines the limitations and future scope
of the work.
II.LITERATURE REVIEW
A. SQL Injection
Traditional SQL Injection (SQLi) prevention methods pri-
marily focused on fundamental coding practices such as input
validation and parameterised queries, which aimed to mitigate
attacks by sanitising user inputs. Although these methods were
effective for basic attacks, more sophisticated techniques, such
as time-based, blind, and second-order SQL injections, enabled
malicious inputs to bypass traditional validation mechanisms
and execute the payload at a later stage [2]. As SQLi threats
evolved, signature-based detection systems were introduced,
relying on known attack patterns to identify malicious queries
in real time. However, these systems encountered significant
difficulties in handling novel and obfuscated attacks that devi-
ated from predefined patterns, resulting in high false-positivearXiv:2502.04786v1  [cs.CR]  7 Feb 2025
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 2
and false-negative rates [3]. To address these challenges, rule-
based systems were developed to analyse query structures
more deeply.

SQL Injection
Traditional SQL Injection (SQLi) prevention methods pri-
marily focused on fundamental coding practices such as input
validation and parameterised queries, which aimed to mitigate
attacks by sanitising user inputs. Although these methods were
effective for basic attacks, more sophisticated techniques, such
as time-based, blind, and second-order SQL injections, enabled
malicious inputs to bypass traditional validation mechanisms
and execute the payload at a later stage [2]. As SQLi threats
evolved, signature-based detection systems were introduced,
relying on known attack patterns to identify malicious queries
in real time. However, these systems encountered significant
difficulties in handling novel and obfuscated attacks that devi-
ated from predefined patterns, resulting in high false-positivearXiv:2502.04786v1  [cs.CR]  7 Feb 2025
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 2
and false-negative rates [3]. To address these challenges, rule-
based systems were developed to analyse query structures
more deeply. Yet, they continued to experience high false-
positive rates and struggled to detect subtle attacks [4].
With the continuous advancement of SQLi techniques,
behavioural detection systems were developed to identify
anomalies in query behaviour.

Although these methods were
effective for basic attacks, more sophisticated techniques, such
as time-based, blind, and second-order SQL injections, enabled
malicious inputs to bypass traditional validation mechanisms
and execute the payload at a later stage [2]. As SQLi threats
evolved, signature-based detection systems were introduced,
relying on known attack patterns to identify malicious queries
in real time. However, these systems encountered significant
difficulties in handling novel and obfuscated attacks that devi-
ated from predefined patterns, resulting in high false-positivearXiv:2502.04786v1  [cs.CR]  7 Feb 2025
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 2
and false-negative rates [3]. To address these challenges, rule-
based systems were developed to analyse query structures
more deeply. Yet, they continued to experience high false-
positive rates and struggled to detect subtle attacks [4].
With the continuous advancement of SQLi techniques,
behavioural detection systems were developed to identify
anomalies in query behaviour. These systems aimed to detect
deviations from normal query patterns but often produced
high false positives, particularly in dynamic environments
[8].

As SQLi threats
evolved, signature-based detection systems were introduced,
relying on known attack patterns to identify malicious queries
in real time. However, these systems encountered significant
difficulties in handling novel and obfuscated attacks that devi-
ated from predefined patterns, resulting in high false-positivearXiv:2502.04786v1  [cs.CR]  7 Feb 2025
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 2
and false-negative rates [3]. To address these challenges, rule-
based systems were developed to analyse query structures
more deeply. Yet, they continued to experience high false-
positive rates and struggled to detect subtle attacks [4].
With the continuous advancement of SQLi techniques,
behavioural detection systems were developed to identify
anomalies in query behaviour. These systems aimed to detect
deviations from normal query patterns but often produced
high false positives, particularly in dynamic environments
[8]. Hybrid models that combined static code analysis with
dynamic execution traces improved detection by analysing
both code structure and runtime behaviour.

However, these systems encountered significant
difficulties in handling novel and obfuscated attacks that devi-
ated from predefined patterns, resulting in high false-positivearXiv:2502.04786v1  [cs.CR]  7 Feb 2025
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 2
and false-negative rates [3]. To address these challenges, rule-
based systems were developed to analyse query structures
more deeply. Yet, they continued to experience high false-
positive rates and struggled to detect subtle attacks [4].
With the continuous advancement of SQLi techniques,
behavioural detection systems were developed to identify
anomalies in query behaviour. These systems aimed to detect
deviations from normal query patterns but often produced
high false positives, particularly in dynamic environments
[8]. Hybrid models that combined static code analysis with
dynamic execution traces improved detection by analysing
both code structure and runtime behaviour. Nonetheless, their
dependency on labelled data reduced their effectiveness in
real-world scenarios, where such datasets are often limited
[9].

To address these challenges, rule-
based systems were developed to analyse query structures
more deeply. Yet, they continued to experience high false-
positive rates and struggled to detect subtle attacks [4].
With the continuous advancement of SQLi techniques,
behavioural detection systems were developed to identify
anomalies in query behaviour. These systems aimed to detect
deviations from normal query patterns but often produced
high false positives, particularly in dynamic environments
[8]. Hybrid models that combined static code analysis with
dynamic execution traces improved detection by analysing
both code structure and runtime behaviour. Nonetheless, their
dependency on labelled data reduced their effectiveness in
real-world scenarios, where such datasets are often limited
[9]. Heuristic-based systems, such as V1p3R, attempted to
overcome these issues by leveraging error message feedback
to adapt detection in real time, but complex and obfuscated
attacks remained difficult to detect [10].
To overcome these persistent limitations, machine learning
approaches have been increasingly applied to SQLi detection.
Early models, such as Na ¨ıve Bayes combined with Role-
Based Access Control (RBAC), improved detection accuracy
by classifying queries probabilistically.

Yet, they continued to experience high false-
positive rates and struggled to detect subtle attacks [4].
With the continuous advancement of SQLi techniques,
behavioural detection systems were developed to identify
anomalies in query behaviour. These systems aimed to detect
deviations from normal query patterns but often produced
high false positives, particularly in dynamic environments
[8]. Hybrid models that combined static code analysis with
dynamic execution traces improved detection by analysing
both code structure and runtime behaviour. Nonetheless, their
dependency on labelled data reduced their effectiveness in
real-world scenarios, where such datasets are often limited
[9]. Heuristic-based systems, such as V1p3R, attempted to
overcome these issues by leveraging error message feedback
to adapt detection in real time, but complex and obfuscated
attacks remained difficult to detect [10].
To overcome these persistent limitations, machine learning
approaches have been increasingly applied to SQLi detection.
Early models, such as Na ¨ıve Bayes combined with Role-
Based Access Control (RBAC), improved detection accuracy
by classifying queries probabilistically. However, these models
faced difficulties in handling obfuscated attacks and required
manually crafted features, which limited their adaptability to
novel attack patterns [5].

These systems aimed to detect
deviations from normal query patterns but often produced
high false positives, particularly in dynamic environments
[8]. Hybrid models that combined static code analysis with
dynamic execution traces improved detection by analysing
both code structure and runtime behaviour. Nonetheless, their
dependency on labelled data reduced their effectiveness in
real-world scenarios, where such datasets are often limited
[9]. Heuristic-based systems, such as V1p3R, attempted to
overcome these issues by leveraging error message feedback
to adapt detection in real time, but complex and obfuscated
attacks remained difficult to detect [10].
To overcome these persistent limitations, machine learning
approaches have been increasingly applied to SQLi detection.
Early models, such as Na ¨ıve Bayes combined with Role-
Based Access Control (RBAC), improved detection accuracy
by classifying queries probabilistically. However, these models
faced difficulties in handling obfuscated attacks and required
manually crafted features, which limited their adaptability to
novel attack patterns [5]. Support Vector Machines (SVMs)
offered further improvements by enhancing scalability and
handling more complex SQLi patterns.

Hybrid models that combined static code analysis with
dynamic execution traces improved detection by analysing
both code structure and runtime behaviour. Nonetheless, their
dependency on labelled data reduced their effectiveness in
real-world scenarios, where such datasets are often limited
[9]. Heuristic-based systems, such as V1p3R, attempted to
overcome these issues by leveraging error message feedback
to adapt detection in real time, but complex and obfuscated
attacks remained difficult to detect [10].
To overcome these persistent limitations, machine learning
approaches have been increasingly applied to SQLi detection.
Early models, such as Na ¨ıve Bayes combined with Role-
Based Access Control (RBAC), improved detection accuracy
by classifying queries probabilistically. However, these models
faced difficulties in handling obfuscated attacks and required
manually crafted features, which limited their adaptability to
novel attack patterns [5]. Support Vector Machines (SVMs)
offered further improvements by enhancing scalability and
handling more complex SQLi patterns. Yet, their reliance on
manual feature engineering rendered them less effective in
detecting rapidly evolving attacks [6].

Nonetheless, their
dependency on labelled data reduced their effectiveness in
real-world scenarios, where such datasets are often limited
[9]. Heuristic-based systems, such as V1p3R, attempted to
overcome these issues by leveraging error message feedback
to adapt detection in real time, but complex and obfuscated
attacks remained difficult to detect [10].
To overcome these persistent limitations, machine learning
approaches have been increasingly applied to SQLi detection.
Early models, such as Na ¨ıve Bayes combined with Role-
Based Access Control (RBAC), improved detection accuracy
by classifying queries probabilistically. However, these models
faced difficulties in handling obfuscated attacks and required
manually crafted features, which limited their adaptability to
novel attack patterns [5]. Support Vector Machines (SVMs)
offered further improvements by enhancing scalability and
handling more complex SQLi patterns. Yet, their reliance on
manual feature engineering rendered them less effective in
detecting rapidly evolving attacks [6]. Ensemble methods, in-
cluding LightGBM and Gradient Boosting Machines (GBM),
achieved high detection accuracy by combining multiple weak
learners.

Heuristic-based systems, such as V1p3R, attempted to
overcome these issues by leveraging error message feedback
to adapt detection in real time, but complex and obfuscated
attacks remained difficult to detect [10].
To overcome these persistent limitations, machine learning
approaches have been increasingly applied to SQLi detection.
Early models, such as Na ¨ıve Bayes combined with Role-
Based Access Control (RBAC), improved detection accuracy
by classifying queries probabilistically. However, these models
faced difficulties in handling obfuscated attacks and required
manually crafted features, which limited their adaptability to
novel attack patterns [5]. Support Vector Machines (SVMs)
offered further improvements by enhancing scalability and
handling more complex SQLi patterns. Yet, their reliance on
manual feature engineering rendered them less effective in
detecting rapidly evolving attacks [6]. Ensemble methods, in-
cluding LightGBM and Gradient Boosting Machines (GBM),
achieved high detection accuracy by combining multiple weak
learners. Despite these advancements, their dependence on
hand-crafted features hindered their ability to generalise to
unseen queries [7].
More recently, deep learning models, such as Convolu-
tional Neural Networks (CNNs) and Multi-Layer Perceptrons
(MLPs), have pushed SQLi detection forward by automati-
cally extracting complex patterns from SQL queries.

However, these models
faced difficulties in handling obfuscated attacks and required
manually crafted features, which limited their adaptability to
novel attack patterns [5]. Support Vector Machines (SVMs)
offered further improvements by enhancing scalability and
handling more complex SQLi patterns. Yet, their reliance on
manual feature engineering rendered them less effective in
detecting rapidly evolving attacks [6]. Ensemble methods, in-
cluding LightGBM and Gradient Boosting Machines (GBM),
achieved high detection accuracy by combining multiple weak
learners. Despite these advancements, their dependence on
hand-crafted features hindered their ability to generalise to
unseen queries [7].
More recently, deep learning models, such as Convolu-
tional Neural Networks (CNNs) and Multi-Layer Perceptrons
(MLPs), have pushed SQLi detection forward by automati-
cally extracting complex patterns from SQL queries. These
models reduced false positives and enhanced the detection
of obfuscated attacks.

Support Vector Machines (SVMs)
offered further improvements by enhancing scalability and
handling more complex SQLi patterns. Yet, their reliance on
manual feature engineering rendered them less effective in
detecting rapidly evolving attacks [6]. Ensemble methods, in-
cluding LightGBM and Gradient Boosting Machines (GBM),
achieved high detection accuracy by combining multiple weak
learners. Despite these advancements, their dependence on
hand-crafted features hindered their ability to generalise to
unseen queries [7].
More recently, deep learning models, such as Convolu-
tional Neural Networks (CNNs) and Multi-Layer Perceptrons
(MLPs), have pushed SQLi detection forward by automati-
cally extracting complex patterns from SQL queries. These
models reduced false positives and enhanced the detection
of obfuscated attacks. However, they required large, labelled
data sets and high computational resources, which limits their
scalability in practical applications [11].

Yet, their reliance on
manual feature engineering rendered them less effective in
detecting rapidly evolving attacks [6]. Ensemble methods, in-
cluding LightGBM and Gradient Boosting Machines (GBM),
achieved high detection accuracy by combining multiple weak
learners. Despite these advancements, their dependence on
hand-crafted features hindered their ability to generalise to
unseen queries [7].
More recently, deep learning models, such as Convolu-
tional Neural Networks (CNNs) and Multi-Layer Perceptrons
(MLPs), have pushed SQLi detection forward by automati-
cally extracting complex patterns from SQL queries. These
models reduced false positives and enhanced the detection
of obfuscated attacks. However, they required large, labelled
data sets and high computational resources, which limits their
scalability in practical applications [11]. SQLNN, a deep
learning model that utilised TF-IDF for feature extraction,
demonstrated high accuracy but faced challenges in inter-
pretability and struggled to detect highly obfuscated queries
[12].
Despite these advancements, several challenges remain.
Adapting to evolving SQLi techniques, managing limited la-
belled datasets, and addressing the computational costs of deep
learning models continue to present significant hurdles.

Ensemble methods, in-
cluding LightGBM and Gradient Boosting Machines (GBM),
achieved high detection accuracy by combining multiple weak
learners. Despite these advancements, their dependence on
hand-crafted features hindered their ability to generalise to
unseen queries [7].
More recently, deep learning models, such as Convolu-
tional Neural Networks (CNNs) and Multi-Layer Perceptrons
(MLPs), have pushed SQLi detection forward by automati-
cally extracting complex patterns from SQL queries. These
models reduced false positives and enhanced the detection
of obfuscated attacks. However, they required large, labelled
data sets and high computational resources, which limits their
scalability in practical applications [11]. SQLNN, a deep
learning model that utilised TF-IDF for feature extraction,
demonstrated high accuracy but faced challenges in inter-
pretability and struggled to detect highly obfuscated queries
[12].
Despite these advancements, several challenges remain.
Adapting to evolving SQLi techniques, managing limited la-
belled datasets, and addressing the computational costs of deep
learning models continue to present significant hurdles. Tra-
ditional detection systems remain vulnerable to sophisticated
attacks, while machine learning models are still dependent on
manual feature engineering.

Despite these advancements, their dependence on
hand-crafted features hindered their ability to generalise to
unseen queries [7].
More recently, deep learning models, such as Convolu-
tional Neural Networks (CNNs) and Multi-Layer Perceptrons
(MLPs), have pushed SQLi detection forward by automati-
cally extracting complex patterns from SQL queries. These
models reduced false positives and enhanced the detection
of obfuscated attacks. However, they required large, labelled
data sets and high computational resources, which limits their
scalability in practical applications [11]. SQLNN, a deep
learning model that utilised TF-IDF for feature extraction,
demonstrated high accuracy but faced challenges in inter-
pretability and struggled to detect highly obfuscated queries
[12].
Despite these advancements, several challenges remain.
Adapting to evolving SQLi techniques, managing limited la-
belled datasets, and addressing the computational costs of deep
learning models continue to present significant hurdles. Tra-
ditional detection systems remain vulnerable to sophisticated
attacks, while machine learning models are still dependent on
manual feature engineering. These limitations have driven the
exploration of adaptive solutions, such as the generation of
synthetic data to augment limited datasets and improve model
generalisation.B.

These
models reduced false positives and enhanced the detection
of obfuscated attacks. However, they required large, labelled
data sets and high computational resources, which limits their
scalability in practical applications [11]. SQLNN, a deep
learning model that utilised TF-IDF for feature extraction,
demonstrated high accuracy but faced challenges in inter-
pretability and struggled to detect highly obfuscated queries
[12].
Despite these advancements, several challenges remain.
Adapting to evolving SQLi techniques, managing limited la-
belled datasets, and addressing the computational costs of deep
learning models continue to present significant hurdles. Tra-
ditional detection systems remain vulnerable to sophisticated
attacks, while machine learning models are still dependent on
manual feature engineering. These limitations have driven the
exploration of adaptive solutions, such as the generation of
synthetic data to augment limited datasets and improve model
generalisation.B. Text Data Synthesis
1) Rule-based Text Synthesis: Text data synthesis is crucial
for enhancing the performance of machine learning models,
offering a range of techniques to generate synthetic data.
Model-based techniques, such as those explored in the work
of Panagiotis et al [13], generate diverse data by rephrasing
content while preserving its meaning, though they are com-
putationally demanding and can introduce semantic drift.

However, they required large, labelled
data sets and high computational resources, which limits their
scalability in practical applications [11]. SQLNN, a deep
learning model that utilised TF-IDF for feature extraction,
demonstrated high accuracy but faced challenges in inter-
pretability and struggled to detect highly obfuscated queries
[12].
Despite these advancements, several challenges remain.
Adapting to evolving SQLi techniques, managing limited la-
belled datasets, and addressing the computational costs of deep
learning models continue to present significant hurdles. Tra-
ditional detection systems remain vulnerable to sophisticated
attacks, while machine learning models are still dependent on
manual feature engineering. These limitations have driven the
exploration of adaptive solutions, such as the generation of
synthetic data to augment limited datasets and improve model
generalisation.B. Text Data Synthesis
1) Rule-based Text Synthesis: Text data synthesis is crucial
for enhancing the performance of machine learning models,
offering a range of techniques to generate synthetic data.
Model-based techniques, such as those explored in the work
of Panagiotis et al [13], generate diverse data by rephrasing
content while preserving its meaning, though they are com-
putationally demanding and can introduce semantic drift. On
the other hand, rule-based augmentation methods, such as syn-
onym replacement, random insertion, and swapping [14], offer
computational efficiency but often fail to maintain contextual
meaning, leading to distorted outputs.

SQLNN, a deep
learning model that utilised TF-IDF for feature extraction,
demonstrated high accuracy but faced challenges in inter-
pretability and struggled to detect highly obfuscated queries
[12].
Despite these advancements, several challenges remain.
Adapting to evolving SQLi techniques, managing limited la-
belled datasets, and addressing the computational costs of deep
learning models continue to present significant hurdles. Tra-
ditional detection systems remain vulnerable to sophisticated
attacks, while machine learning models are still dependent on
manual feature engineering. These limitations have driven the
exploration of adaptive solutions, such as the generation of
synthetic data to augment limited datasets and improve model
generalisation.B. Text Data Synthesis
1) Rule-based Text Synthesis: Text data synthesis is crucial
for enhancing the performance of machine learning models,
offering a range of techniques to generate synthetic data.
Model-based techniques, such as those explored in the work
of Panagiotis et al [13], generate diverse data by rephrasing
content while preserving its meaning, though they are com-
putationally demanding and can introduce semantic drift. On
the other hand, rule-based augmentation methods, such as syn-
onym replacement, random insertion, and swapping [14], offer
computational efficiency but often fail to maintain contextual
meaning, leading to distorted outputs. These limitations make
rule-based methods unsuitable for complex tasks such as SQL
query augmentation.
Feature-Space Augmentation, introduced in the work of
Shorten et al [15], applies transformations to latent em-
beddings to improve generalisation by modifying intermedi-
ate representations.

Tra-
ditional detection systems remain vulnerable to sophisticated
attacks, while machine learning models are still dependent on
manual feature engineering. These limitations have driven the
exploration of adaptive solutions, such as the generation of
synthetic data to augment limited datasets and improve model
generalisation.B. Text Data Synthesis
1) Rule-based Text Synthesis: Text data synthesis is crucial
for enhancing the performance of machine learning models,
offering a range of techniques to generate synthetic data.
Model-based techniques, such as those explored in the work
of Panagiotis et al [13], generate diverse data by rephrasing
content while preserving its meaning, though they are com-
putationally demanding and can introduce semantic drift. On
the other hand, rule-based augmentation methods, such as syn-
onym replacement, random insertion, and swapping [14], offer
computational efficiency but often fail to maintain contextual
meaning, leading to distorted outputs. These limitations make
rule-based methods unsuitable for complex tasks such as SQL
query augmentation.
Feature-Space Augmentation, introduced in the work of
Shorten et al [15], applies transformations to latent em-
beddings to improve generalisation by modifying intermedi-
ate representations. Graph-Structured Augmentation preserves
syntactic relationships by leveraging knowledge graphs or
syntax trees, while MixUp Augmentation blends text samples
and labels to expand decision boundaries and reduce overfit-
ting.

These limitations have driven the
exploration of adaptive solutions, such as the generation of
synthetic data to augment limited datasets and improve model
generalisation.B. Text Data Synthesis
1) Rule-based Text Synthesis: Text data synthesis is crucial
for enhancing the performance of machine learning models,
offering a range of techniques to generate synthetic data.
Model-based techniques, such as those explored in the work
of Panagiotis et al [13], generate diverse data by rephrasing
content while preserving its meaning, though they are com-
putationally demanding and can introduce semantic drift. On
the other hand, rule-based augmentation methods, such as syn-
onym replacement, random insertion, and swapping [14], offer
computational efficiency but often fail to maintain contextual
meaning, leading to distorted outputs. These limitations make
rule-based methods unsuitable for complex tasks such as SQL
query augmentation.
Feature-Space Augmentation, introduced in the work of
Shorten et al [15], applies transformations to latent em-
beddings to improve generalisation by modifying intermedi-
ate representations. Graph-Structured Augmentation preserves
syntactic relationships by leveraging knowledge graphs or
syntax trees, while MixUp Augmentation blends text samples
and labels to expand decision boundaries and reduce overfit-
ting. However, these methods can reduce interpretability and
introduce inconsistencies, particularly in structured data such
as SQL queries, where maintaining syntactic and semantic
relationships is critical.

Text Data Synthesis
1) Rule-based Text Synthesis: Text data synthesis is crucial
for enhancing the performance of machine learning models,
offering a range of techniques to generate synthetic data.
Model-based techniques, such as those explored in the work
of Panagiotis et al [13], generate diverse data by rephrasing
content while preserving its meaning, though they are com-
putationally demanding and can introduce semantic drift. On
the other hand, rule-based augmentation methods, such as syn-
onym replacement, random insertion, and swapping [14], offer
computational efficiency but often fail to maintain contextual
meaning, leading to distorted outputs. These limitations make
rule-based methods unsuitable for complex tasks such as SQL
query augmentation.
Feature-Space Augmentation, introduced in the work of
Shorten et al [15], applies transformations to latent em-
beddings to improve generalisation by modifying intermedi-
ate representations. Graph-Structured Augmentation preserves
syntactic relationships by leveraging knowledge graphs or
syntax trees, while MixUp Augmentation blends text samples
and labels to expand decision boundaries and reduce overfit-
ting. However, these methods can reduce interpretability and
introduce inconsistencies, particularly in structured data such
as SQL queries, where maintaining syntactic and semantic
relationships is critical. Minor changes in SQL queries can
disrupt the query logic, making rule-based approaches less
suitable for augmenting SQL data.

On
the other hand, rule-based augmentation methods, such as syn-
onym replacement, random insertion, and swapping [14], offer
computational efficiency but often fail to maintain contextual
meaning, leading to distorted outputs. These limitations make
rule-based methods unsuitable for complex tasks such as SQL
query augmentation.
Feature-Space Augmentation, introduced in the work of
Shorten et al [15], applies transformations to latent em-
beddings to improve generalisation by modifying intermedi-
ate representations. Graph-Structured Augmentation preserves
syntactic relationships by leveraging knowledge graphs or
syntax trees, while MixUp Augmentation blends text samples
and labels to expand decision boundaries and reduce overfit-
ting. However, these methods can reduce interpretability and
introduce inconsistencies, particularly in structured data such
as SQL queries, where maintaining syntactic and semantic
relationships is critical. Minor changes in SQL queries can
disrupt the query logic, making rule-based approaches less
suitable for augmenting SQL data. Consequently, model-
based synthesis provides a more context-aware and accurate
approach for SQL data augmentation.
2) Model-based Text Synthesis: Large Language Models
(LLMs), as highlighted in Lovelace et al [16], capture both
short- and long-term dependencies, making them effective
for tasks such as SQL query augmentation.

These limitations make
rule-based methods unsuitable for complex tasks such as SQL
query augmentation.
Feature-Space Augmentation, introduced in the work of
Shorten et al [15], applies transformations to latent em-
beddings to improve generalisation by modifying intermedi-
ate representations. Graph-Structured Augmentation preserves
syntactic relationships by leveraging knowledge graphs or
syntax trees, while MixUp Augmentation blends text samples
and labels to expand decision boundaries and reduce overfit-
ting. However, these methods can reduce interpretability and
introduce inconsistencies, particularly in structured data such
as SQL queries, where maintaining syntactic and semantic
relationships is critical. Minor changes in SQL queries can
disrupt the query logic, making rule-based approaches less
suitable for augmenting SQL data. Consequently, model-
based synthesis provides a more context-aware and accurate
approach for SQL data augmentation.
2) Model-based Text Synthesis: Large Language Models
(LLMs), as highlighted in Lovelace et al [16], capture both
short- and long-term dependencies, making them effective
for tasks such as SQL query augmentation. However, LLMs
require substantial computational resources and large data sets
for training, which limits their utility in resource-constrained
environments.

Graph-Structured Augmentation preserves
syntactic relationships by leveraging knowledge graphs or
syntax trees, while MixUp Augmentation blends text samples
and labels to expand decision boundaries and reduce overfit-
ting. However, these methods can reduce interpretability and
introduce inconsistencies, particularly in structured data such
as SQL queries, where maintaining syntactic and semantic
relationships is critical. Minor changes in SQL queries can
disrupt the query logic, making rule-based approaches less
suitable for augmenting SQL data. Consequently, model-
based synthesis provides a more context-aware and accurate
approach for SQL data augmentation.
2) Model-based Text Synthesis: Large Language Models
(LLMs), as highlighted in Lovelace et al [16], capture both
short- and long-term dependencies, making them effective
for tasks such as SQL query augmentation. However, LLMs
require substantial computational resources and large data sets
for training, which limits their utility in resource-constrained
environments. Labs [17] discusses the use of Variational
Autoencoders (V AEs) and Generative Adversarial Networks
(GANs), with V AEs providing flexibility by manipulating
latent space and GANs excelling in generating realistic data
through adversarial training.

However, these methods can reduce interpretability and
introduce inconsistencies, particularly in structured data such
as SQL queries, where maintaining syntactic and semantic
relationships is critical. Minor changes in SQL queries can
disrupt the query logic, making rule-based approaches less
suitable for augmenting SQL data. Consequently, model-
based synthesis provides a more context-aware and accurate
approach for SQL data augmentation.
2) Model-based Text Synthesis: Large Language Models
(LLMs), as highlighted in Lovelace et al [16], capture both
short- and long-term dependencies, making them effective
for tasks such as SQL query augmentation. However, LLMs
require substantial computational resources and large data sets
for training, which limits their utility in resource-constrained
environments. Labs [17] discusses the use of Variational
Autoencoders (V AEs) and Generative Adversarial Networks
(GANs), with V AEs providing flexibility by manipulating
latent space and GANs excelling in generating realistic data
through adversarial training. However, GANs demand careful
tuning to prevent mode collapse, which can limit their appli-
cation in certain scenarios.
Transformer-based models, such as BERT, T5, and BART,
utilise attention mechanisms to capture long-range depen-
dencies and are effective for tasks such as text generation
and translation.

Minor changes in SQL queries can
disrupt the query logic, making rule-based approaches less
suitable for augmenting SQL data. Consequently, model-
based synthesis provides a more context-aware and accurate
approach for SQL data augmentation.
2) Model-based Text Synthesis: Large Language Models
(LLMs), as highlighted in Lovelace et al [16], capture both
short- and long-term dependencies, making them effective
for tasks such as SQL query augmentation. However, LLMs
require substantial computational resources and large data sets
for training, which limits their utility in resource-constrained
environments. Labs [17] discusses the use of Variational
Autoencoders (V AEs) and Generative Adversarial Networks
(GANs), with V AEs providing flexibility by manipulating
latent space and GANs excelling in generating realistic data
through adversarial training. However, GANs demand careful
tuning to prevent mode collapse, which can limit their appli-
cation in certain scenarios.
Transformer-based models, such as BERT, T5, and BART,
utilise attention mechanisms to capture long-range depen-
dencies and are effective for tasks such as text generation
and translation. However, these models face scalability chal-
lenges when deployed at scale.

Consequently, model-
based synthesis provides a more context-aware and accurate
approach for SQL data augmentation.
2) Model-based Text Synthesis: Large Language Models
(LLMs), as highlighted in Lovelace et al [16], capture both
short- and long-term dependencies, making them effective
for tasks such as SQL query augmentation. However, LLMs
require substantial computational resources and large data sets
for training, which limits their utility in resource-constrained
environments. Labs [17] discusses the use of Variational
Autoencoders (V AEs) and Generative Adversarial Networks
(GANs), with V AEs providing flexibility by manipulating
latent space and GANs excelling in generating realistic data
through adversarial training. However, GANs demand careful
tuning to prevent mode collapse, which can limit their appli-
cation in certain scenarios.
Transformer-based models, such as BERT, T5, and BART,
utilise attention mechanisms to capture long-range depen-
dencies and are effective for tasks such as text generation
and translation. However, these models face scalability chal-
lenges when deployed at scale. Recurrent Neural Networks
(RNNs), including LSTM and GRU, remain valuable for
sequence modelling involving temporal dependencies but are
increasingly being replaced by transformers in many scenarios.
Additionally, Diffusion Models, such as Denoising Diffusion
Probabilistic Models (DDPM), introduced in the work of
Labs [17], iteratively refine noisy data to improve sample
quality and efficiency, though they also require significant
computational resources.

However, LLMs
require substantial computational resources and large data sets
for training, which limits their utility in resource-constrained
environments. Labs [17] discusses the use of Variational
Autoencoders (V AEs) and Generative Adversarial Networks
(GANs), with V AEs providing flexibility by manipulating
latent space and GANs excelling in generating realistic data
through adversarial training. However, GANs demand careful
tuning to prevent mode collapse, which can limit their appli-
cation in certain scenarios.
Transformer-based models, such as BERT, T5, and BART,
utilise attention mechanisms to capture long-range depen-
dencies and are effective for tasks such as text generation
and translation. However, these models face scalability chal-
lenges when deployed at scale. Recurrent Neural Networks
(RNNs), including LSTM and GRU, remain valuable for
sequence modelling involving temporal dependencies but are
increasingly being replaced by transformers in many scenarios.
Additionally, Diffusion Models, such as Denoising Diffusion
Probabilistic Models (DDPM), introduced in the work of
Labs [17], iteratively refine noisy data to improve sample
quality and efficiency, though they also require significant
computational resources. Seq-U-Net, introduced in the work
of Stoller et al [18], provides a more efficient alternative for
sequence modelling.

Labs [17] discusses the use of Variational
Autoencoders (V AEs) and Generative Adversarial Networks
(GANs), with V AEs providing flexibility by manipulating
latent space and GANs excelling in generating realistic data
through adversarial training. However, GANs demand careful
tuning to prevent mode collapse, which can limit their appli-
cation in certain scenarios.
Transformer-based models, such as BERT, T5, and BART,
utilise attention mechanisms to capture long-range depen-
dencies and are effective for tasks such as text generation
and translation. However, these models face scalability chal-
lenges when deployed at scale. Recurrent Neural Networks
(RNNs), including LSTM and GRU, remain valuable for
sequence modelling involving temporal dependencies but are
increasingly being replaced by transformers in many scenarios.
Additionally, Diffusion Models, such as Denoising Diffusion
Probabilistic Models (DDPM), introduced in the work of
Labs [17], iteratively refine noisy data to improve sample
quality and efficiency, though they also require significant
computational resources. Seq-U-Net, introduced in the work
of Stoller et al [18], provides a more efficient alternative for
sequence modelling. By using causal convolutions, Seq-U-Net
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 3
handles sequence dependencies with reduced computational
costs while preserving syntactic and semantic relationships,
making it particularly useful for structured tasks such as SQL
query generation in resource-constrained environments.
3) Algorithmic-based Text Synthesis: In addition to model-
based methods, algorithmic approaches such as SMOTE (Syn-
thetic Minority Oversampling Technique) [19] efficiently ad-
dress class imbalances by generating synthetic minority class
samples through interpolation.

However, GANs demand careful
tuning to prevent mode collapse, which can limit their appli-
cation in certain scenarios.
Transformer-based models, such as BERT, T5, and BART,
utilise attention mechanisms to capture long-range depen-
dencies and are effective for tasks such as text generation
and translation. However, these models face scalability chal-
lenges when deployed at scale. Recurrent Neural Networks
(RNNs), including LSTM and GRU, remain valuable for
sequence modelling involving temporal dependencies but are
increasingly being replaced by transformers in many scenarios.
Additionally, Diffusion Models, such as Denoising Diffusion
Probabilistic Models (DDPM), introduced in the work of
Labs [17], iteratively refine noisy data to improve sample
quality and efficiency, though they also require significant
computational resources. Seq-U-Net, introduced in the work
of Stoller et al [18], provides a more efficient alternative for
sequence modelling. By using causal convolutions, Seq-U-Net
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 3
handles sequence dependencies with reduced computational
costs while preserving syntactic and semantic relationships,
making it particularly useful for structured tasks such as SQL
query generation in resource-constrained environments.
3) Algorithmic-based Text Synthesis: In addition to model-
based methods, algorithmic approaches such as SMOTE (Syn-
thetic Minority Oversampling Technique) [19] efficiently ad-
dress class imbalances by generating synthetic minority class
samples through interpolation. Variants such as ADASYN
(Adaptive Synthetic Sampling) focus on generating samples
for harder-to-learn instances, improving model performance
in challenging cases [20].

However, these models face scalability chal-
lenges when deployed at scale. Recurrent Neural Networks
(RNNs), including LSTM and GRU, remain valuable for
sequence modelling involving temporal dependencies but are
increasingly being replaced by transformers in many scenarios.
Additionally, Diffusion Models, such as Denoising Diffusion
Probabilistic Models (DDPM), introduced in the work of
Labs [17], iteratively refine noisy data to improve sample
quality and efficiency, though they also require significant
computational resources. Seq-U-Net, introduced in the work
of Stoller et al [18], provides a more efficient alternative for
sequence modelling. By using causal convolutions, Seq-U-Net
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 3
handles sequence dependencies with reduced computational
costs while preserving syntactic and semantic relationships,
making it particularly useful for structured tasks such as SQL
query generation in resource-constrained environments.
3) Algorithmic-based Text Synthesis: In addition to model-
based methods, algorithmic approaches such as SMOTE (Syn-
thetic Minority Oversampling Technique) [19] efficiently ad-
dress class imbalances by generating synthetic minority class
samples through interpolation. Variants such as ADASYN
(Adaptive Synthetic Sampling) focus on generating samples
for harder-to-learn instances, improving model performance
in challenging cases [20]. TOMEK Links, often combined
with SMOTE, refine synthetic data by removing overlapping
points between majority and minority classes, enhancing clas-
sification accuracy [21], [22].

Recurrent Neural Networks
(RNNs), including LSTM and GRU, remain valuable for
sequence modelling involving temporal dependencies but are
increasingly being replaced by transformers in many scenarios.
Additionally, Diffusion Models, such as Denoising Diffusion
Probabilistic Models (DDPM), introduced in the work of
Labs [17], iteratively refine noisy data to improve sample
quality and efficiency, though they also require significant
computational resources. Seq-U-Net, introduced in the work
of Stoller et al [18], provides a more efficient alternative for
sequence modelling. By using causal convolutions, Seq-U-Net
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 3
handles sequence dependencies with reduced computational
costs while preserving syntactic and semantic relationships,
making it particularly useful for structured tasks such as SQL
query generation in resource-constrained environments.
3) Algorithmic-based Text Synthesis: In addition to model-
based methods, algorithmic approaches such as SMOTE (Syn-
thetic Minority Oversampling Technique) [19] efficiently ad-
dress class imbalances by generating synthetic minority class
samples through interpolation. Variants such as ADASYN
(Adaptive Synthetic Sampling) focus on generating samples
for harder-to-learn instances, improving model performance
in challenging cases [20]. TOMEK Links, often combined
with SMOTE, refine synthetic data by removing overlapping
points between majority and minority classes, enhancing clas-
sification accuracy [21], [22]. These methods ensure balanced
data representation, mitigating bias and improving model
generalisation.
Out of all the approaches discussed, model-based methods
were selected due to their ability to maintain syntactic and
semantic relationships, critical for SQL query augmentation.
While SMOTE handles data imbalance, it falls short in pre-
serving complex structures.

Seq-U-Net, introduced in the work
of Stoller et al [18], provides a more efficient alternative for
sequence modelling. By using causal convolutions, Seq-U-Net
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 3
handles sequence dependencies with reduced computational
costs while preserving syntactic and semantic relationships,
making it particularly useful for structured tasks such as SQL
query generation in resource-constrained environments.
3) Algorithmic-based Text Synthesis: In addition to model-
based methods, algorithmic approaches such as SMOTE (Syn-
thetic Minority Oversampling Technique) [19] efficiently ad-
dress class imbalances by generating synthetic minority class
samples through interpolation. Variants such as ADASYN
(Adaptive Synthetic Sampling) focus on generating samples
for harder-to-learn instances, improving model performance
in challenging cases [20]. TOMEK Links, often combined
with SMOTE, refine synthetic data by removing overlapping
points between majority and minority classes, enhancing clas-
sification accuracy [21], [22]. These methods ensure balanced
data representation, mitigating bias and improving model
generalisation.
Out of all the approaches discussed, model-based methods
were selected due to their ability to maintain syntactic and
semantic relationships, critical for SQL query augmentation.
While SMOTE handles data imbalance, it falls short in pre-
serving complex structures. Therefore, techniques such as
V AEs, U-Net, and GANs were chosen for their precision and
reliability for structured data.
Variational Autoencoders (V AEs) have proven highly effec-
tive in reducing dimensionality and extracting features by en-
coding high-dimensional data into latent representations.

By using causal convolutions, Seq-U-Net
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 3
handles sequence dependencies with reduced computational
costs while preserving syntactic and semantic relationships,
making it particularly useful for structured tasks such as SQL
query generation in resource-constrained environments.
3) Algorithmic-based Text Synthesis: In addition to model-
based methods, algorithmic approaches such as SMOTE (Syn-
thetic Minority Oversampling Technique) [19] efficiently ad-
dress class imbalances by generating synthetic minority class
samples through interpolation. Variants such as ADASYN
(Adaptive Synthetic Sampling) focus on generating samples
for harder-to-learn instances, improving model performance
in challenging cases [20]. TOMEK Links, often combined
with SMOTE, refine synthetic data by removing overlapping
points between majority and minority classes, enhancing clas-
sification accuracy [21], [22]. These methods ensure balanced
data representation, mitigating bias and improving model
generalisation.
Out of all the approaches discussed, model-based methods
were selected due to their ability to maintain syntactic and
semantic relationships, critical for SQL query augmentation.
While SMOTE handles data imbalance, it falls short in pre-
serving complex structures. Therefore, techniques such as
V AEs, U-Net, and GANs were chosen for their precision and
reliability for structured data.
Variational Autoencoders (V AEs) have proven highly effec-
tive in reducing dimensionality and extracting features by en-
coding high-dimensional data into latent representations. This
enables models to focus on essential features while discarding
noise, making them ideal for tasks such as SQL injection
detection, where computational efficiency and preserving key
information are critical [23].

Variants such as ADASYN
(Adaptive Synthetic Sampling) focus on generating samples
for harder-to-learn instances, improving model performance
in challenging cases [20]. TOMEK Links, often combined
with SMOTE, refine synthetic data by removing overlapping
points between majority and minority classes, enhancing clas-
sification accuracy [21], [22]. These methods ensure balanced
data representation, mitigating bias and improving model
generalisation.
Out of all the approaches discussed, model-based methods
were selected due to their ability to maintain syntactic and
semantic relationships, critical for SQL query augmentation.
While SMOTE handles data imbalance, it falls short in pre-
serving complex structures. Therefore, techniques such as
V AEs, U-Net, and GANs were chosen for their precision and
reliability for structured data.
Variational Autoencoders (V AEs) have proven highly effec-
tive in reducing dimensionality and extracting features by en-
coding high-dimensional data into latent representations. This
enables models to focus on essential features while discarding
noise, making them ideal for tasks such as SQL injection
detection, where computational efficiency and preserving key
information are critical [23]. Additionally, the V AE ability to
handle semi-supervised learning enables efficient processing
of both labelled and unlabelled data, enhancing their utility in
scenarios with limited labelled datasets [24].
U-Net, initially developed for biomedical segmentation, has
demonstrated its versatility in feature extraction and synthetic
data generation.

TOMEK Links, often combined
with SMOTE, refine synthetic data by removing overlapping
points between majority and minority classes, enhancing clas-
sification accuracy [21], [22]. These methods ensure balanced
data representation, mitigating bias and improving model
generalisation.
Out of all the approaches discussed, model-based methods
were selected due to their ability to maintain syntactic and
semantic relationships, critical for SQL query augmentation.
While SMOTE handles data imbalance, it falls short in pre-
serving complex structures. Therefore, techniques such as
V AEs, U-Net, and GANs were chosen for their precision and
reliability for structured data.
Variational Autoencoders (V AEs) have proven highly effec-
tive in reducing dimensionality and extracting features by en-
coding high-dimensional data into latent representations. This
enables models to focus on essential features while discarding
noise, making them ideal for tasks such as SQL injection
detection, where computational efficiency and preserving key
information are critical [23]. Additionally, the V AE ability to
handle semi-supervised learning enables efficient processing
of both labelled and unlabelled data, enhancing their utility in
scenarios with limited labelled datasets [24].
U-Net, initially developed for biomedical segmentation, has
demonstrated its versatility in feature extraction and synthetic
data generation. Its encoder-decoder architecture excels in
capturing intricate features, even with minimal labelled data.
This makes it particularly well-suited for generating synthetic
SQL injection datasets, addressing the challenge of scarce
labelled data while capturing evolving attack patterns [25],
[26].
GANs further improve text-based data augmentation by en-
hancing the diversity and quality of synthetic data.

These methods ensure balanced
data representation, mitigating bias and improving model
generalisation.
Out of all the approaches discussed, model-based methods
were selected due to their ability to maintain syntactic and
semantic relationships, critical for SQL query augmentation.
While SMOTE handles data imbalance, it falls short in pre-
serving complex structures. Therefore, techniques such as
V AEs, U-Net, and GANs were chosen for their precision and
reliability for structured data.
Variational Autoencoders (V AEs) have proven highly effec-
tive in reducing dimensionality and extracting features by en-
coding high-dimensional data into latent representations. This
enables models to focus on essential features while discarding
noise, making them ideal for tasks such as SQL injection
detection, where computational efficiency and preserving key
information are critical [23]. Additionally, the V AE ability to
handle semi-supervised learning enables efficient processing
of both labelled and unlabelled data, enhancing their utility in
scenarios with limited labelled datasets [24].
U-Net, initially developed for biomedical segmentation, has
demonstrated its versatility in feature extraction and synthetic
data generation. Its encoder-decoder architecture excels in
capturing intricate features, even with minimal labelled data.
This makes it particularly well-suited for generating synthetic
SQL injection datasets, addressing the challenge of scarce
labelled data while capturing evolving attack patterns [25],
[26].
GANs further improve text-based data augmentation by en-
hancing the diversity and quality of synthetic data. Techniques
such as CWGAN-GP introduce class conditioning, generating
text to balance underrepresented categories, which is crucial
for handling class imbalances in SQL injection datasets [15].
Additionally, models such as DP-GAN and SentiGAN promote
diversity in synthetic text generation, preventing mode collapse
and enhancing generalisation for text-heavy tasks [27], [28].
In conclusion, model-based approaches such as V AEs, U-
Net, and GANs offer advanced capabilities in generating
contextually accurate and semantically rich data, making them
more suitable for tasks such as SQL injection detection,
despite their higher computational demands.III.

Therefore, techniques such as
V AEs, U-Net, and GANs were chosen for their precision and
reliability for structured data.
Variational Autoencoders (V AEs) have proven highly effec-
tive in reducing dimensionality and extracting features by en-
coding high-dimensional data into latent representations. This
enables models to focus on essential features while discarding
noise, making them ideal for tasks such as SQL injection
detection, where computational efficiency and preserving key
information are critical [23]. Additionally, the V AE ability to
handle semi-supervised learning enables efficient processing
of both labelled and unlabelled data, enhancing their utility in
scenarios with limited labelled datasets [24].
U-Net, initially developed for biomedical segmentation, has
demonstrated its versatility in feature extraction and synthetic
data generation. Its encoder-decoder architecture excels in
capturing intricate features, even with minimal labelled data.
This makes it particularly well-suited for generating synthetic
SQL injection datasets, addressing the challenge of scarce
labelled data while capturing evolving attack patterns [25],
[26].
GANs further improve text-based data augmentation by en-
hancing the diversity and quality of synthetic data. Techniques
such as CWGAN-GP introduce class conditioning, generating
text to balance underrepresented categories, which is crucial
for handling class imbalances in SQL injection datasets [15].
Additionally, models such as DP-GAN and SentiGAN promote
diversity in synthetic text generation, preventing mode collapse
and enhancing generalisation for text-heavy tasks [27], [28].
In conclusion, model-based approaches such as V AEs, U-
Net, and GANs offer advanced capabilities in generating
contextually accurate and semantically rich data, making them
more suitable for tasks such as SQL injection detection,
despite their higher computational demands.III. IMPLEMENTATION
The pipeline, as illustrated in Figure 1, details the structured
stages of data processing and model implementation used
in this study.

This
enables models to focus on essential features while discarding
noise, making them ideal for tasks such as SQL injection
detection, where computational efficiency and preserving key
information are critical [23]. Additionally, the V AE ability to
handle semi-supervised learning enables efficient processing
of both labelled and unlabelled data, enhancing their utility in
scenarios with limited labelled datasets [24].
U-Net, initially developed for biomedical segmentation, has
demonstrated its versatility in feature extraction and synthetic
data generation. Its encoder-decoder architecture excels in
capturing intricate features, even with minimal labelled data.
This makes it particularly well-suited for generating synthetic
SQL injection datasets, addressing the challenge of scarce
labelled data while capturing evolving attack patterns [25],
[26].
GANs further improve text-based data augmentation by en-
hancing the diversity and quality of synthetic data. Techniques
such as CWGAN-GP introduce class conditioning, generating
text to balance underrepresented categories, which is crucial
for handling class imbalances in SQL injection datasets [15].
Additionally, models such as DP-GAN and SentiGAN promote
diversity in synthetic text generation, preventing mode collapse
and enhancing generalisation for text-heavy tasks [27], [28].
In conclusion, model-based approaches such as V AEs, U-
Net, and GANs offer advanced capabilities in generating
contextually accurate and semantically rich data, making them
more suitable for tasks such as SQL injection detection,
despite their higher computational demands.III. IMPLEMENTATION
The pipeline, as illustrated in Figure 1, details the structured
stages of data processing and model implementation used
in this study. The process commences with data collection
and preprocessing , followed by tokenisation ,embedding ,
and encoding.

Additionally, the V AE ability to
handle semi-supervised learning enables efficient processing
of both labelled and unlabelled data, enhancing their utility in
scenarios with limited labelled datasets [24].
U-Net, initially developed for biomedical segmentation, has
demonstrated its versatility in feature extraction and synthetic
data generation. Its encoder-decoder architecture excels in
capturing intricate features, even with minimal labelled data.
This makes it particularly well-suited for generating synthetic
SQL injection datasets, addressing the challenge of scarce
labelled data while capturing evolving attack patterns [25],
[26].
GANs further improve text-based data augmentation by en-
hancing the diversity and quality of synthetic data. Techniques
such as CWGAN-GP introduce class conditioning, generating
text to balance underrepresented categories, which is crucial
for handling class imbalances in SQL injection datasets [15].
Additionally, models such as DP-GAN and SentiGAN promote
diversity in synthetic text generation, preventing mode collapse
and enhancing generalisation for text-heavy tasks [27], [28].
In conclusion, model-based approaches such as V AEs, U-
Net, and GANs offer advanced capabilities in generating
contextually accurate and semantically rich data, making them
more suitable for tasks such as SQL injection detection,
despite their higher computational demands.III. IMPLEMENTATION
The pipeline, as illustrated in Figure 1, details the structured
stages of data processing and model implementation used
in this study. The process commences with data collection
and preprocessing , followed by tokenisation ,embedding ,
and encoding. Subsequent steps include the generation of
synthetic data using models such as U-Net, and CWGAN-
GP.

Its encoder-decoder architecture excels in
capturing intricate features, even with minimal labelled data.
This makes it particularly well-suited for generating synthetic
SQL injection datasets, addressing the challenge of scarce
labelled data while capturing evolving attack patterns [25],
[26].
GANs further improve text-based data augmentation by en-
hancing the diversity and quality of synthetic data. Techniques
such as CWGAN-GP introduce class conditioning, generating
text to balance underrepresented categories, which is crucial
for handling class imbalances in SQL injection datasets [15].
Additionally, models such as DP-GAN and SentiGAN promote
diversity in synthetic text generation, preventing mode collapse
and enhancing generalisation for text-heavy tasks [27], [28].
In conclusion, model-based approaches such as V AEs, U-
Net, and GANs offer advanced capabilities in generating
contextually accurate and semantically rich data, making them
more suitable for tasks such as SQL injection detection,
despite their higher computational demands.III. IMPLEMENTATION
The pipeline, as illustrated in Figure 1, details the structured
stages of data processing and model implementation used
in this study. The process commences with data collection
and preprocessing , followed by tokenisation ,embedding ,
and encoding. Subsequent steps include the generation of
synthetic data using models such as U-Net, and CWGAN-
GP. These synthetic datasets are then integrated with real data,
resulting in a hybrid dataset, which is used for model training.
The final model evaluation phase ensures that both real and
synthetic data contribute to the detection of SQL Injection
(SQLi) attacks.
Fig.

Techniques
such as CWGAN-GP introduce class conditioning, generating
text to balance underrepresented categories, which is crucial
for handling class imbalances in SQL injection datasets [15].
Additionally, models such as DP-GAN and SentiGAN promote
diversity in synthetic text generation, preventing mode collapse
and enhancing generalisation for text-heavy tasks [27], [28].
In conclusion, model-based approaches such as V AEs, U-
Net, and GANs offer advanced capabilities in generating
contextually accurate and semantically rich data, making them
more suitable for tasks such as SQL injection detection,
despite their higher computational demands.III. IMPLEMENTATION
The pipeline, as illustrated in Figure 1, details the structured
stages of data processing and model implementation used
in this study. The process commences with data collection
and preprocessing , followed by tokenisation ,embedding ,
and encoding. Subsequent steps include the generation of
synthetic data using models such as U-Net, and CWGAN-
GP. These synthetic datasets are then integrated with real data,
resulting in a hybrid dataset, which is used for model training.
The final model evaluation phase ensures that both real and
synthetic data contribute to the detection of SQL Injection
(SQLi) attacks.
Fig. 1.

IMPLEMENTATION
The pipeline, as illustrated in Figure 1, details the structured
stages of data processing and model implementation used
in this study. The process commences with data collection
and preprocessing , followed by tokenisation ,embedding ,
and encoding. Subsequent steps include the generation of
synthetic data using models such as U-Net, and CWGAN-
GP. These synthetic datasets are then integrated with real data,
resulting in a hybrid dataset, which is used for model training.
The final model evaluation phase ensures that both real and
synthetic data contribute to the detection of SQL Injection
(SQLi) attacks.
Fig. 1. Pipeline Architecture
A.

The process commences with data collection
and preprocessing , followed by tokenisation ,embedding ,
and encoding. Subsequent steps include the generation of
synthetic data using models such as U-Net, and CWGAN-
GP. These synthetic datasets are then integrated with real data,
resulting in a hybrid dataset, which is used for model training.
The final model evaluation phase ensures that both real and
synthetic data contribute to the detection of SQL Injection
(SQLi) attacks.
Fig. 1. Pipeline Architecture
A. Data Collection & Preprocessing
The initial datasets, sourced from Kaggle (‘sqli csv‘
and ‘Modified SQL Dataset.csv‘), underwent a rigorous data
cleaning process to resolve inconsistencies and remove re-
dundant entries.

Subsequent steps include the generation of
synthetic data using models such as U-Net, and CWGAN-
GP. These synthetic datasets are then integrated with real data,
resulting in a hybrid dataset, which is used for model training.
The final model evaluation phase ensures that both real and
synthetic data contribute to the detection of SQL Injection
(SQLi) attacks.
Fig. 1. Pipeline Architecture
A. Data Collection & Preprocessing
The initial datasets, sourced from Kaggle (‘sqli csv‘
and ‘Modified SQL Dataset.csv‘), underwent a rigorous data
cleaning process to resolve inconsistencies and remove re-
dundant entries. These datasets were further enriched with
advanced SQLi techniques such as error-based, time-based,
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 4
and blind SQL injection attacks to ensure a comprehensive
representation of various SQLi attack types.

These synthetic datasets are then integrated with real data,
resulting in a hybrid dataset, which is used for model training.
The final model evaluation phase ensures that both real and
synthetic data contribute to the detection of SQL Injection
(SQLi) attacks.
Fig. 1. Pipeline Architecture
A. Data Collection & Preprocessing
The initial datasets, sourced from Kaggle (‘sqli csv‘
and ‘Modified SQL Dataset.csv‘), underwent a rigorous data
cleaning process to resolve inconsistencies and remove re-
dundant entries. These datasets were further enriched with
advanced SQLi techniques such as error-based, time-based,
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 4
and blind SQL injection attacks to ensure a comprehensive
representation of various SQLi attack types. This integration
aimed to improve the detection capabilities of the model for
a broader range of SQL injection patterns, including those
identified in the OWASP Top 10 A03:2021.
B.

1. Pipeline Architecture
A. Data Collection & Preprocessing
The initial datasets, sourced from Kaggle (‘sqli csv‘
and ‘Modified SQL Dataset.csv‘), underwent a rigorous data
cleaning process to resolve inconsistencies and remove re-
dundant entries. These datasets were further enriched with
advanced SQLi techniques such as error-based, time-based,
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 4
and blind SQL injection attacks to ensure a comprehensive
representation of various SQLi attack types. This integration
aimed to improve the detection capabilities of the model for
a broader range of SQL injection patterns, including those
identified in the OWASP Top 10 A03:2021.
B. Tokenisation & Embedding
A custom tokeniser was developed to convert SQL queries
into structured tokens, ensuring the capture of essential syn-
tactic and semantic features.

Pipeline Architecture
A. Data Collection & Preprocessing
The initial datasets, sourced from Kaggle (‘sqli csv‘
and ‘Modified SQL Dataset.csv‘), underwent a rigorous data
cleaning process to resolve inconsistencies and remove re-
dundant entries. These datasets were further enriched with
advanced SQLi techniques such as error-based, time-based,
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 4
and blind SQL injection attacks to ensure a comprehensive
representation of various SQLi attack types. This integration
aimed to improve the detection capabilities of the model for
a broader range of SQL injection patterns, including those
identified in the OWASP Top 10 A03:2021.
B. Tokenisation & Embedding
A custom tokeniser was developed to convert SQL queries
into structured tokens, ensuring the capture of essential syn-
tactic and semantic features. Various embedding methods,
including FastText ,Character-level embeddings ,Byte Pair
Encoding (BPE) , and BERT , were evaluated to determine the
optimal approach.

Data Collection & Preprocessing
The initial datasets, sourced from Kaggle (‘sqli csv‘
and ‘Modified SQL Dataset.csv‘), underwent a rigorous data
cleaning process to resolve inconsistencies and remove re-
dundant entries. These datasets were further enriched with
advanced SQLi techniques such as error-based, time-based,
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 4
and blind SQL injection attacks to ensure a comprehensive
representation of various SQLi attack types. This integration
aimed to improve the detection capabilities of the model for
a broader range of SQL injection patterns, including those
identified in the OWASP Top 10 A03:2021.
B. Tokenisation & Embedding
A custom tokeniser was developed to convert SQL queries
into structured tokens, ensuring the capture of essential syn-
tactic and semantic features. Various embedding methods,
including FastText ,Character-level embeddings ,Byte Pair
Encoding (BPE) , and BERT , were evaluated to determine the
optimal approach. As shown in Fig.

These datasets were further enriched with
advanced SQLi techniques such as error-based, time-based,
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 4
and blind SQL injection attacks to ensure a comprehensive
representation of various SQLi attack types. This integration
aimed to improve the detection capabilities of the model for
a broader range of SQL injection patterns, including those
identified in the OWASP Top 10 A03:2021.
B. Tokenisation & Embedding
A custom tokeniser was developed to convert SQL queries
into structured tokens, ensuring the capture of essential syn-
tactic and semantic features. Various embedding methods,
including FastText ,Character-level embeddings ,Byte Pair
Encoding (BPE) , and BERT , were evaluated to determine the
optimal approach. As shown in Fig. 2, FastText emerged as
the most efficient, offering a strong balance between accuracy
and training time, making it the best option for transforming
SQL queries into vector representations for subsequent model
training.
Fig.

This integration
aimed to improve the detection capabilities of the model for
a broader range of SQL injection patterns, including those
identified in the OWASP Top 10 A03:2021.
B. Tokenisation & Embedding
A custom tokeniser was developed to convert SQL queries
into structured tokens, ensuring the capture of essential syn-
tactic and semantic features. Various embedding methods,
including FastText ,Character-level embeddings ,Byte Pair
Encoding (BPE) , and BERT , were evaluated to determine the
optimal approach. As shown in Fig. 2, FastText emerged as
the most efficient, offering a strong balance between accuracy
and training time, making it the best option for transforming
SQL queries into vector representations for subsequent model
training.
Fig. 2.

Tokenisation & Embedding
A custom tokeniser was developed to convert SQL queries
into structured tokens, ensuring the capture of essential syn-
tactic and semantic features. Various embedding methods,
including FastText ,Character-level embeddings ,Byte Pair
Encoding (BPE) , and BERT , were evaluated to determine the
optimal approach. As shown in Fig. 2, FastText emerged as
the most efficient, offering a strong balance between accuracy
and training time, making it the best option for transforming
SQL queries into vector representations for subsequent model
training.
Fig. 2. Accuracy and Training Time by Embedding Method
C.

Various embedding methods,
including FastText ,Character-level embeddings ,Byte Pair
Encoding (BPE) , and BERT , were evaluated to determine the
optimal approach. As shown in Fig. 2, FastText emerged as
the most efficient, offering a strong balance between accuracy
and training time, making it the best option for transforming
SQL queries into vector representations for subsequent model
training.
Fig. 2. Accuracy and Training Time by Embedding Method
C. Feature Extraction & Data Encoding
The Variational Autoencoder (V AE) was employed to en-
code SQL queries into latent space representations, enabling
effective feature extraction and dimensionality reduction.

As shown in Fig. 2, FastText emerged as
the most efficient, offering a strong balance between accuracy
and training time, making it the best option for transforming
SQL queries into vector representations for subsequent model
training.
Fig. 2. Accuracy and Training Time by Embedding Method
C. Feature Extraction & Data Encoding
The Variational Autoencoder (V AE) was employed to en-
code SQL queries into latent space representations, enabling
effective feature extraction and dimensionality reduction. As
shown in Fig.

2, FastText emerged as
the most efficient, offering a strong balance between accuracy
and training time, making it the best option for transforming
SQL queries into vector representations for subsequent model
training.
Fig. 2. Accuracy and Training Time by Embedding Method
C. Feature Extraction & Data Encoding
The Variational Autoencoder (V AE) was employed to en-
code SQL queries into latent space representations, enabling
effective feature extraction and dimensionality reduction. As
shown in Fig. 3, the V AE consists of an encoder, which
compresses the input SQL queries into latent variables charac-
terised by mean ( µ) and variance ( σ2) vectors, and a decoder,
which reconstructs the input data from this latent space.

2. Accuracy and Training Time by Embedding Method
C. Feature Extraction & Data Encoding
The Variational Autoencoder (V AE) was employed to en-
code SQL queries into latent space representations, enabling
effective feature extraction and dimensionality reduction. As
shown in Fig. 3, the V AE consists of an encoder, which
compresses the input SQL queries into latent variables charac-
terised by mean ( µ) and variance ( σ2) vectors, and a decoder,
which reconstructs the input data from this latent space. The
initial dataset, comprising FastText embeddings with a shape
of (32,336, 100, 50), was transformed into a lower-dimensional
representation of shape (32,336, 448) after V AE encoding.
Fig.

Accuracy and Training Time by Embedding Method
C. Feature Extraction & Data Encoding
The Variational Autoencoder (V AE) was employed to en-
code SQL queries into latent space representations, enabling
effective feature extraction and dimensionality reduction. As
shown in Fig. 3, the V AE consists of an encoder, which
compresses the input SQL queries into latent variables charac-
terised by mean ( µ) and variance ( σ2) vectors, and a decoder,
which reconstructs the input data from this latent space. The
initial dataset, comprising FastText embeddings with a shape
of (32,336, 100, 50), was transformed into a lower-dimensional
representation of shape (32,336, 448) after V AE encoding.
Fig. 3.

Feature Extraction & Data Encoding
The Variational Autoencoder (V AE) was employed to en-
code SQL queries into latent space representations, enabling
effective feature extraction and dimensionality reduction. As
shown in Fig. 3, the V AE consists of an encoder, which
compresses the input SQL queries into latent variables charac-
terised by mean ( µ) and variance ( σ2) vectors, and a decoder,
which reconstructs the input data from this latent space. The
initial dataset, comprising FastText embeddings with a shape
of (32,336, 100, 50), was transformed into a lower-dimensional
representation of shape (32,336, 448) after V AE encoding.
Fig. 3. V AE Architecture for SQL Query Encoding
To enable efficient sampling from the latent space while
maintaining differentiability during training, the reparame-terisation trick was applied, as represented by the following
equation:
z=µ+ϵ·expσ2
2
, ϵ∼ N(0,1)
The V AE’s loss function combines two key components:
1.Reconstruction loss , which measures how accurately the
decoder reconstructs the original SQL queries:
Lreconstruction =1
NNX
i=1∥xi−fdec(zi)∥2
2.Kullback-Leibler (KL) divergence , which regularises the
latent space by ensuring the learned distribution is close to a
unit Gaussian:
LKL=−1
2X
(1 + log( σ2)−µ2−σ2)
The total V AE loss is expressed as:
LV AE =Lreconstruction +β· LKL
where βcontrols the trade-off between reconstruction quality
and regularisation.
Fig.

As
shown in Fig. 3, the V AE consists of an encoder, which
compresses the input SQL queries into latent variables charac-
terised by mean ( µ) and variance ( σ2) vectors, and a decoder,
which reconstructs the input data from this latent space. The
initial dataset, comprising FastText embeddings with a shape
of (32,336, 100, 50), was transformed into a lower-dimensional
representation of shape (32,336, 448) after V AE encoding.
Fig. 3. V AE Architecture for SQL Query Encoding
To enable efficient sampling from the latent space while
maintaining differentiability during training, the reparame-terisation trick was applied, as represented by the following
equation:
z=µ+ϵ·expσ2
2
, ϵ∼ N(0,1)
The V AE’s loss function combines two key components:
1.Reconstruction loss , which measures how accurately the
decoder reconstructs the original SQL queries:
Lreconstruction =1
NNX
i=1∥xi−fdec(zi)∥2
2.Kullback-Leibler (KL) divergence , which regularises the
latent space by ensuring the learned distribution is close to a
unit Gaussian:
LKL=−1
2X
(1 + log( σ2)−µ2−σ2)
The total V AE loss is expressed as:
LV AE =Lreconstruction +β· LKL
where βcontrols the trade-off between reconstruction quality
and regularisation.
Fig. 4 illustrates the convergence of training and validation
losses during V AE training, demonstrating stable learning and
model generalisation.
Fig.

3, the V AE consists of an encoder, which
compresses the input SQL queries into latent variables charac-
terised by mean ( µ) and variance ( σ2) vectors, and a decoder,
which reconstructs the input data from this latent space. The
initial dataset, comprising FastText embeddings with a shape
of (32,336, 100, 50), was transformed into a lower-dimensional
representation of shape (32,336, 448) after V AE encoding.
Fig. 3. V AE Architecture for SQL Query Encoding
To enable efficient sampling from the latent space while
maintaining differentiability during training, the reparame-terisation trick was applied, as represented by the following
equation:
z=µ+ϵ·expσ2
2
, ϵ∼ N(0,1)
The V AE’s loss function combines two key components:
1.Reconstruction loss , which measures how accurately the
decoder reconstructs the original SQL queries:
Lreconstruction =1
NNX
i=1∥xi−fdec(zi)∥2
2.Kullback-Leibler (KL) divergence , which regularises the
latent space by ensuring the learned distribution is close to a
unit Gaussian:
LKL=−1
2X
(1 + log( σ2)−µ2−σ2)
The total V AE loss is expressed as:
LV AE =Lreconstruction +β· LKL
where βcontrols the trade-off between reconstruction quality
and regularisation.
Fig. 4 illustrates the convergence of training and validation
losses during V AE training, demonstrating stable learning and
model generalisation.
Fig. 4.

The
initial dataset, comprising FastText embeddings with a shape
of (32,336, 100, 50), was transformed into a lower-dimensional
representation of shape (32,336, 448) after V AE encoding.
Fig. 3. V AE Architecture for SQL Query Encoding
To enable efficient sampling from the latent space while
maintaining differentiability during training, the reparame-terisation trick was applied, as represented by the following
equation:
z=µ+ϵ·expσ2
2
, ϵ∼ N(0,1)
The V AE’s loss function combines two key components:
1.Reconstruction loss , which measures how accurately the
decoder reconstructs the original SQL queries:
Lreconstruction =1
NNX
i=1∥xi−fdec(zi)∥2
2.Kullback-Leibler (KL) divergence , which regularises the
latent space by ensuring the learned distribution is close to a
unit Gaussian:
LKL=−1
2X
(1 + log( σ2)−µ2−σ2)
The total V AE loss is expressed as:
LV AE =Lreconstruction +β· LKL
where βcontrols the trade-off between reconstruction quality
and regularisation.
Fig. 4 illustrates the convergence of training and validation
losses during V AE training, demonstrating stable learning and
model generalisation.
Fig. 4. Training and Validation Loss during V AE Training
The V AE was evaluated using several metrics, including
Mean Squared Error (MSE) ,R² score , and explained
variance , ensuring that the model efficiently encoded the SQL
queries while minimising reconstruction errors.
The latent representations generated by the V AE were then
used as input for advanced generative models U-Net, and
CWGAN-GP to generate synthetic SQL queries.

3. V AE Architecture for SQL Query Encoding
To enable efficient sampling from the latent space while
maintaining differentiability during training, the reparame-terisation trick was applied, as represented by the following
equation:
z=µ+ϵ·expσ2
2
, ϵ∼ N(0,1)
The V AE’s loss function combines two key components:
1.Reconstruction loss , which measures how accurately the
decoder reconstructs the original SQL queries:
Lreconstruction =1
NNX
i=1∥xi−fdec(zi)∥2
2.Kullback-Leibler (KL) divergence , which regularises the
latent space by ensuring the learned distribution is close to a
unit Gaussian:
LKL=−1
2X
(1 + log( σ2)−µ2−σ2)
The total V AE loss is expressed as:
LV AE =Lreconstruction +β· LKL
where βcontrols the trade-off between reconstruction quality
and regularisation.
Fig. 4 illustrates the convergence of training and validation
losses during V AE training, demonstrating stable learning and
model generalisation.
Fig. 4. Training and Validation Loss during V AE Training
The V AE was evaluated using several metrics, including
Mean Squared Error (MSE) ,R² score , and explained
variance , ensuring that the model efficiently encoded the SQL
queries while minimising reconstruction errors.
The latent representations generated by the V AE were then
used as input for advanced generative models U-Net, and
CWGAN-GP to generate synthetic SQL queries. Additionally,
the V AE-encoded data was used to train several machine
learning models, including Logistic Regression, SVM, Ran-
dom Forest (RF), and XGBoost.

V AE Architecture for SQL Query Encoding
To enable efficient sampling from the latent space while
maintaining differentiability during training, the reparame-terisation trick was applied, as represented by the following
equation:
z=µ+ϵ·expσ2
2
, ϵ∼ N(0,1)
The V AE’s loss function combines two key components:
1.Reconstruction loss , which measures how accurately the
decoder reconstructs the original SQL queries:
Lreconstruction =1
NNX
i=1∥xi−fdec(zi)∥2
2.Kullback-Leibler (KL) divergence , which regularises the
latent space by ensuring the learned distribution is close to a
unit Gaussian:
LKL=−1
2X
(1 + log( σ2)−µ2−σ2)
The total V AE loss is expressed as:
LV AE =Lreconstruction +β· LKL
where βcontrols the trade-off between reconstruction quality
and regularisation.
Fig. 4 illustrates the convergence of training and validation
losses during V AE training, demonstrating stable learning and
model generalisation.
Fig. 4. Training and Validation Loss during V AE Training
The V AE was evaluated using several metrics, including
Mean Squared Error (MSE) ,R² score , and explained
variance , ensuring that the model efficiently encoded the SQL
queries while minimising reconstruction errors.
The latent representations generated by the V AE were then
used as input for advanced generative models U-Net, and
CWGAN-GP to generate synthetic SQL queries. Additionally,
the V AE-encoded data was used to train several machine
learning models, including Logistic Regression, SVM, Ran-
dom Forest (RF), and XGBoost. Each model was rigorously
evaluated based on accuracy, precision, recall, and F1-score
to identify the best-performing baseline model.

4 illustrates the convergence of training and validation
losses during V AE training, demonstrating stable learning and
model generalisation.
Fig. 4. Training and Validation Loss during V AE Training
The V AE was evaluated using several metrics, including
Mean Squared Error (MSE) ,R² score , and explained
variance , ensuring that the model efficiently encoded the SQL
queries while minimising reconstruction errors.
The latent representations generated by the V AE were then
used as input for advanced generative models U-Net, and
CWGAN-GP to generate synthetic SQL queries. Additionally,
the V AE-encoded data was used to train several machine
learning models, including Logistic Regression, SVM, Ran-
dom Forest (RF), and XGBoost. Each model was rigorously
evaluated based on accuracy, precision, recall, and F1-score
to identify the best-performing baseline model. Among these,
XGBoost emerged as the most effective, demonstrating su-
perior performance in terms of classification accuracy and
robustness.

4. Training and Validation Loss during V AE Training
The V AE was evaluated using several metrics, including
Mean Squared Error (MSE) ,R² score , and explained
variance , ensuring that the model efficiently encoded the SQL
queries while minimising reconstruction errors.
The latent representations generated by the V AE were then
used as input for advanced generative models U-Net, and
CWGAN-GP to generate synthetic SQL queries. Additionally,
the V AE-encoded data was used to train several machine
learning models, including Logistic Regression, SVM, Ran-
dom Forest (RF), and XGBoost. Each model was rigorously
evaluated based on accuracy, precision, recall, and F1-score
to identify the best-performing baseline model. Among these,
XGBoost emerged as the most effective, demonstrating su-
perior performance in terms of classification accuracy and
robustness. This baseline model was subsequently used as
a reference to evaluate the quality of the synthetic data as
generated by the advanced generative models.
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 5
D.

Training and Validation Loss during V AE Training
The V AE was evaluated using several metrics, including
Mean Squared Error (MSE) ,R² score , and explained
variance , ensuring that the model efficiently encoded the SQL
queries while minimising reconstruction errors.
The latent representations generated by the V AE were then
used as input for advanced generative models U-Net, and
CWGAN-GP to generate synthetic SQL queries. Additionally,
the V AE-encoded data was used to train several machine
learning models, including Logistic Regression, SVM, Ran-
dom Forest (RF), and XGBoost. Each model was rigorously
evaluated based on accuracy, precision, recall, and F1-score
to identify the best-performing baseline model. Among these,
XGBoost emerged as the most effective, demonstrating su-
perior performance in terms of classification accuracy and
robustness. This baseline model was subsequently used as
a reference to evaluate the quality of the synthetic data as
generated by the advanced generative models.
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 5
D. Synthetic Data Generation
To enhance the diversity of the dataset, two generative
models U-Net, and CWGAN-GP were utilised to generate
synthetic SQL queries that closely mimic real-world SQL
injection patterns.

Additionally,
the V AE-encoded data was used to train several machine
learning models, including Logistic Regression, SVM, Ran-
dom Forest (RF), and XGBoost. Each model was rigorously
evaluated based on accuracy, precision, recall, and F1-score
to identify the best-performing baseline model. Among these,
XGBoost emerged as the most effective, demonstrating su-
perior performance in terms of classification accuracy and
robustness. This baseline model was subsequently used as
a reference to evaluate the quality of the synthetic data as
generated by the advanced generative models.
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 5
D. Synthetic Data Generation
To enhance the diversity of the dataset, two generative
models U-Net, and CWGAN-GP were utilised to generate
synthetic SQL queries that closely mimic real-world SQL
injection patterns. The following subsections will discuss each
model in detail, outlining their architecture and adaptations for
SQL query data generation.
1) U-Net Model: In this study, the U-Net architecture was
adapted for generating synthetic SQL queries to augment the
dataset used for SQL injection detection.

Each model was rigorously
evaluated based on accuracy, precision, recall, and F1-score
to identify the best-performing baseline model. Among these,
XGBoost emerged as the most effective, demonstrating su-
perior performance in terms of classification accuracy and
robustness. This baseline model was subsequently used as
a reference to evaluate the quality of the synthetic data as
generated by the advanced generative models.
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 5
D. Synthetic Data Generation
To enhance the diversity of the dataset, two generative
models U-Net, and CWGAN-GP were utilised to generate
synthetic SQL queries that closely mimic real-world SQL
injection patterns. The following subsections will discuss each
model in detail, outlining their architecture and adaptations for
SQL query data generation.
1) U-Net Model: In this study, the U-Net architecture was
adapted for generating synthetic SQL queries to augment the
dataset used for SQL injection detection. The U-Net model
was chosen due to its ability to capture both local and global
dependencies, which is essential for preserving the hierarchical
structure of SQL queries.
Model Architecture: The U-Net model retained its core
encoder-decoder architecture, but was adapted for 1D se-
quential data, as shown in Fig.

Among these,
XGBoost emerged as the most effective, demonstrating su-
perior performance in terms of classification accuracy and
robustness. This baseline model was subsequently used as
a reference to evaluate the quality of the synthetic data as
generated by the advanced generative models.
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 5
D. Synthetic Data Generation
To enhance the diversity of the dataset, two generative
models U-Net, and CWGAN-GP were utilised to generate
synthetic SQL queries that closely mimic real-world SQL
injection patterns. The following subsections will discuss each
model in detail, outlining their architecture and adaptations for
SQL query data generation.
1) U-Net Model: In this study, the U-Net architecture was
adapted for generating synthetic SQL queries to augment the
dataset used for SQL injection detection. The U-Net model
was chosen due to its ability to capture both local and global
dependencies, which is essential for preserving the hierarchical
structure of SQL queries.
Model Architecture: The U-Net model retained its core
encoder-decoder architecture, but was adapted for 1D se-
quential data, as shown in Fig. 5.

This baseline model was subsequently used as
a reference to evaluate the quality of the synthetic data as
generated by the advanced generative models.
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 5
D. Synthetic Data Generation
To enhance the diversity of the dataset, two generative
models U-Net, and CWGAN-GP were utilised to generate
synthetic SQL queries that closely mimic real-world SQL
injection patterns. The following subsections will discuss each
model in detail, outlining their architecture and adaptations for
SQL query data generation.
1) U-Net Model: In this study, the U-Net architecture was
adapted for generating synthetic SQL queries to augment the
dataset used for SQL injection detection. The U-Net model
was chosen due to its ability to capture both local and global
dependencies, which is essential for preserving the hierarchical
structure of SQL queries.
Model Architecture: The U-Net model retained its core
encoder-decoder architecture, but was adapted for 1D se-
quential data, as shown in Fig. 5. The encoder consists of
convolutional layers followed by batch normalisation, ReLU
activation, and max-pooling to capture abstract features and
reduce dimensionality.

Synthetic Data Generation
To enhance the diversity of the dataset, two generative
models U-Net, and CWGAN-GP were utilised to generate
synthetic SQL queries that closely mimic real-world SQL
injection patterns. The following subsections will discuss each
model in detail, outlining their architecture and adaptations for
SQL query data generation.
1) U-Net Model: In this study, the U-Net architecture was
adapted for generating synthetic SQL queries to augment the
dataset used for SQL injection detection. The U-Net model
was chosen due to its ability to capture both local and global
dependencies, which is essential for preserving the hierarchical
structure of SQL queries.
Model Architecture: The U-Net model retained its core
encoder-decoder architecture, but was adapted for 1D se-
quential data, as shown in Fig. 5. The encoder consists of
convolutional layers followed by batch normalisation, ReLU
activation, and max-pooling to capture abstract features and
reduce dimensionality. The decoder mirrors the encoder but
performs up-sampling, restoring the original sequence struc-
ture of the SQL queries while retaining critical low-level
details through skip connections.
Fig.

The following subsections will discuss each
model in detail, outlining their architecture and adaptations for
SQL query data generation.
1) U-Net Model: In this study, the U-Net architecture was
adapted for generating synthetic SQL queries to augment the
dataset used for SQL injection detection. The U-Net model
was chosen due to its ability to capture both local and global
dependencies, which is essential for preserving the hierarchical
structure of SQL queries.
Model Architecture: The U-Net model retained its core
encoder-decoder architecture, but was adapted for 1D se-
quential data, as shown in Fig. 5. The encoder consists of
convolutional layers followed by batch normalisation, ReLU
activation, and max-pooling to capture abstract features and
reduce dimensionality. The decoder mirrors the encoder but
performs up-sampling, restoring the original sequence struc-
ture of the SQL queries while retaining critical low-level
details through skip connections.
Fig. 5.

The U-Net model
was chosen due to its ability to capture both local and global
dependencies, which is essential for preserving the hierarchical
structure of SQL queries.
Model Architecture: The U-Net model retained its core
encoder-decoder architecture, but was adapted for 1D se-
quential data, as shown in Fig. 5. The encoder consists of
convolutional layers followed by batch normalisation, ReLU
activation, and max-pooling to capture abstract features and
reduce dimensionality. The decoder mirrors the encoder but
performs up-sampling, restoring the original sequence struc-
ture of the SQL queries while retaining critical low-level
details through skip connections.
Fig. 5. U-Net Model Architecture for SQL Query Generation
The mathematical operation for the encoder can be ex-
pressed as:
fenc(x) =MaxPool (ReLU (BN(Conv1D (x))))
Where xis the input SQL query, BN denotes batch normali-
sation, and Conv1D is the 1D convolutional layer.
The decoder reconstructs the input data via:
fdec(x) =Conv1DTranspose (Concat (x,skip))
Here, Conv1DTranspose is used for up-sampling, and Concat
represents the skip connections from corresponding encoder
layers.
Hyperparameter Optimisation with Optuna: To improve
the performance of the U-Net, hyperparameter tuning wasconducted using the Optuna framework.

5. The encoder consists of
convolutional layers followed by batch normalisation, ReLU
activation, and max-pooling to capture abstract features and
reduce dimensionality. The decoder mirrors the encoder but
performs up-sampling, restoring the original sequence struc-
ture of the SQL queries while retaining critical low-level
details through skip connections.
Fig. 5. U-Net Model Architecture for SQL Query Generation
The mathematical operation for the encoder can be ex-
pressed as:
fenc(x) =MaxPool (ReLU (BN(Conv1D (x))))
Where xis the input SQL query, BN denotes batch normali-
sation, and Conv1D is the 1D convolutional layer.
The decoder reconstructs the input data via:
fdec(x) =Conv1DTranspose (Concat (x,skip))
Here, Conv1DTranspose is used for up-sampling, and Concat
represents the skip connections from corresponding encoder
layers.
Hyperparameter Optimisation with Optuna: To improve
the performance of the U-Net, hyperparameter tuning wasconducted using the Optuna framework. The Optuna Tree-
structured Parzen Estimator (TPE) was used to explore the
hyperparameter space.

The encoder consists of
convolutional layers followed by batch normalisation, ReLU
activation, and max-pooling to capture abstract features and
reduce dimensionality. The decoder mirrors the encoder but
performs up-sampling, restoring the original sequence struc-
ture of the SQL queries while retaining critical low-level
details through skip connections.
Fig. 5. U-Net Model Architecture for SQL Query Generation
The mathematical operation for the encoder can be ex-
pressed as:
fenc(x) =MaxPool (ReLU (BN(Conv1D (x))))
Where xis the input SQL query, BN denotes batch normali-
sation, and Conv1D is the 1D convolutional layer.
The decoder reconstructs the input data via:
fdec(x) =Conv1DTranspose (Concat (x,skip))
Here, Conv1DTranspose is used for up-sampling, and Concat
represents the skip connections from corresponding encoder
layers.
Hyperparameter Optimisation with Optuna: To improve
the performance of the U-Net, hyperparameter tuning wasconducted using the Optuna framework. The Optuna Tree-
structured Parzen Estimator (TPE) was used to explore the
hyperparameter space. The optimisation aimed to minimise
the Mean Squared Error (MSE) between the original and re-
constructed SQL queries.

The decoder mirrors the encoder but
performs up-sampling, restoring the original sequence struc-
ture of the SQL queries while retaining critical low-level
details through skip connections.
Fig. 5. U-Net Model Architecture for SQL Query Generation
The mathematical operation for the encoder can be ex-
pressed as:
fenc(x) =MaxPool (ReLU (BN(Conv1D (x))))
Where xis the input SQL query, BN denotes batch normali-
sation, and Conv1D is the 1D convolutional layer.
The decoder reconstructs the input data via:
fdec(x) =Conv1DTranspose (Concat (x,skip))
Here, Conv1DTranspose is used for up-sampling, and Concat
represents the skip connections from corresponding encoder
layers.
Hyperparameter Optimisation with Optuna: To improve
the performance of the U-Net, hyperparameter tuning wasconducted using the Optuna framework. The Optuna Tree-
structured Parzen Estimator (TPE) was used to explore the
hyperparameter space. The optimisation aimed to minimise
the Mean Squared Error (MSE) between the original and re-
constructed SQL queries. The key hyperparameters optimised
were:
•Base Filters: Ranging from 32 to 128 filters.
•Learning Rate: 1e−5to1e−2.
•Dropout Rate: 0.1 to 0.5.
•Depth: 3 to 5 layers.
The best configuration included a base filter size of 704, a
learning rate of 4.61e−5, and a dropout rate of 0.03.

5. U-Net Model Architecture for SQL Query Generation
The mathematical operation for the encoder can be ex-
pressed as:
fenc(x) =MaxPool (ReLU (BN(Conv1D (x))))
Where xis the input SQL query, BN denotes batch normali-
sation, and Conv1D is the 1D convolutional layer.
The decoder reconstructs the input data via:
fdec(x) =Conv1DTranspose (Concat (x,skip))
Here, Conv1DTranspose is used for up-sampling, and Concat
represents the skip connections from corresponding encoder
layers.
Hyperparameter Optimisation with Optuna: To improve
the performance of the U-Net, hyperparameter tuning wasconducted using the Optuna framework. The Optuna Tree-
structured Parzen Estimator (TPE) was used to explore the
hyperparameter space. The optimisation aimed to minimise
the Mean Squared Error (MSE) between the original and re-
constructed SQL queries. The key hyperparameters optimised
were:
•Base Filters: Ranging from 32 to 128 filters.
•Learning Rate: 1e−5to1e−2.
•Dropout Rate: 0.1 to 0.5.
•Depth: 3 to 5 layers.
The best configuration included a base filter size of 704, a
learning rate of 4.61e−5, and a dropout rate of 0.03. These
hyperparameters ensured a balance between model capacity
and generalisation, minimising overfitting.
Training Process: The U-Net model was trained using
the Adam optimiser, with a learning rate decay schedule
that gradually reduced the learning rate.

U-Net Model Architecture for SQL Query Generation
The mathematical operation for the encoder can be ex-
pressed as:
fenc(x) =MaxPool (ReLU (BN(Conv1D (x))))
Where xis the input SQL query, BN denotes batch normali-
sation, and Conv1D is the 1D convolutional layer.
The decoder reconstructs the input data via:
fdec(x) =Conv1DTranspose (Concat (x,skip))
Here, Conv1DTranspose is used for up-sampling, and Concat
represents the skip connections from corresponding encoder
layers.
Hyperparameter Optimisation with Optuna: To improve
the performance of the U-Net, hyperparameter tuning wasconducted using the Optuna framework. The Optuna Tree-
structured Parzen Estimator (TPE) was used to explore the
hyperparameter space. The optimisation aimed to minimise
the Mean Squared Error (MSE) between the original and re-
constructed SQL queries. The key hyperparameters optimised
were:
•Base Filters: Ranging from 32 to 128 filters.
•Learning Rate: 1e−5to1e−2.
•Dropout Rate: 0.1 to 0.5.
•Depth: 3 to 5 layers.
The best configuration included a base filter size of 704, a
learning rate of 4.61e−5, and a dropout rate of 0.03. These
hyperparameters ensured a balance between model capacity
and generalisation, minimising overfitting.
Training Process: The U-Net model was trained using
the Adam optimiser, with a learning rate decay schedule
that gradually reduced the learning rate. Early stopping was
employed to prevent overfitting.

The Optuna Tree-
structured Parzen Estimator (TPE) was used to explore the
hyperparameter space. The optimisation aimed to minimise
the Mean Squared Error (MSE) between the original and re-
constructed SQL queries. The key hyperparameters optimised
were:
•Base Filters: Ranging from 32 to 128 filters.
•Learning Rate: 1e−5to1e−2.
•Dropout Rate: 0.1 to 0.5.
•Depth: 3 to 5 layers.
The best configuration included a base filter size of 704, a
learning rate of 4.61e−5, and a dropout rate of 0.03. These
hyperparameters ensured a balance between model capacity
and generalisation, minimising overfitting.
Training Process: The U-Net model was trained using
the Adam optimiser, with a learning rate decay schedule
that gradually reduced the learning rate. Early stopping was
employed to prevent overfitting. The final loss function was
defined as:
LU−Net=1
NNX
i=1(xi−fdec(fenc(xi)))2
Where xirepresents the input SQL query, and fencandfdec
are the encoder and decoder functions, respectively.
Fig.

The optimisation aimed to minimise
the Mean Squared Error (MSE) between the original and re-
constructed SQL queries. The key hyperparameters optimised
were:
•Base Filters: Ranging from 32 to 128 filters.
•Learning Rate: 1e−5to1e−2.
•Dropout Rate: 0.1 to 0.5.
•Depth: 3 to 5 layers.
The best configuration included a base filter size of 704, a
learning rate of 4.61e−5, and a dropout rate of 0.03. These
hyperparameters ensured a balance between model capacity
and generalisation, minimising overfitting.
Training Process: The U-Net model was trained using
the Adam optimiser, with a learning rate decay schedule
that gradually reduced the learning rate. Early stopping was
employed to prevent overfitting. The final loss function was
defined as:
LU−Net=1
NNX
i=1(xi−fdec(fenc(xi)))2
Where xirepresents the input SQL query, and fencandfdec
are the encoder and decoder functions, respectively.
Fig. 6.

The key hyperparameters optimised
were:
•Base Filters: Ranging from 32 to 128 filters.
•Learning Rate: 1e−5to1e−2.
•Dropout Rate: 0.1 to 0.5.
•Depth: 3 to 5 layers.
The best configuration included a base filter size of 704, a
learning rate of 4.61e−5, and a dropout rate of 0.03. These
hyperparameters ensured a balance between model capacity
and generalisation, minimising overfitting.
Training Process: The U-Net model was trained using
the Adam optimiser, with a learning rate decay schedule
that gradually reduced the learning rate. Early stopping was
employed to prevent overfitting. The final loss function was
defined as:
LU−Net=1
NNX
i=1(xi−fdec(fenc(xi)))2
Where xirepresents the input SQL query, and fencandfdec
are the encoder and decoder functions, respectively.
Fig. 6. Training and Validation Losses of U-Net Model
Evaluation Metrics: The performance of the U-Net model
was evaluated using multiple metrics, including Mean Squared
Error (MSE), R² Score, Explained Variance Score (EVS),
BLEU Score, Cosine Similarity, Lowenstein Distance, and
Mean and Variance Differences.

These
hyperparameters ensured a balance between model capacity
and generalisation, minimising overfitting.
Training Process: The U-Net model was trained using
the Adam optimiser, with a learning rate decay schedule
that gradually reduced the learning rate. Early stopping was
employed to prevent overfitting. The final loss function was
defined as:
LU−Net=1
NNX
i=1(xi−fdec(fenc(xi)))2
Where xirepresents the input SQL query, and fencandfdec
are the encoder and decoder functions, respectively.
Fig. 6. Training and Validation Losses of U-Net Model
Evaluation Metrics: The performance of the U-Net model
was evaluated using multiple metrics, including Mean Squared
Error (MSE), R² Score, Explained Variance Score (EVS),
BLEU Score, Cosine Similarity, Lowenstein Distance, and
Mean and Variance Differences. Additionally, Principal Com-
ponent Analysis (PCA) was conducted to visually compare the
real and synthetic data distributions.

Early stopping was
employed to prevent overfitting. The final loss function was
defined as:
LU−Net=1
NNX
i=1(xi−fdec(fenc(xi)))2
Where xirepresents the input SQL query, and fencandfdec
are the encoder and decoder functions, respectively.
Fig. 6. Training and Validation Losses of U-Net Model
Evaluation Metrics: The performance of the U-Net model
was evaluated using multiple metrics, including Mean Squared
Error (MSE), R² Score, Explained Variance Score (EVS),
BLEU Score, Cosine Similarity, Lowenstein Distance, and
Mean and Variance Differences. Additionally, Principal Com-
ponent Analysis (PCA) was conducted to visually compare the
real and synthetic data distributions. These metrics collectively
confirm the effectiveness of U-Net in generating high-quality
synthetic SQL queries.
2) CWGAN-GP Model : The Conditional Wasserstein Gen-
erative Adversarial Network with Gradient Penalty (CWGAN-
GP) was utilised to generate synthetic SQL queries in this
study.

The final loss function was
defined as:
LU−Net=1
NNX
i=1(xi−fdec(fenc(xi)))2
Where xirepresents the input SQL query, and fencandfdec
are the encoder and decoder functions, respectively.
Fig. 6. Training and Validation Losses of U-Net Model
Evaluation Metrics: The performance of the U-Net model
was evaluated using multiple metrics, including Mean Squared
Error (MSE), R² Score, Explained Variance Score (EVS),
BLEU Score, Cosine Similarity, Lowenstein Distance, and
Mean and Variance Differences. Additionally, Principal Com-
ponent Analysis (PCA) was conducted to visually compare the
real and synthetic data distributions. These metrics collectively
confirm the effectiveness of U-Net in generating high-quality
synthetic SQL queries.
2) CWGAN-GP Model : The Conditional Wasserstein Gen-
erative Adversarial Network with Gradient Penalty (CWGAN-
GP) was utilised to generate synthetic SQL queries in this
study. This model was chosen due to its capability to address
the vanishing gradient problem and mode collapse, issues
that are often encountered when training traditional GANs on
complex, structured data such as SQL queries.

6. Training and Validation Losses of U-Net Model
Evaluation Metrics: The performance of the U-Net model
was evaluated using multiple metrics, including Mean Squared
Error (MSE), R² Score, Explained Variance Score (EVS),
BLEU Score, Cosine Similarity, Lowenstein Distance, and
Mean and Variance Differences. Additionally, Principal Com-
ponent Analysis (PCA) was conducted to visually compare the
real and synthetic data distributions. These metrics collectively
confirm the effectiveness of U-Net in generating high-quality
synthetic SQL queries.
2) CWGAN-GP Model : The Conditional Wasserstein Gen-
erative Adversarial Network with Gradient Penalty (CWGAN-
GP) was utilised to generate synthetic SQL queries in this
study. This model was chosen due to its capability to address
the vanishing gradient problem and mode collapse, issues
that are often encountered when training traditional GANs on
complex, structured data such as SQL queries. The CWGAN-
GP not only stabilises the training process but also allows the
generation of SQL queries conditioned on specific labels, such
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 6
as benign or malicious queries.

Training and Validation Losses of U-Net Model
Evaluation Metrics: The performance of the U-Net model
was evaluated using multiple metrics, including Mean Squared
Error (MSE), R² Score, Explained Variance Score (EVS),
BLEU Score, Cosine Similarity, Lowenstein Distance, and
Mean and Variance Differences. Additionally, Principal Com-
ponent Analysis (PCA) was conducted to visually compare the
real and synthetic data distributions. These metrics collectively
confirm the effectiveness of U-Net in generating high-quality
synthetic SQL queries.
2) CWGAN-GP Model : The Conditional Wasserstein Gen-
erative Adversarial Network with Gradient Penalty (CWGAN-
GP) was utilised to generate synthetic SQL queries in this
study. This model was chosen due to its capability to address
the vanishing gradient problem and mode collapse, issues
that are often encountered when training traditional GANs on
complex, structured data such as SQL queries. The CWGAN-
GP not only stabilises the training process but also allows the
generation of SQL queries conditioned on specific labels, such
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 6
as benign or malicious queries. By incorporating a gradient
penalty, the model enforces Lipschitz continuity, ensuring
smoother training and more realistic query generation.
Model Architecture: The CWGAN-GP architecture con-
sists of two primary components, the generator and the
critic (discriminator), as illustrated in Figure 7.

Additionally, Principal Com-
ponent Analysis (PCA) was conducted to visually compare the
real and synthetic data distributions. These metrics collectively
confirm the effectiveness of U-Net in generating high-quality
synthetic SQL queries.
2) CWGAN-GP Model : The Conditional Wasserstein Gen-
erative Adversarial Network with Gradient Penalty (CWGAN-
GP) was utilised to generate synthetic SQL queries in this
study. This model was chosen due to its capability to address
the vanishing gradient problem and mode collapse, issues
that are often encountered when training traditional GANs on
complex, structured data such as SQL queries. The CWGAN-
GP not only stabilises the training process but also allows the
generation of SQL queries conditioned on specific labels, such
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 6
as benign or malicious queries. By incorporating a gradient
penalty, the model enforces Lipschitz continuity, ensuring
smoother training and more realistic query generation.
Model Architecture: The CWGAN-GP architecture con-
sists of two primary components, the generator and the
critic (discriminator), as illustrated in Figure 7. The generator
produces synthetic SQL queries by combining a random noise
vector zwith a one-hot encoded label y, which is used to
condition the output.

These metrics collectively
confirm the effectiveness of U-Net in generating high-quality
synthetic SQL queries.
2) CWGAN-GP Model : The Conditional Wasserstein Gen-
erative Adversarial Network with Gradient Penalty (CWGAN-
GP) was utilised to generate synthetic SQL queries in this
study. This model was chosen due to its capability to address
the vanishing gradient problem and mode collapse, issues
that are often encountered when training traditional GANs on
complex, structured data such as SQL queries. The CWGAN-
GP not only stabilises the training process but also allows the
generation of SQL queries conditioned on specific labels, such
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 6
as benign or malicious queries. By incorporating a gradient
penalty, the model enforces Lipschitz continuity, ensuring
smoother training and more realistic query generation.
Model Architecture: The CWGAN-GP architecture con-
sists of two primary components, the generator and the
critic (discriminator), as illustrated in Figure 7. The generator
produces synthetic SQL queries by combining a random noise
vector zwith a one-hot encoded label y, which is used to
condition the output. The critic, on the other hand, evaluates
both real and synthetic SQL queries, using the Wasserstein
distance to distinguish between real and fake data, while
a gradient penalty regularises the critic to ensure Lipschitz
continuity.
Fig.

This model was chosen due to its capability to address
the vanishing gradient problem and mode collapse, issues
that are often encountered when training traditional GANs on
complex, structured data such as SQL queries. The CWGAN-
GP not only stabilises the training process but also allows the
generation of SQL queries conditioned on specific labels, such
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 6
as benign or malicious queries. By incorporating a gradient
penalty, the model enforces Lipschitz continuity, ensuring
smoother training and more realistic query generation.
Model Architecture: The CWGAN-GP architecture con-
sists of two primary components, the generator and the
critic (discriminator), as illustrated in Figure 7. The generator
produces synthetic SQL queries by combining a random noise
vector zwith a one-hot encoded label y, which is used to
condition the output. The critic, on the other hand, evaluates
both real and synthetic SQL queries, using the Wasserstein
distance to distinguish between real and fake data, while
a gradient penalty regularises the critic to ensure Lipschitz
continuity.
Fig. 7.

The CWGAN-
GP not only stabilises the training process but also allows the
generation of SQL queries conditioned on specific labels, such
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 6
as benign or malicious queries. By incorporating a gradient
penalty, the model enforces Lipschitz continuity, ensuring
smoother training and more realistic query generation.
Model Architecture: The CWGAN-GP architecture con-
sists of two primary components, the generator and the
critic (discriminator), as illustrated in Figure 7. The generator
produces synthetic SQL queries by combining a random noise
vector zwith a one-hot encoded label y, which is used to
condition the output. The critic, on the other hand, evaluates
both real and synthetic SQL queries, using the Wasserstein
distance to distinguish between real and fake data, while
a gradient penalty regularises the critic to ensure Lipschitz
continuity.
Fig. 7. CWGAN-GP Architectural Design for SQL Data Generation
Mathematical Formulation:
The generator G(z, y)takes a noise vector zsampled
from a normal distribution and a one-hot encoded label y.
These inputs are concatenated and passed through several fully
connected layers, which use ReLU activations to generate
synthetic SQL queries.

By incorporating a gradient
penalty, the model enforces Lipschitz continuity, ensuring
smoother training and more realistic query generation.
Model Architecture: The CWGAN-GP architecture con-
sists of two primary components, the generator and the
critic (discriminator), as illustrated in Figure 7. The generator
produces synthetic SQL queries by combining a random noise
vector zwith a one-hot encoded label y, which is used to
condition the output. The critic, on the other hand, evaluates
both real and synthetic SQL queries, using the Wasserstein
distance to distinguish between real and fake data, while
a gradient penalty regularises the critic to ensure Lipschitz
continuity.
Fig. 7. CWGAN-GP Architectural Design for SQL Data Generation
Mathematical Formulation:
The generator G(z, y)takes a noise vector zsampled
from a normal distribution and a one-hot encoded label y.
These inputs are concatenated and passed through several fully
connected layers, which use ReLU activations to generate
synthetic SQL queries. The generator can be mathematically
formulated as [29]:
G(z, y) =Dense k(ReLU (Concat (z, y)))→.

The generator
produces synthetic SQL queries by combining a random noise
vector zwith a one-hot encoded label y, which is used to
condition the output. The critic, on the other hand, evaluates
both real and synthetic SQL queries, using the Wasserstein
distance to distinguish between real and fake data, while
a gradient penalty regularises the critic to ensure Lipschitz
continuity.
Fig. 7. CWGAN-GP Architectural Design for SQL Data Generation
Mathematical Formulation:
The generator G(z, y)takes a noise vector zsampled
from a normal distribution and a one-hot encoded label y.
These inputs are concatenated and passed through several fully
connected layers, which use ReLU activations to generate
synthetic SQL queries. The generator can be mathematically
formulated as [29]:
G(z, y) =Dense k(ReLU (Concat (z, y)))→. .→Output Layer
where zis the latent noise vector and yis the label.

The critic, on the other hand, evaluates
both real and synthetic SQL queries, using the Wasserstein
distance to distinguish between real and fake data, while
a gradient penalty regularises the critic to ensure Lipschitz
continuity.
Fig. 7. CWGAN-GP Architectural Design for SQL Data Generation
Mathematical Formulation:
The generator G(z, y)takes a noise vector zsampled
from a normal distribution and a one-hot encoded label y.
These inputs are concatenated and passed through several fully
connected layers, which use ReLU activations to generate
synthetic SQL queries. The generator can be mathematically
formulated as [29]:
G(z, y) =Dense k(ReLU (Concat (z, y)))→. .→Output Layer
where zis the latent noise vector and yis the label. The
output layer produces a vector of the same dimensionality as
the original SQL queries.
The critic D(x, y)receives real or generated SQL queries
and their corresponding labels.

7. CWGAN-GP Architectural Design for SQL Data Generation
Mathematical Formulation:
The generator G(z, y)takes a noise vector zsampled
from a normal distribution and a one-hot encoded label y.
These inputs are concatenated and passed through several fully
connected layers, which use ReLU activations to generate
synthetic SQL queries. The generator can be mathematically
formulated as [29]:
G(z, y) =Dense k(ReLU (Concat (z, y)))→. .→Output Layer
where zis the latent noise vector and yis the label. The
output layer produces a vector of the same dimensionality as
the original SQL queries.
The critic D(x, y)receives real or generated SQL queries
and their corresponding labels. The critic uses dense layers
with ReLU activations to estimate the Wasserstein distance,
a real-valued score that differentiates between real and fake
queries.

CWGAN-GP Architectural Design for SQL Data Generation
Mathematical Formulation:
The generator G(z, y)takes a noise vector zsampled
from a normal distribution and a one-hot encoded label y.
These inputs are concatenated and passed through several fully
connected layers, which use ReLU activations to generate
synthetic SQL queries. The generator can be mathematically
formulated as [29]:
G(z, y) =Dense k(ReLU (Concat (z, y)))→. .→Output Layer
where zis the latent noise vector and yis the label. The
output layer produces a vector of the same dimensionality as
the original SQL queries.
The critic D(x, y)receives real or generated SQL queries
and their corresponding labels. The critic uses dense layers
with ReLU activations to estimate the Wasserstein distance,
a real-valued score that differentiates between real and fake
queries. The critic is defined as Atienza [29]:
D(x, y) =Dense k(ReLU (Concat (x, y)))→.

The generator can be mathematically
formulated as [29]:
G(z, y) =Dense k(ReLU (Concat (z, y)))→. .→Output Layer
where zis the latent noise vector and yis the label. The
output layer produces a vector of the same dimensionality as
the original SQL queries.
The critic D(x, y)receives real or generated SQL queries
and their corresponding labels. The critic uses dense layers
with ReLU activations to estimate the Wasserstein distance,
a real-valued score that differentiates between real and fake
queries. The critic is defined as Atienza [29]:
D(x, y) =Dense k(ReLU (Concat (x, y)))→. .→Output Layer
where xis either the real or the generated SQL query.
To ensure the critic satisfies the Lipschitz constraint, a
gradient penalty term is added to the loss function.

.→Output Layer
where zis the latent noise vector and yis the label. The
output layer produces a vector of the same dimensionality as
the original SQL queries.
The critic D(x, y)receives real or generated SQL queries
and their corresponding labels. The critic uses dense layers
with ReLU activations to estimate the Wasserstein distance,
a real-valued score that differentiates between real and fake
queries. The critic is defined as Atienza [29]:
D(x, y) =Dense k(ReLU (Concat (x, y)))→. .→Output Layer
where xis either the real or the generated SQL query.
To ensure the critic satisfies the Lipschitz constraint, a
gradient penalty term is added to the loss function. The
gradient penalty is computed as follows:
LGP=λE 
(∥∇ˆxD(ˆx)∥2−1)2
where ˆxis an interpolation between real and fake data, and
λis a regularisation parameter controlling the contribution of
the gradient penalty.Loss Functions: The CWGAN-GP uses the Wasserstein
loss with gradient penalty for both the generator and the critic:
•Critic loss:
LCritic =E[D(xreal)]−E[D(xfake)]+λE 
(∥∇ˆxD(ˆx)∥2−1)2
The critic maximises the difference between its evaluation
of real queries xrealand generated queries xfake, while
minimising the gradient penalty term to enforce stability.
•Generator loss:
LGenerator =−E[D(xfake)]
The generator minimises this loss to create synthetic
queries that the critic struggles to differentiate from real
queries.
Fig.

The
output layer produces a vector of the same dimensionality as
the original SQL queries.
The critic D(x, y)receives real or generated SQL queries
and their corresponding labels. The critic uses dense layers
with ReLU activations to estimate the Wasserstein distance,
a real-valued score that differentiates between real and fake
queries. The critic is defined as Atienza [29]:
D(x, y) =Dense k(ReLU (Concat (x, y)))→. .→Output Layer
where xis either the real or the generated SQL query.
To ensure the critic satisfies the Lipschitz constraint, a
gradient penalty term is added to the loss function. The
gradient penalty is computed as follows:
LGP=λE 
(∥∇ˆxD(ˆx)∥2−1)2
where ˆxis an interpolation between real and fake data, and
λis a regularisation parameter controlling the contribution of
the gradient penalty.Loss Functions: The CWGAN-GP uses the Wasserstein
loss with gradient penalty for both the generator and the critic:
•Critic loss:
LCritic =E[D(xreal)]−E[D(xfake)]+λE 
(∥∇ˆxD(ˆx)∥2−1)2
The critic maximises the difference between its evaluation
of real queries xrealand generated queries xfake, while
minimising the gradient penalty term to enforce stability.
•Generator loss:
LGenerator =−E[D(xfake)]
The generator minimises this loss to create synthetic
queries that the critic struggles to differentiate from real
queries.
Fig. 8.

The critic uses dense layers
with ReLU activations to estimate the Wasserstein distance,
a real-valued score that differentiates between real and fake
queries. The critic is defined as Atienza [29]:
D(x, y) =Dense k(ReLU (Concat (x, y)))→. .→Output Layer
where xis either the real or the generated SQL query.
To ensure the critic satisfies the Lipschitz constraint, a
gradient penalty term is added to the loss function. The
gradient penalty is computed as follows:
LGP=λE 
(∥∇ˆxD(ˆx)∥2−1)2
where ˆxis an interpolation between real and fake data, and
λis a regularisation parameter controlling the contribution of
the gradient penalty.Loss Functions: The CWGAN-GP uses the Wasserstein
loss with gradient penalty for both the generator and the critic:
•Critic loss:
LCritic =E[D(xreal)]−E[D(xfake)]+λE 
(∥∇ˆxD(ˆx)∥2−1)2
The critic maximises the difference between its evaluation
of real queries xrealand generated queries xfake, while
minimising the gradient penalty term to enforce stability.
•Generator loss:
LGenerator =−E[D(xfake)]
The generator minimises this loss to create synthetic
queries that the critic struggles to differentiate from real
queries.
Fig. 8. CWGAN-GP Generator and Critic Losses with Gradient Penalty
Training and Optimisation: The training process alternates
between updating the critic and the generator:
•Critic update: The critic is updated using real and fake
SQL queries, with the gradient penalty applied to enforce
Lipschitz continuity.

The critic is defined as Atienza [29]:
D(x, y) =Dense k(ReLU (Concat (x, y)))→. .→Output Layer
where xis either the real or the generated SQL query.
To ensure the critic satisfies the Lipschitz constraint, a
gradient penalty term is added to the loss function. The
gradient penalty is computed as follows:
LGP=λE 
(∥∇ˆxD(ˆx)∥2−1)2
where ˆxis an interpolation between real and fake data, and
λis a regularisation parameter controlling the contribution of
the gradient penalty.Loss Functions: The CWGAN-GP uses the Wasserstein
loss with gradient penalty for both the generator and the critic:
•Critic loss:
LCritic =E[D(xreal)]−E[D(xfake)]+λE 
(∥∇ˆxD(ˆx)∥2−1)2
The critic maximises the difference between its evaluation
of real queries xrealand generated queries xfake, while
minimising the gradient penalty term to enforce stability.
•Generator loss:
LGenerator =−E[D(xfake)]
The generator minimises this loss to create synthetic
queries that the critic struggles to differentiate from real
queries.
Fig. 8. CWGAN-GP Generator and Critic Losses with Gradient Penalty
Training and Optimisation: The training process alternates
between updating the critic and the generator:
•Critic update: The critic is updated using real and fake
SQL queries, with the gradient penalty applied to enforce
Lipschitz continuity. For each generator update, the critic
is trained multiple times (in this case, ncritic = 2) to
ensure stability.
•Generator update: The generator is updated to minimise
the score of the critic on the generated SQL queries.
To fine-tune the CWGAN-GP model, two approaches were
employed:
•Bayesian Optimisation: Initially, Bayesian Optimisation
was used to explore the hyperparameter space, resulting
in minimal reconstruction loss.

.→Output Layer
where xis either the real or the generated SQL query.
To ensure the critic satisfies the Lipschitz constraint, a
gradient penalty term is added to the loss function. The
gradient penalty is computed as follows:
LGP=λE 
(∥∇ˆxD(ˆx)∥2−1)2
where ˆxis an interpolation between real and fake data, and
λis a regularisation parameter controlling the contribution of
the gradient penalty.Loss Functions: The CWGAN-GP uses the Wasserstein
loss with gradient penalty for both the generator and the critic:
•Critic loss:
LCritic =E[D(xreal)]−E[D(xfake)]+λE 
(∥∇ˆxD(ˆx)∥2−1)2
The critic maximises the difference between its evaluation
of real queries xrealand generated queries xfake, while
minimising the gradient penalty term to enforce stability.
•Generator loss:
LGenerator =−E[D(xfake)]
The generator minimises this loss to create synthetic
queries that the critic struggles to differentiate from real
queries.
Fig. 8. CWGAN-GP Generator and Critic Losses with Gradient Penalty
Training and Optimisation: The training process alternates
between updating the critic and the generator:
•Critic update: The critic is updated using real and fake
SQL queries, with the gradient penalty applied to enforce
Lipschitz continuity. For each generator update, the critic
is trained multiple times (in this case, ncritic = 2) to
ensure stability.
•Generator update: The generator is updated to minimise
the score of the critic on the generated SQL queries.
To fine-tune the CWGAN-GP model, two approaches were
employed:
•Bayesian Optimisation: Initially, Bayesian Optimisation
was used to explore the hyperparameter space, resulting
in minimal reconstruction loss. Hyperparameters such as
the number of layers, dropout rates, and learning rate
were tuned.
•Optuna Fine-Tuning: After the Bayesian phase, Optuna
was used to further fine-tune the model, exploring a
narrower and higher-potential search space.

The
gradient penalty is computed as follows:
LGP=λE 
(∥∇ˆxD(ˆx)∥2−1)2
where ˆxis an interpolation between real and fake data, and
λis a regularisation parameter controlling the contribution of
the gradient penalty.Loss Functions: The CWGAN-GP uses the Wasserstein
loss with gradient penalty for both the generator and the critic:
•Critic loss:
LCritic =E[D(xreal)]−E[D(xfake)]+λE 
(∥∇ˆxD(ˆx)∥2−1)2
The critic maximises the difference between its evaluation
of real queries xrealand generated queries xfake, while
minimising the gradient penalty term to enforce stability.
•Generator loss:
LGenerator =−E[D(xfake)]
The generator minimises this loss to create synthetic
queries that the critic struggles to differentiate from real
queries.
Fig. 8. CWGAN-GP Generator and Critic Losses with Gradient Penalty
Training and Optimisation: The training process alternates
between updating the critic and the generator:
•Critic update: The critic is updated using real and fake
SQL queries, with the gradient penalty applied to enforce
Lipschitz continuity. For each generator update, the critic
is trained multiple times (in this case, ncritic = 2) to
ensure stability.
•Generator update: The generator is updated to minimise
the score of the critic on the generated SQL queries.
To fine-tune the CWGAN-GP model, two approaches were
employed:
•Bayesian Optimisation: Initially, Bayesian Optimisation
was used to explore the hyperparameter space, resulting
in minimal reconstruction loss. Hyperparameters such as
the number of layers, dropout rates, and learning rate
were tuned.
•Optuna Fine-Tuning: After the Bayesian phase, Optuna
was used to further fine-tune the model, exploring a
narrower and higher-potential search space. The dynamic
exploration as provided by Optuna, combined with its
pruning mechanism, enabled efficient fine-tuning by halt-
ing underperforming trials early.
Evaluation Metrics: The performance of the CWGAN-
GP model was evaluated using various metrics, including
Mean Squared Error (MSE), R² score, BLEU score, Cosine
similarity, and Lowenstein distance.

8. CWGAN-GP Generator and Critic Losses with Gradient Penalty
Training and Optimisation: The training process alternates
between updating the critic and the generator:
•Critic update: The critic is updated using real and fake
SQL queries, with the gradient penalty applied to enforce
Lipschitz continuity. For each generator update, the critic
is trained multiple times (in this case, ncritic = 2) to
ensure stability.
•Generator update: The generator is updated to minimise
the score of the critic on the generated SQL queries.
To fine-tune the CWGAN-GP model, two approaches were
employed:
•Bayesian Optimisation: Initially, Bayesian Optimisation
was used to explore the hyperparameter space, resulting
in minimal reconstruction loss. Hyperparameters such as
the number of layers, dropout rates, and learning rate
were tuned.
•Optuna Fine-Tuning: After the Bayesian phase, Optuna
was used to further fine-tune the model, exploring a
narrower and higher-potential search space. The dynamic
exploration as provided by Optuna, combined with its
pruning mechanism, enabled efficient fine-tuning by halt-
ing underperforming trials early.
Evaluation Metrics: The performance of the CWGAN-
GP model was evaluated using various metrics, including
Mean Squared Error (MSE), R² score, BLEU score, Cosine
similarity, and Lowenstein distance. These metrics were used
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 7
to assess how closely the generated SQL queries resembled
real SQL queries.

CWGAN-GP Generator and Critic Losses with Gradient Penalty
Training and Optimisation: The training process alternates
between updating the critic and the generator:
•Critic update: The critic is updated using real and fake
SQL queries, with the gradient penalty applied to enforce
Lipschitz continuity. For each generator update, the critic
is trained multiple times (in this case, ncritic = 2) to
ensure stability.
•Generator update: The generator is updated to minimise
the score of the critic on the generated SQL queries.
To fine-tune the CWGAN-GP model, two approaches were
employed:
•Bayesian Optimisation: Initially, Bayesian Optimisation
was used to explore the hyperparameter space, resulting
in minimal reconstruction loss. Hyperparameters such as
the number of layers, dropout rates, and learning rate
were tuned.
•Optuna Fine-Tuning: After the Bayesian phase, Optuna
was used to further fine-tune the model, exploring a
narrower and higher-potential search space. The dynamic
exploration as provided by Optuna, combined with its
pruning mechanism, enabled efficient fine-tuning by halt-
ing underperforming trials early.
Evaluation Metrics: The performance of the CWGAN-
GP model was evaluated using various metrics, including
Mean Squared Error (MSE), R² score, BLEU score, Cosine
similarity, and Lowenstein distance. These metrics were used
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 7
to assess how closely the generated SQL queries resembled
real SQL queries. Furthermore, Principal Component Analysis
(PCA) was employed to visualise the overlap between real and
synthetic data, confirming the CWGAN-GP model’s ability to
generate realistic, high-quality SQL queries.
The results demonstrated that the CWGAN-GP model sig-
nificantly improved the diversity and quality of the synthetic
SQL queries, providing a robust solution for SQL injection
detection systems.
E.

For each generator update, the critic
is trained multiple times (in this case, ncritic = 2) to
ensure stability.
•Generator update: The generator is updated to minimise
the score of the critic on the generated SQL queries.
To fine-tune the CWGAN-GP model, two approaches were
employed:
•Bayesian Optimisation: Initially, Bayesian Optimisation
was used to explore the hyperparameter space, resulting
in minimal reconstruction loss. Hyperparameters such as
the number of layers, dropout rates, and learning rate
were tuned.
•Optuna Fine-Tuning: After the Bayesian phase, Optuna
was used to further fine-tune the model, exploring a
narrower and higher-potential search space. The dynamic
exploration as provided by Optuna, combined with its
pruning mechanism, enabled efficient fine-tuning by halt-
ing underperforming trials early.
Evaluation Metrics: The performance of the CWGAN-
GP model was evaluated using various metrics, including
Mean Squared Error (MSE), R² score, BLEU score, Cosine
similarity, and Lowenstein distance. These metrics were used
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 7
to assess how closely the generated SQL queries resembled
real SQL queries. Furthermore, Principal Component Analysis
(PCA) was employed to visualise the overlap between real and
synthetic data, confirming the CWGAN-GP model’s ability to
generate realistic, high-quality SQL queries.
The results demonstrated that the CWGAN-GP model sig-
nificantly improved the diversity and quality of the synthetic
SQL queries, providing a robust solution for SQL injection
detection systems.
E. Pseudo-Labelling of Synthetic Data
To refine the synthetic SQL data as generated by U-Net and
CWGAN-GP, pseudo-labelling was employed.

Hyperparameters such as
the number of layers, dropout rates, and learning rate
were tuned.
•Optuna Fine-Tuning: After the Bayesian phase, Optuna
was used to further fine-tune the model, exploring a
narrower and higher-potential search space. The dynamic
exploration as provided by Optuna, combined with its
pruning mechanism, enabled efficient fine-tuning by halt-
ing underperforming trials early.
Evaluation Metrics: The performance of the CWGAN-
GP model was evaluated using various metrics, including
Mean Squared Error (MSE), R² score, BLEU score, Cosine
similarity, and Lowenstein distance. These metrics were used
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 7
to assess how closely the generated SQL queries resembled
real SQL queries. Furthermore, Principal Component Analysis
(PCA) was employed to visualise the overlap between real and
synthetic data, confirming the CWGAN-GP model’s ability to
generate realistic, high-quality SQL queries.
The results demonstrated that the CWGAN-GP model sig-
nificantly improved the diversity and quality of the synthetic
SQL queries, providing a robust solution for SQL injection
detection systems.
E. Pseudo-Labelling of Synthetic Data
To refine the synthetic SQL data as generated by U-Net and
CWGAN-GP, pseudo-labelling was employed. This method
involved reducing the dimensionality of the high-dimensional
data using Principal Component Analysis (PCA) and applying
KMeans clustering to assign pseudo-labels.
PCA for Dimensionality Reduction : Principal Component
Analysis (PCA) was applied to reduce the dimensions of
the synthetic data to two principal components for better
visual representation and easier clustering.

The dynamic
exploration as provided by Optuna, combined with its
pruning mechanism, enabled efficient fine-tuning by halt-
ing underperforming trials early.
Evaluation Metrics: The performance of the CWGAN-
GP model was evaluated using various metrics, including
Mean Squared Error (MSE), R² score, BLEU score, Cosine
similarity, and Lowenstein distance. These metrics were used
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 7
to assess how closely the generated SQL queries resembled
real SQL queries. Furthermore, Principal Component Analysis
(PCA) was employed to visualise the overlap between real and
synthetic data, confirming the CWGAN-GP model’s ability to
generate realistic, high-quality SQL queries.
The results demonstrated that the CWGAN-GP model sig-
nificantly improved the diversity and quality of the synthetic
SQL queries, providing a robust solution for SQL injection
detection systems.
E. Pseudo-Labelling of Synthetic Data
To refine the synthetic SQL data as generated by U-Net and
CWGAN-GP, pseudo-labelling was employed. This method
involved reducing the dimensionality of the high-dimensional
data using Principal Component Analysis (PCA) and applying
KMeans clustering to assign pseudo-labels.
PCA for Dimensionality Reduction : Principal Component
Analysis (PCA) was applied to reduce the dimensions of
the synthetic data to two principal components for better
visual representation and easier clustering. Mathematically, the
transformation can be described as:
Z=XW
where Xrepresents the original high-dimensional data and
Wis the projection matrix consisting of the top two eigenvec-
tors of the covariance matrix of the data.

These metrics were used
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 7
to assess how closely the generated SQL queries resembled
real SQL queries. Furthermore, Principal Component Analysis
(PCA) was employed to visualise the overlap between real and
synthetic data, confirming the CWGAN-GP model’s ability to
generate realistic, high-quality SQL queries.
The results demonstrated that the CWGAN-GP model sig-
nificantly improved the diversity and quality of the synthetic
SQL queries, providing a robust solution for SQL injection
detection systems.
E. Pseudo-Labelling of Synthetic Data
To refine the synthetic SQL data as generated by U-Net and
CWGAN-GP, pseudo-labelling was employed. This method
involved reducing the dimensionality of the high-dimensional
data using Principal Component Analysis (PCA) and applying
KMeans clustering to assign pseudo-labels.
PCA for Dimensionality Reduction : Principal Component
Analysis (PCA) was applied to reduce the dimensions of
the synthetic data to two principal components for better
visual representation and easier clustering. Mathematically, the
transformation can be described as:
Z=XW
where Xrepresents the original high-dimensional data and
Wis the projection matrix consisting of the top two eigenvec-
tors of the covariance matrix of the data. This transformation
enabled a clear separation of the data into clusters, facilitating
the next step of clustering and pseudo-labelling.
KMeans Clustering for Pseudo-Labelling : Once the data
was reduced to two dimensions, KMeans clustering was per-
formed to assign pseudo-labels.

Furthermore, Principal Component Analysis
(PCA) was employed to visualise the overlap between real and
synthetic data, confirming the CWGAN-GP model’s ability to
generate realistic, high-quality SQL queries.
The results demonstrated that the CWGAN-GP model sig-
nificantly improved the diversity and quality of the synthetic
SQL queries, providing a robust solution for SQL injection
detection systems.
E. Pseudo-Labelling of Synthetic Data
To refine the synthetic SQL data as generated by U-Net and
CWGAN-GP, pseudo-labelling was employed. This method
involved reducing the dimensionality of the high-dimensional
data using Principal Component Analysis (PCA) and applying
KMeans clustering to assign pseudo-labels.
PCA for Dimensionality Reduction : Principal Component
Analysis (PCA) was applied to reduce the dimensions of
the synthetic data to two principal components for better
visual representation and easier clustering. Mathematically, the
transformation can be described as:
Z=XW
where Xrepresents the original high-dimensional data and
Wis the projection matrix consisting of the top two eigenvec-
tors of the covariance matrix of the data. This transformation
enabled a clear separation of the data into clusters, facilitating
the next step of clustering and pseudo-labelling.
KMeans Clustering for Pseudo-Labelling : Once the data
was reduced to two dimensions, KMeans clustering was per-
formed to assign pseudo-labels. The KMeans algorithm min-
imised the Within-Cluster Sum of Squares (WCSS), defined
as:
WCSS =kX
i=1X
x∈Ci∥x−µi∥2
where kis the number of clusters (in this case, k= 2),
Cirepresents the set of points assigned to cluster i,µiis
the centroid of cluster i, and xis each data point.

Pseudo-Labelling of Synthetic Data
To refine the synthetic SQL data as generated by U-Net and
CWGAN-GP, pseudo-labelling was employed. This method
involved reducing the dimensionality of the high-dimensional
data using Principal Component Analysis (PCA) and applying
KMeans clustering to assign pseudo-labels.
PCA for Dimensionality Reduction : Principal Component
Analysis (PCA) was applied to reduce the dimensions of
the synthetic data to two principal components for better
visual representation and easier clustering. Mathematically, the
transformation can be described as:
Z=XW
where Xrepresents the original high-dimensional data and
Wis the projection matrix consisting of the top two eigenvec-
tors of the covariance matrix of the data. This transformation
enabled a clear separation of the data into clusters, facilitating
the next step of clustering and pseudo-labelling.
KMeans Clustering for Pseudo-Labelling : Once the data
was reduced to two dimensions, KMeans clustering was per-
formed to assign pseudo-labels. The KMeans algorithm min-
imised the Within-Cluster Sum of Squares (WCSS), defined
as:
WCSS =kX
i=1X
x∈Ci∥x−µi∥2
where kis the number of clusters (in this case, k= 2),
Cirepresents the set of points assigned to cluster i,µiis
the centroid of cluster i, and xis each data point. The
KMeans algorithm assigned pseudo-labels corresponding to
benign (Class 0) and malicious (Class 1) SQL queries.

This method
involved reducing the dimensionality of the high-dimensional
data using Principal Component Analysis (PCA) and applying
KMeans clustering to assign pseudo-labels.
PCA for Dimensionality Reduction : Principal Component
Analysis (PCA) was applied to reduce the dimensions of
the synthetic data to two principal components for better
visual representation and easier clustering. Mathematically, the
transformation can be described as:
Z=XW
where Xrepresents the original high-dimensional data and
Wis the projection matrix consisting of the top two eigenvec-
tors of the covariance matrix of the data. This transformation
enabled a clear separation of the data into clusters, facilitating
the next step of clustering and pseudo-labelling.
KMeans Clustering for Pseudo-Labelling : Once the data
was reduced to two dimensions, KMeans clustering was per-
formed to assign pseudo-labels. The KMeans algorithm min-
imised the Within-Cluster Sum of Squares (WCSS), defined
as:
WCSS =kX
i=1X
x∈Ci∥x−µi∥2
where kis the number of clusters (in this case, k= 2),
Cirepresents the set of points assigned to cluster i,µiis
the centroid of cluster i, and xis each data point. The
KMeans algorithm assigned pseudo-labels corresponding to
benign (Class 0) and malicious (Class 1) SQL queries. The
labelling was based on the spread of the data: benign queries
exhibited a lower spread, while malicious queries displayed
a higher spread in the feature space.

Mathematically, the
transformation can be described as:
Z=XW
where Xrepresents the original high-dimensional data and
Wis the projection matrix consisting of the top two eigenvec-
tors of the covariance matrix of the data. This transformation
enabled a clear separation of the data into clusters, facilitating
the next step of clustering and pseudo-labelling.
KMeans Clustering for Pseudo-Labelling : Once the data
was reduced to two dimensions, KMeans clustering was per-
formed to assign pseudo-labels. The KMeans algorithm min-
imised the Within-Cluster Sum of Squares (WCSS), defined
as:
WCSS =kX
i=1X
x∈Ci∥x−µi∥2
where kis the number of clusters (in this case, k= 2),
Cirepresents the set of points assigned to cluster i,µiis
the centroid of cluster i, and xis each data point. The
KMeans algorithm assigned pseudo-labels corresponding to
benign (Class 0) and malicious (Class 1) SQL queries. The
labelling was based on the spread of the data: benign queries
exhibited a lower spread, while malicious queries displayed
a higher spread in the feature space. This distinction in the
data distribution enabled the clustering algorithm to effectively
separate benign from malicious queries.

This transformation
enabled a clear separation of the data into clusters, facilitating
the next step of clustering and pseudo-labelling.
KMeans Clustering for Pseudo-Labelling : Once the data
was reduced to two dimensions, KMeans clustering was per-
formed to assign pseudo-labels. The KMeans algorithm min-
imised the Within-Cluster Sum of Squares (WCSS), defined
as:
WCSS =kX
i=1X
x∈Ci∥x−µi∥2
where kis the number of clusters (in this case, k= 2),
Cirepresents the set of points assigned to cluster i,µiis
the centroid of cluster i, and xis each data point. The
KMeans algorithm assigned pseudo-labels corresponding to
benign (Class 0) and malicious (Class 1) SQL queries. The
labelling was based on the spread of the data: benign queries
exhibited a lower spread, while malicious queries displayed
a higher spread in the feature space. This distinction in the
data distribution enabled the clustering algorithm to effectively
separate benign from malicious queries. By leveraging these
differences in data spread, the KMeans algorithm enabled
the accurate classification of synthetic data into the relevant
categories, facilitating its use for training machine learning
models.
F.

The KMeans algorithm min-
imised the Within-Cluster Sum of Squares (WCSS), defined
as:
WCSS =kX
i=1X
x∈Ci∥x−µi∥2
where kis the number of clusters (in this case, k= 2),
Cirepresents the set of points assigned to cluster i,µiis
the centroid of cluster i, and xis each data point. The
KMeans algorithm assigned pseudo-labels corresponding to
benign (Class 0) and malicious (Class 1) SQL queries. The
labelling was based on the spread of the data: benign queries
exhibited a lower spread, while malicious queries displayed
a higher spread in the feature space. This distinction in the
data distribution enabled the clustering algorithm to effectively
separate benign from malicious queries. By leveraging these
differences in data spread, the KMeans algorithm enabled
the accurate classification of synthetic data into the relevant
categories, facilitating its use for training machine learning
models.
F. Evaluation of Models on Hybrid Data
To further enhance model performance, a hybrid dataset
was created by combining real SQL data with pseudo-labelledsynthetic data as generated by U-Net and CWGAN-GP mod-
els.

The
KMeans algorithm assigned pseudo-labels corresponding to
benign (Class 0) and malicious (Class 1) SQL queries. The
labelling was based on the spread of the data: benign queries
exhibited a lower spread, while malicious queries displayed
a higher spread in the feature space. This distinction in the
data distribution enabled the clustering algorithm to effectively
separate benign from malicious queries. By leveraging these
differences in data spread, the KMeans algorithm enabled
the accurate classification of synthetic data into the relevant
categories, facilitating its use for training machine learning
models.
F. Evaluation of Models on Hybrid Data
To further enhance model performance, a hybrid dataset
was created by combining real SQL data with pseudo-labelledsynthetic data as generated by U-Net and CWGAN-GP mod-
els. The following steps were performed to evaluate the
performance of the model:
Hybrid Dataset Composition : The combined dataset
Dcombined was created by mixing real data with synthetic data
from U-Net and CWGAN-GP in different proportions.

The
labelling was based on the spread of the data: benign queries
exhibited a lower spread, while malicious queries displayed
a higher spread in the feature space. This distinction in the
data distribution enabled the clustering algorithm to effectively
separate benign from malicious queries. By leveraging these
differences in data spread, the KMeans algorithm enabled
the accurate classification of synthetic data into the relevant
categories, facilitating its use for training machine learning
models.
F. Evaluation of Models on Hybrid Data
To further enhance model performance, a hybrid dataset
was created by combining real SQL data with pseudo-labelledsynthetic data as generated by U-Net and CWGAN-GP mod-
els. The following steps were performed to evaluate the
performance of the model:
Hybrid Dataset Composition : The combined dataset
Dcombined was created by mixing real data with synthetic data
from U-Net and CWGAN-GP in different proportions. The
combined dataset is formulated as follows:
Dcombined =Dreal∪(DU-Net×p1)∪(DCWGAN-GP ×p2)
where Dreal represents the real dataset, DU-Net and
DCWGAN-GP are the synthetic datasets generated by U-Net and
CWGAN-GP, and p1andp2are the proportions of synthetic
data from each model.

This distinction in the
data distribution enabled the clustering algorithm to effectively
separate benign from malicious queries. By leveraging these
differences in data spread, the KMeans algorithm enabled
the accurate classification of synthetic data into the relevant
categories, facilitating its use for training machine learning
models.
F. Evaluation of Models on Hybrid Data
To further enhance model performance, a hybrid dataset
was created by combining real SQL data with pseudo-labelledsynthetic data as generated by U-Net and CWGAN-GP mod-
els. The following steps were performed to evaluate the
performance of the model:
Hybrid Dataset Composition : The combined dataset
Dcombined was created by mixing real data with synthetic data
from U-Net and CWGAN-GP in different proportions. The
combined dataset is formulated as follows:
Dcombined =Dreal∪(DU-Net×p1)∪(DCWGAN-GP ×p2)
where Dreal represents the real dataset, DU-Net and
DCWGAN-GP are the synthetic datasets generated by U-Net and
CWGAN-GP, and p1andp2are the proportions of synthetic
data from each model. By adjusting p1andp2, different hybrid
dataset compositions were tested to optimise the training data
balance between real and synthetic data.
Cross-Validation of Dataset Combinations : Stratified K-
Fold Cross-Validation was employed to evaluate different
combinations of real and synthetic data while preserving class
distribution across all folds.

By leveraging these
differences in data spread, the KMeans algorithm enabled
the accurate classification of synthetic data into the relevant
categories, facilitating its use for training machine learning
models.
F. Evaluation of Models on Hybrid Data
To further enhance model performance, a hybrid dataset
was created by combining real SQL data with pseudo-labelledsynthetic data as generated by U-Net and CWGAN-GP mod-
els. The following steps were performed to evaluate the
performance of the model:
Hybrid Dataset Composition : The combined dataset
Dcombined was created by mixing real data with synthetic data
from U-Net and CWGAN-GP in different proportions. The
combined dataset is formulated as follows:
Dcombined =Dreal∪(DU-Net×p1)∪(DCWGAN-GP ×p2)
where Dreal represents the real dataset, DU-Net and
DCWGAN-GP are the synthetic datasets generated by U-Net and
CWGAN-GP, and p1andp2are the proportions of synthetic
data from each model. By adjusting p1andp2, different hybrid
dataset compositions were tested to optimise the training data
balance between real and synthetic data.
Cross-Validation of Dataset Combinations : Stratified K-
Fold Cross-Validation was employed to evaluate different
combinations of real and synthetic data while preserving class
distribution across all folds. This method ensured that the
performance of the model was evaluated consistently across
various splits of the data.

Evaluation of Models on Hybrid Data
To further enhance model performance, a hybrid dataset
was created by combining real SQL data with pseudo-labelledsynthetic data as generated by U-Net and CWGAN-GP mod-
els. The following steps were performed to evaluate the
performance of the model:
Hybrid Dataset Composition : The combined dataset
Dcombined was created by mixing real data with synthetic data
from U-Net and CWGAN-GP in different proportions. The
combined dataset is formulated as follows:
Dcombined =Dreal∪(DU-Net×p1)∪(DCWGAN-GP ×p2)
where Dreal represents the real dataset, DU-Net and
DCWGAN-GP are the synthetic datasets generated by U-Net and
CWGAN-GP, and p1andp2are the proportions of synthetic
data from each model. By adjusting p1andp2, different hybrid
dataset compositions were tested to optimise the training data
balance between real and synthetic data.
Cross-Validation of Dataset Combinations : Stratified K-
Fold Cross-Validation was employed to evaluate different
combinations of real and synthetic data while preserving class
distribution across all folds. This method ensured that the
performance of the model was evaluated consistently across
various splits of the data. The performance was measured
using two key metrics:
Accuracy =True Positives +True Negatives
Total Samples
Sensitivity =True Positives
True Positives +False Negatives
These metrics provided insight into the ability of the model
to correctly classify SQLi attacks while minimising false nega-
tives.

The following steps were performed to evaluate the
performance of the model:
Hybrid Dataset Composition : The combined dataset
Dcombined was created by mixing real data with synthetic data
from U-Net and CWGAN-GP in different proportions. The
combined dataset is formulated as follows:
Dcombined =Dreal∪(DU-Net×p1)∪(DCWGAN-GP ×p2)
where Dreal represents the real dataset, DU-Net and
DCWGAN-GP are the synthetic datasets generated by U-Net and
CWGAN-GP, and p1andp2are the proportions of synthetic
data from each model. By adjusting p1andp2, different hybrid
dataset compositions were tested to optimise the training data
balance between real and synthetic data.
Cross-Validation of Dataset Combinations : Stratified K-
Fold Cross-Validation was employed to evaluate different
combinations of real and synthetic data while preserving class
distribution across all folds. This method ensured that the
performance of the model was evaluated consistently across
various splits of the data. The performance was measured
using two key metrics:
Accuracy =True Positives +True Negatives
Total Samples
Sensitivity =True Positives
True Positives +False Negatives
These metrics provided insight into the ability of the model
to correctly classify SQLi attacks while minimising false nega-
tives. The cross-validation process helped identify the optimal
proportion of real and synthetic data for maximising model
performance, ensuring a robust balance between precision and
recall.
G.

The
combined dataset is formulated as follows:
Dcombined =Dreal∪(DU-Net×p1)∪(DCWGAN-GP ×p2)
where Dreal represents the real dataset, DU-Net and
DCWGAN-GP are the synthetic datasets generated by U-Net and
CWGAN-GP, and p1andp2are the proportions of synthetic
data from each model. By adjusting p1andp2, different hybrid
dataset compositions were tested to optimise the training data
balance between real and synthetic data.
Cross-Validation of Dataset Combinations : Stratified K-
Fold Cross-Validation was employed to evaluate different
combinations of real and synthetic data while preserving class
distribution across all folds. This method ensured that the
performance of the model was evaluated consistently across
various splits of the data. The performance was measured
using two key metrics:
Accuracy =True Positives +True Negatives
Total Samples
Sensitivity =True Positives
True Positives +False Negatives
These metrics provided insight into the ability of the model
to correctly classify SQLi attacks while minimising false nega-
tives. The cross-validation process helped identify the optimal
proportion of real and synthetic data for maximising model
performance, ensuring a robust balance between precision and
recall.
G. Final Model Evaluation
After identifying the best dataset combination, the XGBoost
classifier was trained on the combined dataset.

By adjusting p1andp2, different hybrid
dataset compositions were tested to optimise the training data
balance between real and synthetic data.
Cross-Validation of Dataset Combinations : Stratified K-
Fold Cross-Validation was employed to evaluate different
combinations of real and synthetic data while preserving class
distribution across all folds. This method ensured that the
performance of the model was evaluated consistently across
various splits of the data. The performance was measured
using two key metrics:
Accuracy =True Positives +True Negatives
Total Samples
Sensitivity =True Positives
True Positives +False Negatives
These metrics provided insight into the ability of the model
to correctly classify SQLi attacks while minimising false nega-
tives. The cross-validation process helped identify the optimal
proportion of real and synthetic data for maximising model
performance, ensuring a robust balance between precision and
recall.
G. Final Model Evaluation
After identifying the best dataset combination, the XGBoost
classifier was trained on the combined dataset. XGBoost was
selected for its high efficiency and scalability, especially in
dealing with structured data such as SQL queries.

This method ensured that the
performance of the model was evaluated consistently across
various splits of the data. The performance was measured
using two key metrics:
Accuracy =True Positives +True Negatives
Total Samples
Sensitivity =True Positives
True Positives +False Negatives
These metrics provided insight into the ability of the model
to correctly classify SQLi attacks while minimising false nega-
tives. The cross-validation process helped identify the optimal
proportion of real and synthetic data for maximising model
performance, ensuring a robust balance between precision and
recall.
G. Final Model Evaluation
After identifying the best dataset combination, the XGBoost
classifier was trained on the combined dataset. XGBoost was
selected for its high efficiency and scalability, especially in
dealing with structured data such as SQL queries. The final
model used logistic loss as the objective function, defined as:
LXGBoost =−1
NNX
i=1[yilog ˆyi+ (1−yi) log(1 −ˆyi)]
where Nis the total number of samples, yiis the true label
for sample i, and ˆyiis the predicted probability for sample
i.

The performance was measured
using two key metrics:
Accuracy =True Positives +True Negatives
Total Samples
Sensitivity =True Positives
True Positives +False Negatives
These metrics provided insight into the ability of the model
to correctly classify SQLi attacks while minimising false nega-
tives. The cross-validation process helped identify the optimal
proportion of real and synthetic data for maximising model
performance, ensuring a robust balance between precision and
recall.
G. Final Model Evaluation
After identifying the best dataset combination, the XGBoost
classifier was trained on the combined dataset. XGBoost was
selected for its high efficiency and scalability, especially in
dealing with structured data such as SQL queries. The final
model used logistic loss as the objective function, defined as:
LXGBoost =−1
NNX
i=1[yilog ˆyi+ (1−yi) log(1 −ˆyi)]
where Nis the total number of samples, yiis the true label
for sample i, and ˆyiis the predicted probability for sample
i. This loss function optimises the classification model by
minimising the error in predicting the correct labels for both
benign and malicious queries.
The trained XGBoost model was evaluated on the test
set using multiple metrics, including accuracy, sensitivity,
precision, recall, and F1-score.
The results demonstrated that the combination of real and
pseudo-labelled synthetic data improved the ability of the
model to generalise to new, unseen SQL queries.

The cross-validation process helped identify the optimal
proportion of real and synthetic data for maximising model
performance, ensuring a robust balance between precision and
recall.
G. Final Model Evaluation
After identifying the best dataset combination, the XGBoost
classifier was trained on the combined dataset. XGBoost was
selected for its high efficiency and scalability, especially in
dealing with structured data such as SQL queries. The final
model used logistic loss as the objective function, defined as:
LXGBoost =−1
NNX
i=1[yilog ˆyi+ (1−yi) log(1 −ˆyi)]
where Nis the total number of samples, yiis the true label
for sample i, and ˆyiis the predicted probability for sample
i. This loss function optimises the classification model by
minimising the error in predicting the correct labels for both
benign and malicious queries.
The trained XGBoost model was evaluated on the test
set using multiple metrics, including accuracy, sensitivity,
precision, recall, and F1-score.
The results demonstrated that the combination of real and
pseudo-labelled synthetic data improved the ability of the
model to generalise to new, unseen SQL queries. The final
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 8
XGBoost model achieved high accuracy, sensitivity, and pre-
cision, indicating its effectiveness in SQL injection detection
across diverse attack types.
IV.RESULTS AND ANALYSIS
In this section, the performance of several machine learning
models trained on V AE-encoded SQL data is evaluated for
detecting SQL Injection Attacks (SQLIA).

Final Model Evaluation
After identifying the best dataset combination, the XGBoost
classifier was trained on the combined dataset. XGBoost was
selected for its high efficiency and scalability, especially in
dealing with structured data such as SQL queries. The final
model used logistic loss as the objective function, defined as:
LXGBoost =−1
NNX
i=1[yilog ˆyi+ (1−yi) log(1 −ˆyi)]
where Nis the total number of samples, yiis the true label
for sample i, and ˆyiis the predicted probability for sample
i. This loss function optimises the classification model by
minimising the error in predicting the correct labels for both
benign and malicious queries.
The trained XGBoost model was evaluated on the test
set using multiple metrics, including accuracy, sensitivity,
precision, recall, and F1-score.
The results demonstrated that the combination of real and
pseudo-labelled synthetic data improved the ability of the
model to generalise to new, unseen SQL queries. The final
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 8
XGBoost model achieved high accuracy, sensitivity, and pre-
cision, indicating its effectiveness in SQL injection detection
across diverse attack types.
IV.RESULTS AND ANALYSIS
In this section, the performance of several machine learning
models trained on V AE-encoded SQL data is evaluated for
detecting SQL Injection Attacks (SQLIA). The models tested
include XGBoost, LightGBM, Random Forest, K-Nearest
Neighbors (KNN), Neural Networks, Logistic Regression,
Support Vector Classifier (SVC), and Naive Bayes.

XGBoost was
selected for its high efficiency and scalability, especially in
dealing with structured data such as SQL queries. The final
model used logistic loss as the objective function, defined as:
LXGBoost =−1
NNX
i=1[yilog ˆyi+ (1−yi) log(1 −ˆyi)]
where Nis the total number of samples, yiis the true label
for sample i, and ˆyiis the predicted probability for sample
i. This loss function optimises the classification model by
minimising the error in predicting the correct labels for both
benign and malicious queries.
The trained XGBoost model was evaluated on the test
set using multiple metrics, including accuracy, sensitivity,
precision, recall, and F1-score.
The results demonstrated that the combination of real and
pseudo-labelled synthetic data improved the ability of the
model to generalise to new, unseen SQL queries. The final
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 8
XGBoost model achieved high accuracy, sensitivity, and pre-
cision, indicating its effectiveness in SQL injection detection
across diverse attack types.
IV.RESULTS AND ANALYSIS
In this section, the performance of several machine learning
models trained on V AE-encoded SQL data is evaluated for
detecting SQL Injection Attacks (SQLIA). The models tested
include XGBoost, LightGBM, Random Forest, K-Nearest
Neighbors (KNN), Neural Networks, Logistic Regression,
Support Vector Classifier (SVC), and Naive Bayes. The evalu-
ation focuses on metrics such as accuracy, precision, recall, F1-
score, and sensitivity for both benign (Class 0) and malicious
(Class 1) queries.
A.

The final
model used logistic loss as the objective function, defined as:
LXGBoost =−1
NNX
i=1[yilog ˆyi+ (1−yi) log(1 −ˆyi)]
where Nis the total number of samples, yiis the true label
for sample i, and ˆyiis the predicted probability for sample
i. This loss function optimises the classification model by
minimising the error in predicting the correct labels for both
benign and malicious queries.
The trained XGBoost model was evaluated on the test
set using multiple metrics, including accuracy, sensitivity,
precision, recall, and F1-score.
The results demonstrated that the combination of real and
pseudo-labelled synthetic data improved the ability of the
model to generalise to new, unseen SQL queries. The final
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 8
XGBoost model achieved high accuracy, sensitivity, and pre-
cision, indicating its effectiveness in SQL injection detection
across diverse attack types.
IV.RESULTS AND ANALYSIS
In this section, the performance of several machine learning
models trained on V AE-encoded SQL data is evaluated for
detecting SQL Injection Attacks (SQLIA). The models tested
include XGBoost, LightGBM, Random Forest, K-Nearest
Neighbors (KNN), Neural Networks, Logistic Regression,
Support Vector Classifier (SVC), and Naive Bayes. The evalu-
ation focuses on metrics such as accuracy, precision, recall, F1-
score, and sensitivity for both benign (Class 0) and malicious
(Class 1) queries.
A. Classification Metrics
Several standard classification metrics were used to thor-
oughly assess the performance of the models.

This loss function optimises the classification model by
minimising the error in predicting the correct labels for both
benign and malicious queries.
The trained XGBoost model was evaluated on the test
set using multiple metrics, including accuracy, sensitivity,
precision, recall, and F1-score.
The results demonstrated that the combination of real and
pseudo-labelled synthetic data improved the ability of the
model to generalise to new, unseen SQL queries. The final
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 8
XGBoost model achieved high accuracy, sensitivity, and pre-
cision, indicating its effectiveness in SQL injection detection
across diverse attack types.
IV.RESULTS AND ANALYSIS
In this section, the performance of several machine learning
models trained on V AE-encoded SQL data is evaluated for
detecting SQL Injection Attacks (SQLIA). The models tested
include XGBoost, LightGBM, Random Forest, K-Nearest
Neighbors (KNN), Neural Networks, Logistic Regression,
Support Vector Classifier (SVC), and Naive Bayes. The evalu-
ation focuses on metrics such as accuracy, precision, recall, F1-
score, and sensitivity for both benign (Class 0) and malicious
(Class 1) queries.
A. Classification Metrics
Several standard classification metrics were used to thor-
oughly assess the performance of the models. These metrics
provide valuable insights into how each model predicts benign
(Class 0) and malicious (Class 1) SQL queries.

The final
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 8
XGBoost model achieved high accuracy, sensitivity, and pre-
cision, indicating its effectiveness in SQL injection detection
across diverse attack types.
IV.RESULTS AND ANALYSIS
In this section, the performance of several machine learning
models trained on V AE-encoded SQL data is evaluated for
detecting SQL Injection Attacks (SQLIA). The models tested
include XGBoost, LightGBM, Random Forest, K-Nearest
Neighbors (KNN), Neural Networks, Logistic Regression,
Support Vector Classifier (SVC), and Naive Bayes. The evalu-
ation focuses on metrics such as accuracy, precision, recall, F1-
score, and sensitivity for both benign (Class 0) and malicious
(Class 1) queries.
A. Classification Metrics
Several standard classification metrics were used to thor-
oughly assess the performance of the models. These metrics
provide valuable insights into how each model predicts benign
(Class 0) and malicious (Class 1) SQL queries. The following
metrics were calculated for each model:
TABLE I
CLASSIFICATION METRICS AND FORMULAS
Metric Formula Description
AccuracyTP+TN
TP+TN+FP+FNProportion of correct predic-
tions out of all predictions
PrecisionTP
TP+FPProportion of positive predic-
tions that were correct
RecallTP
TP+FNProportion of actual positives
correctly predicted (Sensitivity
for Class 1)
F1-Score 2×Precision ×Recall
Precision +RecallHarmonic mean of precision
and recall
SensitivityTP Class 1
TP Class 1+FN Class 1Sensitivity is equivalent to re-
call for Class 1
The performance of various machine learning algorithms
was evaluated based on their ability to detect SQL Injection
Attacks (SQLIA).
Fig.

The models tested
include XGBoost, LightGBM, Random Forest, K-Nearest
Neighbors (KNN), Neural Networks, Logistic Regression,
Support Vector Classifier (SVC), and Naive Bayes. The evalu-
ation focuses on metrics such as accuracy, precision, recall, F1-
score, and sensitivity for both benign (Class 0) and malicious
(Class 1) queries.
A. Classification Metrics
Several standard classification metrics were used to thor-
oughly assess the performance of the models. These metrics
provide valuable insights into how each model predicts benign
(Class 0) and malicious (Class 1) SQL queries. The following
metrics were calculated for each model:
TABLE I
CLASSIFICATION METRICS AND FORMULAS
Metric Formula Description
AccuracyTP+TN
TP+TN+FP+FNProportion of correct predic-
tions out of all predictions
PrecisionTP
TP+FPProportion of positive predic-
tions that were correct
RecallTP
TP+FNProportion of actual positives
correctly predicted (Sensitivity
for Class 1)
F1-Score 2×Precision ×Recall
Precision +RecallHarmonic mean of precision
and recall
SensitivityTP Class 1
TP Class 1+FN Class 1Sensitivity is equivalent to re-
call for Class 1
The performance of various machine learning algorithms
was evaluated based on their ability to detect SQL Injection
Attacks (SQLIA).
Fig. 9.

The evalu-
ation focuses on metrics such as accuracy, precision, recall, F1-
score, and sensitivity for both benign (Class 0) and malicious
(Class 1) queries.
A. Classification Metrics
Several standard classification metrics were used to thor-
oughly assess the performance of the models. These metrics
provide valuable insights into how each model predicts benign
(Class 0) and malicious (Class 1) SQL queries. The following
metrics were calculated for each model:
TABLE I
CLASSIFICATION METRICS AND FORMULAS
Metric Formula Description
AccuracyTP+TN
TP+TN+FP+FNProportion of correct predic-
tions out of all predictions
PrecisionTP
TP+FPProportion of positive predic-
tions that were correct
RecallTP
TP+FNProportion of actual positives
correctly predicted (Sensitivity
for Class 1)
F1-Score 2×Precision ×Recall
Precision +RecallHarmonic mean of precision
and recall
SensitivityTP Class 1
TP Class 1+FN Class 1Sensitivity is equivalent to re-
call for Class 1
The performance of various machine learning algorithms
was evaluated based on their ability to detect SQL Injection
Attacks (SQLIA).
Fig. 9. Comparison of Machine Learning Algorithms based on Accuracy.
XGBoost outperforms others in SQLIA detection accuracy.As depicted in Figure 9, XGBoost achieved the highest
accuracy, outperforming other models with an impressive
score of 99.40%.

Classification Metrics
Several standard classification metrics were used to thor-
oughly assess the performance of the models. These metrics
provide valuable insights into how each model predicts benign
(Class 0) and malicious (Class 1) SQL queries. The following
metrics were calculated for each model:
TABLE I
CLASSIFICATION METRICS AND FORMULAS
Metric Formula Description
AccuracyTP+TN
TP+TN+FP+FNProportion of correct predic-
tions out of all predictions
PrecisionTP
TP+FPProportion of positive predic-
tions that were correct
RecallTP
TP+FNProportion of actual positives
correctly predicted (Sensitivity
for Class 1)
F1-Score 2×Precision ×Recall
Precision +RecallHarmonic mean of precision
and recall
SensitivityTP Class 1
TP Class 1+FN Class 1Sensitivity is equivalent to re-
call for Class 1
The performance of various machine learning algorithms
was evaluated based on their ability to detect SQL Injection
Attacks (SQLIA).
Fig. 9. Comparison of Machine Learning Algorithms based on Accuracy.
XGBoost outperforms others in SQLIA detection accuracy.As depicted in Figure 9, XGBoost achieved the highest
accuracy, outperforming other models with an impressive
score of 99.40%. LightGBM followed closely with 99.35%,
while Random Forest and KNN achieved 99.15% and 98.65%,
respectively.

These metrics
provide valuable insights into how each model predicts benign
(Class 0) and malicious (Class 1) SQL queries. The following
metrics were calculated for each model:
TABLE I
CLASSIFICATION METRICS AND FORMULAS
Metric Formula Description
AccuracyTP+TN
TP+TN+FP+FNProportion of correct predic-
tions out of all predictions
PrecisionTP
TP+FPProportion of positive predic-
tions that were correct
RecallTP
TP+FNProportion of actual positives
correctly predicted (Sensitivity
for Class 1)
F1-Score 2×Precision ×Recall
Precision +RecallHarmonic mean of precision
and recall
SensitivityTP Class 1
TP Class 1+FN Class 1Sensitivity is equivalent to re-
call for Class 1
The performance of various machine learning algorithms
was evaluated based on their ability to detect SQL Injection
Attacks (SQLIA).
Fig. 9. Comparison of Machine Learning Algorithms based on Accuracy.
XGBoost outperforms others in SQLIA detection accuracy.As depicted in Figure 9, XGBoost achieved the highest
accuracy, outperforming other models with an impressive
score of 99.40%. LightGBM followed closely with 99.35%,
while Random Forest and KNN achieved 99.15% and 98.65%,
respectively. Neural Networks, while often strong performers
in complex tasks, registered 95.39% in this specific SQLIA
detection task.

The following
metrics were calculated for each model:
TABLE I
CLASSIFICATION METRICS AND FORMULAS
Metric Formula Description
AccuracyTP+TN
TP+TN+FP+FNProportion of correct predic-
tions out of all predictions
PrecisionTP
TP+FPProportion of positive predic-
tions that were correct
RecallTP
TP+FNProportion of actual positives
correctly predicted (Sensitivity
for Class 1)
F1-Score 2×Precision ×Recall
Precision +RecallHarmonic mean of precision
and recall
SensitivityTP Class 1
TP Class 1+FN Class 1Sensitivity is equivalent to re-
call for Class 1
The performance of various machine learning algorithms
was evaluated based on their ability to detect SQL Injection
Attacks (SQLIA).
Fig. 9. Comparison of Machine Learning Algorithms based on Accuracy.
XGBoost outperforms others in SQLIA detection accuracy.As depicted in Figure 9, XGBoost achieved the highest
accuracy, outperforming other models with an impressive
score of 99.40%. LightGBM followed closely with 99.35%,
while Random Forest and KNN achieved 99.15% and 98.65%,
respectively. Neural Networks, while often strong performers
in complex tasks, registered 95.39% in this specific SQLIA
detection task. Logistic Regression, Support Vector Classifier
(SVC), and Naive Bayes were outperformed by the others,
with Naive Bayes being the least accurate at 72.82%.
The results underscore the suitability of XGBoost for
SQLIA detection tasks, making it the preferred choice for
further experiments.

9. Comparison of Machine Learning Algorithms based on Accuracy.
XGBoost outperforms others in SQLIA detection accuracy.As depicted in Figure 9, XGBoost achieved the highest
accuracy, outperforming other models with an impressive
score of 99.40%. LightGBM followed closely with 99.35%,
while Random Forest and KNN achieved 99.15% and 98.65%,
respectively. Neural Networks, while often strong performers
in complex tasks, registered 95.39% in this specific SQLIA
detection task. Logistic Regression, Support Vector Classifier
(SVC), and Naive Bayes were outperformed by the others,
with Naive Bayes being the least accurate at 72.82%.
The results underscore the suitability of XGBoost for
SQLIA detection tasks, making it the preferred choice for
further experiments. Its balance of speed, precision, and han-
dling of imbalanced data makes it ideal for this application,
particularly when combined with synthetic data generation
techniques such as those explored in this study.
B.

Comparison of Machine Learning Algorithms based on Accuracy.
XGBoost outperforms others in SQLIA detection accuracy.As depicted in Figure 9, XGBoost achieved the highest
accuracy, outperforming other models with an impressive
score of 99.40%. LightGBM followed closely with 99.35%,
while Random Forest and KNN achieved 99.15% and 98.65%,
respectively. Neural Networks, while often strong performers
in complex tasks, registered 95.39% in this specific SQLIA
detection task. Logistic Regression, Support Vector Classifier
(SVC), and Naive Bayes were outperformed by the others,
with Naive Bayes being the least accurate at 72.82%.
The results underscore the suitability of XGBoost for
SQLIA detection tasks, making it the preferred choice for
further experiments. Its balance of speed, precision, and han-
dling of imbalanced data makes it ideal for this application,
particularly when combined with synthetic data generation
techniques such as those explored in this study.
B. Synthetic Data Quality Evaluation Metrics
To assess the quality of the synthetic SQL query data as
generated by U-Net and CWGAN-GP, several key metrics
were utilised.

LightGBM followed closely with 99.35%,
while Random Forest and KNN achieved 99.15% and 98.65%,
respectively. Neural Networks, while often strong performers
in complex tasks, registered 95.39% in this specific SQLIA
detection task. Logistic Regression, Support Vector Classifier
(SVC), and Naive Bayes were outperformed by the others,
with Naive Bayes being the least accurate at 72.82%.
The results underscore the suitability of XGBoost for
SQLIA detection tasks, making it the preferred choice for
further experiments. Its balance of speed, precision, and han-
dling of imbalanced data makes it ideal for this application,
particularly when combined with synthetic data generation
techniques such as those explored in this study.
B. Synthetic Data Quality Evaluation Metrics
To assess the quality of the synthetic SQL query data as
generated by U-Net and CWGAN-GP, several key metrics
were utilised. These metrics are essential for ensuring the
synthetic data closely aligns with real SQL queries in both
structural and statistical dimensions, which is critical for SQL
injection detection models.
•Mean Squared Error (MSE) : MSE calculates the av-
erage squared difference between the real and synthetic
data.

Neural Networks, while often strong performers
in complex tasks, registered 95.39% in this specific SQLIA
detection task. Logistic Regression, Support Vector Classifier
(SVC), and Naive Bayes were outperformed by the others,
with Naive Bayes being the least accurate at 72.82%.
The results underscore the suitability of XGBoost for
SQLIA detection tasks, making it the preferred choice for
further experiments. Its balance of speed, precision, and han-
dling of imbalanced data makes it ideal for this application,
particularly when combined with synthetic data generation
techniques such as those explored in this study.
B. Synthetic Data Quality Evaluation Metrics
To assess the quality of the synthetic SQL query data as
generated by U-Net and CWGAN-GP, several key metrics
were utilised. These metrics are essential for ensuring the
synthetic data closely aligns with real SQL queries in both
structural and statistical dimensions, which is critical for SQL
injection detection models.
•Mean Squared Error (MSE) : MSE calculates the av-
erage squared difference between the real and synthetic
data. A lower MSE value indicates that the generated
data closely mimics the real data, reducing the risk of
discrepancies in model training [30].
•R² Score : This metric quantifies the amount of variance
in the real data that is captured by the synthetic data.
A high R² score ensures that the generated SQL queries
retain sufficient diversity, supporting better generalisation
in machine learning models.
•Explained Variance Score (EVS) : EVS measures the
proportion of variance in the real dataset captured by
the synthetic data.

Logistic Regression, Support Vector Classifier
(SVC), and Naive Bayes were outperformed by the others,
with Naive Bayes being the least accurate at 72.82%.
The results underscore the suitability of XGBoost for
SQLIA detection tasks, making it the preferred choice for
further experiments. Its balance of speed, precision, and han-
dling of imbalanced data makes it ideal for this application,
particularly when combined with synthetic data generation
techniques such as those explored in this study.
B. Synthetic Data Quality Evaluation Metrics
To assess the quality of the synthetic SQL query data as
generated by U-Net and CWGAN-GP, several key metrics
were utilised. These metrics are essential for ensuring the
synthetic data closely aligns with real SQL queries in both
structural and statistical dimensions, which is critical for SQL
injection detection models.
•Mean Squared Error (MSE) : MSE calculates the av-
erage squared difference between the real and synthetic
data. A lower MSE value indicates that the generated
data closely mimics the real data, reducing the risk of
discrepancies in model training [30].
•R² Score : This metric quantifies the amount of variance
in the real data that is captured by the synthetic data.
A high R² score ensures that the generated SQL queries
retain sufficient diversity, supporting better generalisation
in machine learning models.
•Explained Variance Score (EVS) : EVS measures the
proportion of variance in the real dataset captured by
the synthetic data. High EVS indicates that the synthetic
queries adequately cover the behaviours and patterns
observed in real-world SQL injection attacks [30].
•BLEU Score : BLEU measures the token-level similarity
between real and synthetic queries.

Its balance of speed, precision, and han-
dling of imbalanced data makes it ideal for this application,
particularly when combined with synthetic data generation
techniques such as those explored in this study.
B. Synthetic Data Quality Evaluation Metrics
To assess the quality of the synthetic SQL query data as
generated by U-Net and CWGAN-GP, several key metrics
were utilised. These metrics are essential for ensuring the
synthetic data closely aligns with real SQL queries in both
structural and statistical dimensions, which is critical for SQL
injection detection models.
•Mean Squared Error (MSE) : MSE calculates the av-
erage squared difference between the real and synthetic
data. A lower MSE value indicates that the generated
data closely mimics the real data, reducing the risk of
discrepancies in model training [30].
•R² Score : This metric quantifies the amount of variance
in the real data that is captured by the synthetic data.
A high R² score ensures that the generated SQL queries
retain sufficient diversity, supporting better generalisation
in machine learning models.
•Explained Variance Score (EVS) : EVS measures the
proportion of variance in the real dataset captured by
the synthetic data. High EVS indicates that the synthetic
queries adequately cover the behaviours and patterns
observed in real-world SQL injection attacks [30].
•BLEU Score : BLEU measures the token-level similarity
between real and synthetic queries. A higher BLEU score
reflects greater structural alignment, which is critical for
maintaining the functional semantics of SQL queries [30].
•Cosine Similarity : This metric calculates the angular
similarity between vectorised representations of real and
synthetic data.

Synthetic Data Quality Evaluation Metrics
To assess the quality of the synthetic SQL query data as
generated by U-Net and CWGAN-GP, several key metrics
were utilised. These metrics are essential for ensuring the
synthetic data closely aligns with real SQL queries in both
structural and statistical dimensions, which is critical for SQL
injection detection models.
•Mean Squared Error (MSE) : MSE calculates the av-
erage squared difference between the real and synthetic
data. A lower MSE value indicates that the generated
data closely mimics the real data, reducing the risk of
discrepancies in model training [30].
•R² Score : This metric quantifies the amount of variance
in the real data that is captured by the synthetic data.
A high R² score ensures that the generated SQL queries
retain sufficient diversity, supporting better generalisation
in machine learning models.
•Explained Variance Score (EVS) : EVS measures the
proportion of variance in the real dataset captured by
the synthetic data. High EVS indicates that the synthetic
queries adequately cover the behaviours and patterns
observed in real-world SQL injection attacks [30].
•BLEU Score : BLEU measures the token-level similarity
between real and synthetic queries. A higher BLEU score
reflects greater structural alignment, which is critical for
maintaining the functional semantics of SQL queries [30].
•Cosine Similarity : This metric calculates the angular
similarity between vectorised representations of real and
synthetic data. In SQL query generation, cosine similarity
ensures that the overall semantic meaning of the queries
is preserved.
•Lowenstein Distance : This computes the number of edits
required to transform synthetic queries into real ones.

These metrics are essential for ensuring the
synthetic data closely aligns with real SQL queries in both
structural and statistical dimensions, which is critical for SQL
injection detection models.
•Mean Squared Error (MSE) : MSE calculates the av-
erage squared difference between the real and synthetic
data. A lower MSE value indicates that the generated
data closely mimics the real data, reducing the risk of
discrepancies in model training [30].
•R² Score : This metric quantifies the amount of variance
in the real data that is captured by the synthetic data.
A high R² score ensures that the generated SQL queries
retain sufficient diversity, supporting better generalisation
in machine learning models.
•Explained Variance Score (EVS) : EVS measures the
proportion of variance in the real dataset captured by
the synthetic data. High EVS indicates that the synthetic
queries adequately cover the behaviours and patterns
observed in real-world SQL injection attacks [30].
•BLEU Score : BLEU measures the token-level similarity
between real and synthetic queries. A higher BLEU score
reflects greater structural alignment, which is critical for
maintaining the functional semantics of SQL queries [30].
•Cosine Similarity : This metric calculates the angular
similarity between vectorised representations of real and
synthetic data. In SQL query generation, cosine similarity
ensures that the overall semantic meaning of the queries
is preserved.
•Lowenstein Distance : This computes the number of edits
required to transform synthetic queries into real ones. A
lower distance signifies a closer match between the real
and synthetic data, which is vital for maintaining query
integrity.
•Mean and Variance Differences : These metrics compare
the statistical distributions of real and synthetic data
by evaluating their means and variances.

A lower MSE value indicates that the generated
data closely mimics the real data, reducing the risk of
discrepancies in model training [30].
•R² Score : This metric quantifies the amount of variance
in the real data that is captured by the synthetic data.
A high R² score ensures that the generated SQL queries
retain sufficient diversity, supporting better generalisation
in machine learning models.
•Explained Variance Score (EVS) : EVS measures the
proportion of variance in the real dataset captured by
the synthetic data. High EVS indicates that the synthetic
queries adequately cover the behaviours and patterns
observed in real-world SQL injection attacks [30].
•BLEU Score : BLEU measures the token-level similarity
between real and synthetic queries. A higher BLEU score
reflects greater structural alignment, which is critical for
maintaining the functional semantics of SQL queries [30].
•Cosine Similarity : This metric calculates the angular
similarity between vectorised representations of real and
synthetic data. In SQL query generation, cosine similarity
ensures that the overall semantic meaning of the queries
is preserved.
•Lowenstein Distance : This computes the number of edits
required to transform synthetic queries into real ones. A
lower distance signifies a closer match between the real
and synthetic data, which is vital for maintaining query
integrity.
•Mean and Variance Differences : These metrics compare
the statistical distributions of real and synthetic data
by evaluating their means and variances. In SQL data
generation, this ensures that the statistical properties, such
as query patterns and structures, are preserved, improving
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 9
the reliability of the generated data for SQL injection
detection.
Other Metrics and Justifications
Several other metrics commonly used in text generation,
such as perplexity and compression ratio, were considered but
deemed unsuitable for this structured dataset:
•Perplexity : This metric is typically used in language
modelling to measure uncertainty in word predictions.
However, because SQL queries are deterministic and do
not involve probabilistic word choices, perplexity is not
applicable in this context [30].
•Compression Ratio : Commonly used to evaluate text
summarisation, this metric measures the reduction in text
length.

High EVS indicates that the synthetic
queries adequately cover the behaviours and patterns
observed in real-world SQL injection attacks [30].
•BLEU Score : BLEU measures the token-level similarity
between real and synthetic queries. A higher BLEU score
reflects greater structural alignment, which is critical for
maintaining the functional semantics of SQL queries [30].
•Cosine Similarity : This metric calculates the angular
similarity between vectorised representations of real and
synthetic data. In SQL query generation, cosine similarity
ensures that the overall semantic meaning of the queries
is preserved.
•Lowenstein Distance : This computes the number of edits
required to transform synthetic queries into real ones. A
lower distance signifies a closer match between the real
and synthetic data, which is vital for maintaining query
integrity.
•Mean and Variance Differences : These metrics compare
the statistical distributions of real and synthetic data
by evaluating their means and variances. In SQL data
generation, this ensures that the statistical properties, such
as query patterns and structures, are preserved, improving
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 9
the reliability of the generated data for SQL injection
detection.
Other Metrics and Justifications
Several other metrics commonly used in text generation,
such as perplexity and compression ratio, were considered but
deemed unsuitable for this structured dataset:
•Perplexity : This metric is typically used in language
modelling to measure uncertainty in word predictions.
However, because SQL queries are deterministic and do
not involve probabilistic word choices, perplexity is not
applicable in this context [30].
•Compression Ratio : Commonly used to evaluate text
summarisation, this metric measures the reduction in text
length. In SQL query generation, the goal is to preserve
accuracy and completeness rather than conciseness, mak-
ing this metric inappropriate for the task.
By selecting the metrics most relevant to structured SQL
data, this evaluation ensures that the synthetic queries gen-
erated are reliable and useful for training machine learning
models to detect SQL injection attacks.
In addition, Principal Component Analysis (PCA) and K-
Means Clustering were used to visually inspect the alignment
between real and synthetic data distributions.

A higher BLEU score
reflects greater structural alignment, which is critical for
maintaining the functional semantics of SQL queries [30].
•Cosine Similarity : This metric calculates the angular
similarity between vectorised representations of real and
synthetic data. In SQL query generation, cosine similarity
ensures that the overall semantic meaning of the queries
is preserved.
•Lowenstein Distance : This computes the number of edits
required to transform synthetic queries into real ones. A
lower distance signifies a closer match between the real
and synthetic data, which is vital for maintaining query
integrity.
•Mean and Variance Differences : These metrics compare
the statistical distributions of real and synthetic data
by evaluating their means and variances. In SQL data
generation, this ensures that the statistical properties, such
as query patterns and structures, are preserved, improving
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 9
the reliability of the generated data for SQL injection
detection.
Other Metrics and Justifications
Several other metrics commonly used in text generation,
such as perplexity and compression ratio, were considered but
deemed unsuitable for this structured dataset:
•Perplexity : This metric is typically used in language
modelling to measure uncertainty in word predictions.
However, because SQL queries are deterministic and do
not involve probabilistic word choices, perplexity is not
applicable in this context [30].
•Compression Ratio : Commonly used to evaluate text
summarisation, this metric measures the reduction in text
length. In SQL query generation, the goal is to preserve
accuracy and completeness rather than conciseness, mak-
ing this metric inappropriate for the task.
By selecting the metrics most relevant to structured SQL
data, this evaluation ensures that the synthetic queries gen-
erated are reliable and useful for training machine learning
models to detect SQL injection attacks.
In addition, Principal Component Analysis (PCA) and K-
Means Clustering were used to visually inspect the alignment
between real and synthetic data distributions. These techniques
provide additional insights into the structural similarities of
both datasets.

In SQL query generation, cosine similarity
ensures that the overall semantic meaning of the queries
is preserved.
•Lowenstein Distance : This computes the number of edits
required to transform synthetic queries into real ones. A
lower distance signifies a closer match between the real
and synthetic data, which is vital for maintaining query
integrity.
•Mean and Variance Differences : These metrics compare
the statistical distributions of real and synthetic data
by evaluating their means and variances. In SQL data
generation, this ensures that the statistical properties, such
as query patterns and structures, are preserved, improving
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 9
the reliability of the generated data for SQL injection
detection.
Other Metrics and Justifications
Several other metrics commonly used in text generation,
such as perplexity and compression ratio, were considered but
deemed unsuitable for this structured dataset:
•Perplexity : This metric is typically used in language
modelling to measure uncertainty in word predictions.
However, because SQL queries are deterministic and do
not involve probabilistic word choices, perplexity is not
applicable in this context [30].
•Compression Ratio : Commonly used to evaluate text
summarisation, this metric measures the reduction in text
length. In SQL query generation, the goal is to preserve
accuracy and completeness rather than conciseness, mak-
ing this metric inappropriate for the task.
By selecting the metrics most relevant to structured SQL
data, this evaluation ensures that the synthetic queries gen-
erated are reliable and useful for training machine learning
models to detect SQL injection attacks.
In addition, Principal Component Analysis (PCA) and K-
Means Clustering were used to visually inspect the alignment
between real and synthetic data distributions. These techniques
provide additional insights into the structural similarities of
both datasets. The combination of these metrics ensures a
robust evaluation of the synthetic data’s quality, supporting its
use in training models for SQL Injection detection systems.
C.

A
lower distance signifies a closer match between the real
and synthetic data, which is vital for maintaining query
integrity.
•Mean and Variance Differences : These metrics compare
the statistical distributions of real and synthetic data
by evaluating their means and variances. In SQL data
generation, this ensures that the statistical properties, such
as query patterns and structures, are preserved, improving
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 9
the reliability of the generated data for SQL injection
detection.
Other Metrics and Justifications
Several other metrics commonly used in text generation,
such as perplexity and compression ratio, were considered but
deemed unsuitable for this structured dataset:
•Perplexity : This metric is typically used in language
modelling to measure uncertainty in word predictions.
However, because SQL queries are deterministic and do
not involve probabilistic word choices, perplexity is not
applicable in this context [30].
•Compression Ratio : Commonly used to evaluate text
summarisation, this metric measures the reduction in text
length. In SQL query generation, the goal is to preserve
accuracy and completeness rather than conciseness, mak-
ing this metric inappropriate for the task.
By selecting the metrics most relevant to structured SQL
data, this evaluation ensures that the synthetic queries gen-
erated are reliable and useful for training machine learning
models to detect SQL injection attacks.
In addition, Principal Component Analysis (PCA) and K-
Means Clustering were used to visually inspect the alignment
between real and synthetic data distributions. These techniques
provide additional insights into the structural similarities of
both datasets. The combination of these metrics ensures a
robust evaluation of the synthetic data’s quality, supporting its
use in training models for SQL Injection detection systems.
C. Evaluation of Synthetic Data
1) U-Net Model: Results and Discussion: The performance
of the U-Net model in generating synthetic SQL queries was
evaluated using the above key metrics.
Fig.

In SQL data
generation, this ensures that the statistical properties, such
as query patterns and structures, are preserved, improving
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 9
the reliability of the generated data for SQL injection
detection.
Other Metrics and Justifications
Several other metrics commonly used in text generation,
such as perplexity and compression ratio, were considered but
deemed unsuitable for this structured dataset:
•Perplexity : This metric is typically used in language
modelling to measure uncertainty in word predictions.
However, because SQL queries are deterministic and do
not involve probabilistic word choices, perplexity is not
applicable in this context [30].
•Compression Ratio : Commonly used to evaluate text
summarisation, this metric measures the reduction in text
length. In SQL query generation, the goal is to preserve
accuracy and completeness rather than conciseness, mak-
ing this metric inappropriate for the task.
By selecting the metrics most relevant to structured SQL
data, this evaluation ensures that the synthetic queries gen-
erated are reliable and useful for training machine learning
models to detect SQL injection attacks.
In addition, Principal Component Analysis (PCA) and K-
Means Clustering were used to visually inspect the alignment
between real and synthetic data distributions. These techniques
provide additional insights into the structural similarities of
both datasets. The combination of these metrics ensures a
robust evaluation of the synthetic data’s quality, supporting its
use in training models for SQL Injection detection systems.
C. Evaluation of Synthetic Data
1) U-Net Model: Results and Discussion: The performance
of the U-Net model in generating synthetic SQL queries was
evaluated using the above key metrics.
Fig. 10.

In SQL query generation, the goal is to preserve
accuracy and completeness rather than conciseness, mak-
ing this metric inappropriate for the task.
By selecting the metrics most relevant to structured SQL
data, this evaluation ensures that the synthetic queries gen-
erated are reliable and useful for training machine learning
models to detect SQL injection attacks.
In addition, Principal Component Analysis (PCA) and K-
Means Clustering were used to visually inspect the alignment
between real and synthetic data distributions. These techniques
provide additional insights into the structural similarities of
both datasets. The combination of these metrics ensures a
robust evaluation of the synthetic data’s quality, supporting its
use in training models for SQL Injection detection systems.
C. Evaluation of Synthetic Data
1) U-Net Model: Results and Discussion: The performance
of the U-Net model in generating synthetic SQL queries was
evaluated using the above key metrics.
Fig. 10. Performance Metrics for U-Net Model
As shown in Figure 10, the U-Net model performed ex-
ceptionally well, achieving a low Mean Squared Error (MSE)
of 0.0005, indicating a strong match between the real and
synthetic SQL data.

These techniques
provide additional insights into the structural similarities of
both datasets. The combination of these metrics ensures a
robust evaluation of the synthetic data’s quality, supporting its
use in training models for SQL Injection detection systems.
C. Evaluation of Synthetic Data
1) U-Net Model: Results and Discussion: The performance
of the U-Net model in generating synthetic SQL queries was
evaluated using the above key metrics.
Fig. 10. Performance Metrics for U-Net Model
As shown in Figure 10, the U-Net model performed ex-
ceptionally well, achieving a low Mean Squared Error (MSE)
of 0.0005, indicating a strong match between the real and
synthetic SQL data. The model’s R² score of 0.8159 of the
model confirms its effectiveness in capturing variance within
the real dataset.
Other key metrics include a BLEU Score of 0.9919 and
a Cosine Similarity of 0.9996, which highlight the close
structural and semantic resemblance between the generated
and real queries.

The combination of these metrics ensures a
robust evaluation of the synthetic data’s quality, supporting its
use in training models for SQL Injection detection systems.
C. Evaluation of Synthetic Data
1) U-Net Model: Results and Discussion: The performance
of the U-Net model in generating synthetic SQL queries was
evaluated using the above key metrics.
Fig. 10. Performance Metrics for U-Net Model
As shown in Figure 10, the U-Net model performed ex-
ceptionally well, achieving a low Mean Squared Error (MSE)
of 0.0005, indicating a strong match between the real and
synthetic SQL data. The model’s R² score of 0.8159 of the
model confirms its effectiveness in capturing variance within
the real dataset.
Other key metrics include a BLEU Score of 0.9919 and
a Cosine Similarity of 0.9996, which highlight the close
structural and semantic resemblance between the generated
and real queries. Furthermore, the Lowenstein Distance of1.4565 supports the high similarity between the datasets,
requiring minimal changes for alignment.
The Principal Component Analysis (PCA) results in Figure
11 further validate the consistency of the U-Net model in
generating synthetic queries that align closely with the real
SQL data.

Evaluation of Synthetic Data
1) U-Net Model: Results and Discussion: The performance
of the U-Net model in generating synthetic SQL queries was
evaluated using the above key metrics.
Fig. 10. Performance Metrics for U-Net Model
As shown in Figure 10, the U-Net model performed ex-
ceptionally well, achieving a low Mean Squared Error (MSE)
of 0.0005, indicating a strong match between the real and
synthetic SQL data. The model’s R² score of 0.8159 of the
model confirms its effectiveness in capturing variance within
the real dataset.
Other key metrics include a BLEU Score of 0.9919 and
a Cosine Similarity of 0.9996, which highlight the close
structural and semantic resemblance between the generated
and real queries. Furthermore, the Lowenstein Distance of1.4565 supports the high similarity between the datasets,
requiring minimal changes for alignment.
The Principal Component Analysis (PCA) results in Figure
11 further validate the consistency of the U-Net model in
generating synthetic queries that align closely with the real
SQL data. Minimal distributional differences, as indicated by
the Mean Difference of 0.0062 and Variance Difference of
0.0045, emphasise the strong generalisation capabilities of the
model in mimicking real-world query structures.
Fig.

10. Performance Metrics for U-Net Model
As shown in Figure 10, the U-Net model performed ex-
ceptionally well, achieving a low Mean Squared Error (MSE)
of 0.0005, indicating a strong match between the real and
synthetic SQL data. The model’s R² score of 0.8159 of the
model confirms its effectiveness in capturing variance within
the real dataset.
Other key metrics include a BLEU Score of 0.9919 and
a Cosine Similarity of 0.9996, which highlight the close
structural and semantic resemblance between the generated
and real queries. Furthermore, the Lowenstein Distance of1.4565 supports the high similarity between the datasets,
requiring minimal changes for alignment.
The Principal Component Analysis (PCA) results in Figure
11 further validate the consistency of the U-Net model in
generating synthetic queries that align closely with the real
SQL data. Minimal distributional differences, as indicated by
the Mean Difference of 0.0062 and Variance Difference of
0.0045, emphasise the strong generalisation capabilities of the
model in mimicking real-world query structures.
Fig. 11.

Performance Metrics for U-Net Model
As shown in Figure 10, the U-Net model performed ex-
ceptionally well, achieving a low Mean Squared Error (MSE)
of 0.0005, indicating a strong match between the real and
synthetic SQL data. The model’s R² score of 0.8159 of the
model confirms its effectiveness in capturing variance within
the real dataset.
Other key metrics include a BLEU Score of 0.9919 and
a Cosine Similarity of 0.9996, which highlight the close
structural and semantic resemblance between the generated
and real queries. Furthermore, the Lowenstein Distance of1.4565 supports the high similarity between the datasets,
requiring minimal changes for alignment.
The Principal Component Analysis (PCA) results in Figure
11 further validate the consistency of the U-Net model in
generating synthetic queries that align closely with the real
SQL data. Minimal distributional differences, as indicated by
the Mean Difference of 0.0062 and Variance Difference of
0.0045, emphasise the strong generalisation capabilities of the
model in mimicking real-world query structures.
Fig. 11. PCA of Real vs Synthetic Data for U-Net Model
2) CWGAN-GP Results and Discussion: Similar to the
U-Net model, the synthetic data generated by CWGAN-GP
was evaluated using key performance metrics to assess its
effectiveness.
Fig.

The model’s R² score of 0.8159 of the
model confirms its effectiveness in capturing variance within
the real dataset.
Other key metrics include a BLEU Score of 0.9919 and
a Cosine Similarity of 0.9996, which highlight the close
structural and semantic resemblance between the generated
and real queries. Furthermore, the Lowenstein Distance of1.4565 supports the high similarity between the datasets,
requiring minimal changes for alignment.
The Principal Component Analysis (PCA) results in Figure
11 further validate the consistency of the U-Net model in
generating synthetic queries that align closely with the real
SQL data. Minimal distributional differences, as indicated by
the Mean Difference of 0.0062 and Variance Difference of
0.0045, emphasise the strong generalisation capabilities of the
model in mimicking real-world query structures.
Fig. 11. PCA of Real vs Synthetic Data for U-Net Model
2) CWGAN-GP Results and Discussion: Similar to the
U-Net model, the synthetic data generated by CWGAN-GP
was evaluated using key performance metrics to assess its
effectiveness.
Fig. 12.

Furthermore, the Lowenstein Distance of1.4565 supports the high similarity between the datasets,
requiring minimal changes for alignment.
The Principal Component Analysis (PCA) results in Figure
11 further validate the consistency of the U-Net model in
generating synthetic queries that align closely with the real
SQL data. Minimal distributional differences, as indicated by
the Mean Difference of 0.0062 and Variance Difference of
0.0045, emphasise the strong generalisation capabilities of the
model in mimicking real-world query structures.
Fig. 11. PCA of Real vs Synthetic Data for U-Net Model
2) CWGAN-GP Results and Discussion: Similar to the
U-Net model, the synthetic data generated by CWGAN-GP
was evaluated using key performance metrics to assess its
effectiveness.
Fig. 12. Performance Metrics for CWGAN-GP Model
As illustrated in Figure 12, the CWGAN-GP model
achieved a Mean Squared Error (MSE) of 0.0108, indicating
some variance between the real and synthetic datasets.

Minimal distributional differences, as indicated by
the Mean Difference of 0.0062 and Variance Difference of
0.0045, emphasise the strong generalisation capabilities of the
model in mimicking real-world query structures.
Fig. 11. PCA of Real vs Synthetic Data for U-Net Model
2) CWGAN-GP Results and Discussion: Similar to the
U-Net model, the synthetic data generated by CWGAN-GP
was evaluated using key performance metrics to assess its
effectiveness.
Fig. 12. Performance Metrics for CWGAN-GP Model
As illustrated in Figure 12, the CWGAN-GP model
achieved a Mean Squared Error (MSE) of 0.0108, indicating
some variance between the real and synthetic datasets. The R²
score of -1.7253 and the Explained Variance Score of -1.6020
further reflect deviations from real data patterns.
Despite these deviations, the model produced a BLEU
Score of 0.9759 and a Cosine Similarity of 0.9952, showing
strong structural alignment between the real and synthetic SQL
queries.

11. PCA of Real vs Synthetic Data for U-Net Model
2) CWGAN-GP Results and Discussion: Similar to the
U-Net model, the synthetic data generated by CWGAN-GP
was evaluated using key performance metrics to assess its
effectiveness.
Fig. 12. Performance Metrics for CWGAN-GP Model
As illustrated in Figure 12, the CWGAN-GP model
achieved a Mean Squared Error (MSE) of 0.0108, indicating
some variance between the real and synthetic datasets. The R²
score of -1.7253 and the Explained Variance Score of -1.6020
further reflect deviations from real data patterns.
Despite these deviations, the model produced a BLEU
Score of 0.9759 and a Cosine Similarity of 0.9952, showing
strong structural alignment between the real and synthetic SQL
queries. The Lowenstein Distance of 5.1057, though higher,
suggests moderate similarity in sequence structure between
the generated and real data.
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 10
Figure 13 shows the Principal Component Analysis (PCA),
where the real and synthetic data exhibit partial overlap, with
the synthetic data displaying greater dispersion.

PCA of Real vs Synthetic Data for U-Net Model
2) CWGAN-GP Results and Discussion: Similar to the
U-Net model, the synthetic data generated by CWGAN-GP
was evaluated using key performance metrics to assess its
effectiveness.
Fig. 12. Performance Metrics for CWGAN-GP Model
As illustrated in Figure 12, the CWGAN-GP model
achieved a Mean Squared Error (MSE) of 0.0108, indicating
some variance between the real and synthetic datasets. The R²
score of -1.7253 and the Explained Variance Score of -1.6020
further reflect deviations from real data patterns.
Despite these deviations, the model produced a BLEU
Score of 0.9759 and a Cosine Similarity of 0.9952, showing
strong structural alignment between the real and synthetic SQL
queries. The Lowenstein Distance of 5.1057, though higher,
suggests moderate similarity in sequence structure between
the generated and real data.
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 10
Figure 13 shows the Principal Component Analysis (PCA),
where the real and synthetic data exhibit partial overlap, with
the synthetic data displaying greater dispersion. This suggests
that while CWGAN-GP effectively captures overall patterns,
there remains some variability.
In summary, the CWGAN-GP model demonstrates effective
token-level and vector-based similarities with real data, though
with some structural deviations, as evidenced by the PCA and
higher Lowenstein Distance.
Fig.

12. Performance Metrics for CWGAN-GP Model
As illustrated in Figure 12, the CWGAN-GP model
achieved a Mean Squared Error (MSE) of 0.0108, indicating
some variance between the real and synthetic datasets. The R²
score of -1.7253 and the Explained Variance Score of -1.6020
further reflect deviations from real data patterns.
Despite these deviations, the model produced a BLEU
Score of 0.9759 and a Cosine Similarity of 0.9952, showing
strong structural alignment between the real and synthetic SQL
queries. The Lowenstein Distance of 5.1057, though higher,
suggests moderate similarity in sequence structure between
the generated and real data.
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 10
Figure 13 shows the Principal Component Analysis (PCA),
where the real and synthetic data exhibit partial overlap, with
the synthetic data displaying greater dispersion. This suggests
that while CWGAN-GP effectively captures overall patterns,
there remains some variability.
In summary, the CWGAN-GP model demonstrates effective
token-level and vector-based similarities with real data, though
with some structural deviations, as evidenced by the PCA and
higher Lowenstein Distance.
Fig. 13.

Performance Metrics for CWGAN-GP Model
As illustrated in Figure 12, the CWGAN-GP model
achieved a Mean Squared Error (MSE) of 0.0108, indicating
some variance between the real and synthetic datasets. The R²
score of -1.7253 and the Explained Variance Score of -1.6020
further reflect deviations from real data patterns.
Despite these deviations, the model produced a BLEU
Score of 0.9759 and a Cosine Similarity of 0.9952, showing
strong structural alignment between the real and synthetic SQL
queries. The Lowenstein Distance of 5.1057, though higher,
suggests moderate similarity in sequence structure between
the generated and real data.
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 10
Figure 13 shows the Principal Component Analysis (PCA),
where the real and synthetic data exhibit partial overlap, with
the synthetic data displaying greater dispersion. This suggests
that while CWGAN-GP effectively captures overall patterns,
there remains some variability.
In summary, the CWGAN-GP model demonstrates effective
token-level and vector-based similarities with real data, though
with some structural deviations, as evidenced by the PCA and
higher Lowenstein Distance.
Fig. 13. PCA of Real vs Synthetic Data for CWGAN-GP Model
D.

The R²
score of -1.7253 and the Explained Variance Score of -1.6020
further reflect deviations from real data patterns.
Despite these deviations, the model produced a BLEU
Score of 0.9759 and a Cosine Similarity of 0.9952, showing
strong structural alignment between the real and synthetic SQL
queries. The Lowenstein Distance of 5.1057, though higher,
suggests moderate similarity in sequence structure between
the generated and real data.
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 10
Figure 13 shows the Principal Component Analysis (PCA),
where the real and synthetic data exhibit partial overlap, with
the synthetic data displaying greater dispersion. This suggests
that while CWGAN-GP effectively captures overall patterns,
there remains some variability.
In summary, the CWGAN-GP model demonstrates effective
token-level and vector-based similarities with real data, though
with some structural deviations, as evidenced by the PCA and
higher Lowenstein Distance.
Fig. 13. PCA of Real vs Synthetic Data for CWGAN-GP Model
D. Pseudo-Labelling and Clustering Results
Following the generation of synthetic SQL data, pseudo-
labelling was employed to categorise the data into distinct
classes.

The Lowenstein Distance of 5.1057, though higher,
suggests moderate similarity in sequence structure between
the generated and real data.
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 10
Figure 13 shows the Principal Component Analysis (PCA),
where the real and synthetic data exhibit partial overlap, with
the synthetic data displaying greater dispersion. This suggests
that while CWGAN-GP effectively captures overall patterns,
there remains some variability.
In summary, the CWGAN-GP model demonstrates effective
token-level and vector-based similarities with real data, though
with some structural deviations, as evidenced by the PCA and
higher Lowenstein Distance.
Fig. 13. PCA of Real vs Synthetic Data for CWGAN-GP Model
D. Pseudo-Labelling and Clustering Results
Following the generation of synthetic SQL data, pseudo-
labelling was employed to categorise the data into distinct
classes. Pseudo-labels were assigned using KMeans clustering,
which organised the data based on feature similarities.

This suggests
that while CWGAN-GP effectively captures overall patterns,
there remains some variability.
In summary, the CWGAN-GP model demonstrates effective
token-level and vector-based similarities with real data, though
with some structural deviations, as evidenced by the PCA and
higher Lowenstein Distance.
Fig. 13. PCA of Real vs Synthetic Data for CWGAN-GP Model
D. Pseudo-Labelling and Clustering Results
Following the generation of synthetic SQL data, pseudo-
labelling was employed to categorise the data into distinct
classes. Pseudo-labels were assigned using KMeans clustering,
which organised the data based on feature similarities. The
spread of the data was used to determine the labels: benign
queries (Class 0) exhibited a lower spread, while malicious
queries (Class 1) displayed a higher spread.
Fig.

13. PCA of Real vs Synthetic Data for CWGAN-GP Model
D. Pseudo-Labelling and Clustering Results
Following the generation of synthetic SQL data, pseudo-
labelling was employed to categorise the data into distinct
classes. Pseudo-labels were assigned using KMeans clustering,
which organised the data based on feature similarities. The
spread of the data was used to determine the labels: benign
queries (Class 0) exhibited a lower spread, while malicious
queries (Class 1) displayed a higher spread.
Fig. 14.

PCA of Real vs Synthetic Data for CWGAN-GP Model
D. Pseudo-Labelling and Clustering Results
Following the generation of synthetic SQL data, pseudo-
labelling was employed to categorise the data into distinct
classes. Pseudo-labels were assigned using KMeans clustering,
which organised the data based on feature similarities. The
spread of the data was used to determine the labels: benign
queries (Class 0) exhibited a lower spread, while malicious
queries (Class 1) displayed a higher spread.
Fig. 14. KMeans Clustering of U-Net and CWGAN-GP Synthetic Data with
Pseudo Labels.

Pseudo-Labelling and Clustering Results
Following the generation of synthetic SQL data, pseudo-
labelling was employed to categorise the data into distinct
classes. Pseudo-labels were assigned using KMeans clustering,
which organised the data based on feature similarities. The
spread of the data was used to determine the labels: benign
queries (Class 0) exhibited a lower spread, while malicious
queries (Class 1) displayed a higher spread.
Fig. 14. KMeans Clustering of U-Net and CWGAN-GP Synthetic Data with
Pseudo Labels. U-Net results on the left and CWGAN-GP on the right.
As illustrated in Figure 14, the clustering results for both
U-Net and CWGAN-GP reveal a clear separation of synthetic
data into Class 0 and Class 1.

Pseudo-labels were assigned using KMeans clustering,
which organised the data based on feature similarities. The
spread of the data was used to determine the labels: benign
queries (Class 0) exhibited a lower spread, while malicious
queries (Class 1) displayed a higher spread.
Fig. 14. KMeans Clustering of U-Net and CWGAN-GP Synthetic Data with
Pseudo Labels. U-Net results on the left and CWGAN-GP on the right.
As illustrated in Figure 14, the clustering results for both
U-Net and CWGAN-GP reveal a clear separation of synthetic
data into Class 0 and Class 1. This process of assigning
pseudo-labels enhances the practical utility of the synthetic
data when integrated with real labelled datasets.

The
spread of the data was used to determine the labels: benign
queries (Class 0) exhibited a lower spread, while malicious
queries (Class 1) displayed a higher spread.
Fig. 14. KMeans Clustering of U-Net and CWGAN-GP Synthetic Data with
Pseudo Labels. U-Net results on the left and CWGAN-GP on the right.
As illustrated in Figure 14, the clustering results for both
U-Net and CWGAN-GP reveal a clear separation of synthetic
data into Class 0 and Class 1. This process of assigning
pseudo-labels enhances the practical utility of the synthetic
data when integrated with real labelled datasets. By utilising
these pseudo-labels, machine learning models trained on hy-
brid datasets, which include both real and synthetic samples,
can achieve improved performance.E.

14. KMeans Clustering of U-Net and CWGAN-GP Synthetic Data with
Pseudo Labels. U-Net results on the left and CWGAN-GP on the right.
As illustrated in Figure 14, the clustering results for both
U-Net and CWGAN-GP reveal a clear separation of synthetic
data into Class 0 and Class 1. This process of assigning
pseudo-labels enhances the practical utility of the synthetic
data when integrated with real labelled datasets. By utilising
these pseudo-labels, machine learning models trained on hy-
brid datasets, which include both real and synthetic samples,
can achieve improved performance.E. XGBoost Performance on Various Data Combinations
In this section, the performance of the XGBoost model
trained on a combination of original data and synthetic data
as generated by U-Net and CWGAN-GP models is analysed.
Figure 15 illustrates the comparative results of XGBoost across
various evaluation metrics.
Fig.

KMeans Clustering of U-Net and CWGAN-GP Synthetic Data with
Pseudo Labels. U-Net results on the left and CWGAN-GP on the right.
As illustrated in Figure 14, the clustering results for both
U-Net and CWGAN-GP reveal a clear separation of synthetic
data into Class 0 and Class 1. This process of assigning
pseudo-labels enhances the practical utility of the synthetic
data when integrated with real labelled datasets. By utilising
these pseudo-labels, machine learning models trained on hy-
brid datasets, which include both real and synthetic samples,
can achieve improved performance.E. XGBoost Performance on Various Data Combinations
In this section, the performance of the XGBoost model
trained on a combination of original data and synthetic data
as generated by U-Net and CWGAN-GP models is analysed.
Figure 15 illustrates the comparative results of XGBoost across
various evaluation metrics.
Fig. 15.

U-Net results on the left and CWGAN-GP on the right.
As illustrated in Figure 14, the clustering results for both
U-Net and CWGAN-GP reveal a clear separation of synthetic
data into Class 0 and Class 1. This process of assigning
pseudo-labels enhances the practical utility of the synthetic
data when integrated with real labelled datasets. By utilising
these pseudo-labels, machine learning models trained on hy-
brid datasets, which include both real and synthetic samples,
can achieve improved performance.E. XGBoost Performance on Various Data Combinations
In this section, the performance of the XGBoost model
trained on a combination of original data and synthetic data
as generated by U-Net and CWGAN-GP models is analysed.
Figure 15 illustrates the comparative results of XGBoost across
various evaluation metrics.
Fig. 15. XGBoost Performance on Various Data Combinations
The XGBoost model exhibited a consistently strong per-
formance across most metrics when trained on original
data.

This process of assigning
pseudo-labels enhances the practical utility of the synthetic
data when integrated with real labelled datasets. By utilising
these pseudo-labels, machine learning models trained on hy-
brid datasets, which include both real and synthetic samples,
can achieve improved performance.E. XGBoost Performance on Various Data Combinations
In this section, the performance of the XGBoost model
trained on a combination of original data and synthetic data
as generated by U-Net and CWGAN-GP models is analysed.
Figure 15 illustrates the comparative results of XGBoost across
various evaluation metrics.
Fig. 15. XGBoost Performance on Various Data Combinations
The XGBoost model exhibited a consistently strong per-
formance across most metrics when trained on original
data. However, incorporating synthetic data from U-Net and
CWGAN-GP introduced some performance variations, partic-
ularly in precision, recall, and F1-score across benign (Class
0) and malicious (Class 1) queries.
The inclusion of U-Net-generated synthetic data improved
the precision and recall of the model, particularly in identify-
ing SQL injection attacks (Class 1).

By utilising
these pseudo-labels, machine learning models trained on hy-
brid datasets, which include both real and synthetic samples,
can achieve improved performance.E. XGBoost Performance on Various Data Combinations
In this section, the performance of the XGBoost model
trained on a combination of original data and synthetic data
as generated by U-Net and CWGAN-GP models is analysed.
Figure 15 illustrates the comparative results of XGBoost across
various evaluation metrics.
Fig. 15. XGBoost Performance on Various Data Combinations
The XGBoost model exhibited a consistently strong per-
formance across most metrics when trained on original
data. However, incorporating synthetic data from U-Net and
CWGAN-GP introduced some performance variations, partic-
ularly in precision, recall, and F1-score across benign (Class
0) and malicious (Class 1) queries.
The inclusion of U-Net-generated synthetic data improved
the precision and recall of the model, particularly in identify-
ing SQL injection attacks (Class 1). Meanwhile, synthetic data
as generated by CWGAN-GP provided competitive results but
showed a slight reduction in sensitivity, indicating marginal
difficulty in correctly identifying all malicious queries.
F.

XGBoost Performance on Various Data Combinations
In this section, the performance of the XGBoost model
trained on a combination of original data and synthetic data
as generated by U-Net and CWGAN-GP models is analysed.
Figure 15 illustrates the comparative results of XGBoost across
various evaluation metrics.
Fig. 15. XGBoost Performance on Various Data Combinations
The XGBoost model exhibited a consistently strong per-
formance across most metrics when trained on original
data. However, incorporating synthetic data from U-Net and
CWGAN-GP introduced some performance variations, partic-
ularly in precision, recall, and F1-score across benign (Class
0) and malicious (Class 1) queries.
The inclusion of U-Net-generated synthetic data improved
the precision and recall of the model, particularly in identify-
ing SQL injection attacks (Class 1). Meanwhile, synthetic data
as generated by CWGAN-GP provided competitive results but
showed a slight reduction in sensitivity, indicating marginal
difficulty in correctly identifying all malicious queries.
F. Hybrid Data Proportions for XGBoost Training
A dataset pool optimisation method was implemented by
combining synthetic data from U-Net and CWGAN-GP mod-
els with real datasets in proportions to create hybrid datasets,
with the goal of identifying the best balance for improving
key metrics.

15. XGBoost Performance on Various Data Combinations
The XGBoost model exhibited a consistently strong per-
formance across most metrics when trained on original
data. However, incorporating synthetic data from U-Net and
CWGAN-GP introduced some performance variations, partic-
ularly in precision, recall, and F1-score across benign (Class
0) and malicious (Class 1) queries.
The inclusion of U-Net-generated synthetic data improved
the precision and recall of the model, particularly in identify-
ing SQL injection attacks (Class 1). Meanwhile, synthetic data
as generated by CWGAN-GP provided competitive results but
showed a slight reduction in sensitivity, indicating marginal
difficulty in correctly identifying all malicious queries.
F. Hybrid Data Proportions for XGBoost Training
A dataset pool optimisation method was implemented by
combining synthetic data from U-Net and CWGAN-GP mod-
els with real datasets in proportions to create hybrid datasets,
with the goal of identifying the best balance for improving
key metrics. Stratified K-Fold Cross-Validation was applied to
ensure reliability in the evaluation process.
Fig.

XGBoost Performance on Various Data Combinations
The XGBoost model exhibited a consistently strong per-
formance across most metrics when trained on original
data. However, incorporating synthetic data from U-Net and
CWGAN-GP introduced some performance variations, partic-
ularly in precision, recall, and F1-score across benign (Class
0) and malicious (Class 1) queries.
The inclusion of U-Net-generated synthetic data improved
the precision and recall of the model, particularly in identify-
ing SQL injection attacks (Class 1). Meanwhile, synthetic data
as generated by CWGAN-GP provided competitive results but
showed a slight reduction in sensitivity, indicating marginal
difficulty in correctly identifying all malicious queries.
F. Hybrid Data Proportions for XGBoost Training
A dataset pool optimisation method was implemented by
combining synthetic data from U-Net and CWGAN-GP mod-
els with real datasets in proportions to create hybrid datasets,
with the goal of identifying the best balance for improving
key metrics. Stratified K-Fold Cross-Validation was applied to
ensure reliability in the evaluation process.
Fig. 16.

However, incorporating synthetic data from U-Net and
CWGAN-GP introduced some performance variations, partic-
ularly in precision, recall, and F1-score across benign (Class
0) and malicious (Class 1) queries.
The inclusion of U-Net-generated synthetic data improved
the precision and recall of the model, particularly in identify-
ing SQL injection attacks (Class 1). Meanwhile, synthetic data
as generated by CWGAN-GP provided competitive results but
showed a slight reduction in sensitivity, indicating marginal
difficulty in correctly identifying all malicious queries.
F. Hybrid Data Proportions for XGBoost Training
A dataset pool optimisation method was implemented by
combining synthetic data from U-Net and CWGAN-GP mod-
els with real datasets in proportions to create hybrid datasets,
with the goal of identifying the best balance for improving
key metrics. Stratified K-Fold Cross-Validation was applied to
ensure reliability in the evaluation process.
Fig. 16. Performance Metrics: Class 0
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 11
Fig.

Meanwhile, synthetic data
as generated by CWGAN-GP provided competitive results but
showed a slight reduction in sensitivity, indicating marginal
difficulty in correctly identifying all malicious queries.
F. Hybrid Data Proportions for XGBoost Training
A dataset pool optimisation method was implemented by
combining synthetic data from U-Net and CWGAN-GP mod-
els with real datasets in proportions to create hybrid datasets,
with the goal of identifying the best balance for improving
key metrics. Stratified K-Fold Cross-Validation was applied to
ensure reliability in the evaluation process.
Fig. 16. Performance Metrics: Class 0
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 11
Fig. 17.

Hybrid Data Proportions for XGBoost Training
A dataset pool optimisation method was implemented by
combining synthetic data from U-Net and CWGAN-GP mod-
els with real datasets in proportions to create hybrid datasets,
with the goal of identifying the best balance for improving
key metrics. Stratified K-Fold Cross-Validation was applied to
ensure reliability in the evaluation process.
Fig. 16. Performance Metrics: Class 0
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 11
Fig. 17. Performance Metrics: Class 1
Among the 100 tested configurations, several exhibited a
strong performance across all metrics.

Stratified K-Fold Cross-Validation was applied to
ensure reliability in the evaluation process.
Fig. 16. Performance Metrics: Class 0
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 11
Fig. 17. Performance Metrics: Class 1
Among the 100 tested configurations, several exhibited a
strong performance across all metrics. The top five combina-
tions, as shown in Figures 16 and 17, achieved high accuracy,
precision, recall, and F1-scores.

16. Performance Metrics: Class 0
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 11
Fig. 17. Performance Metrics: Class 1
Among the 100 tested configurations, several exhibited a
strong performance across all metrics. The top five combina-
tions, as shown in Figures 16 and 17, achieved high accuracy,
precision, recall, and F1-scores. The best-performing model,
utilising 80% U-Net and 70% CWGAN-GP synthetic data,
reached an accuracy of 99.984%, providing balanced detection
for both benign (Class 0) and malicious (Class 1) SQL queries.
While all top combinations showed promising results, U-Net
data generally improved recall for Class 1, whereas CWGAN-
GP data enhanced precision for Class 0.

Performance Metrics: Class 0
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 11
Fig. 17. Performance Metrics: Class 1
Among the 100 tested configurations, several exhibited a
strong performance across all metrics. The top five combina-
tions, as shown in Figures 16 and 17, achieved high accuracy,
precision, recall, and F1-scores. The best-performing model,
utilising 80% U-Net and 70% CWGAN-GP synthetic data,
reached an accuracy of 99.984%, providing balanced detection
for both benign (Class 0) and malicious (Class 1) SQL queries.
While all top combinations showed promising results, U-Net
data generally improved recall for Class 1, whereas CWGAN-
GP data enhanced precision for Class 0. Ultimately, the 80%
U-Net and 70% CWGAN-GP combination was selected for its
overall balanced performance and deemed optimal for further
testing and validation.
G.

17. Performance Metrics: Class 1
Among the 100 tested configurations, several exhibited a
strong performance across all metrics. The top five combina-
tions, as shown in Figures 16 and 17, achieved high accuracy,
precision, recall, and F1-scores. The best-performing model,
utilising 80% U-Net and 70% CWGAN-GP synthetic data,
reached an accuracy of 99.984%, providing balanced detection
for both benign (Class 0) and malicious (Class 1) SQL queries.
While all top combinations showed promising results, U-Net
data generally improved recall for Class 1, whereas CWGAN-
GP data enhanced precision for Class 0. Ultimately, the 80%
U-Net and 70% CWGAN-GP combination was selected for its
overall balanced performance and deemed optimal for further
testing and validation.
G. Final XGBoost Model Performance
With the optimal hybrid configuration established, the next
step was to evaluate the final performance of the XGBoost
model against the baseline model, ensuring improvements
brought by synthetic data integration were robust and con-
sistent across different datasets.
1) Baseline Model Performance (Validation Results): The
baseline model, trained solely on the original dataset, achieved
an overall accuracy of 0.9817 on the validation set.

Performance Metrics: Class 1
Among the 100 tested configurations, several exhibited a
strong performance across all metrics. The top five combina-
tions, as shown in Figures 16 and 17, achieved high accuracy,
precision, recall, and F1-scores. The best-performing model,
utilising 80% U-Net and 70% CWGAN-GP synthetic data,
reached an accuracy of 99.984%, providing balanced detection
for both benign (Class 0) and malicious (Class 1) SQL queries.
While all top combinations showed promising results, U-Net
data generally improved recall for Class 1, whereas CWGAN-
GP data enhanced precision for Class 0. Ultimately, the 80%
U-Net and 70% CWGAN-GP combination was selected for its
overall balanced performance and deemed optimal for further
testing and validation.
G. Final XGBoost Model Performance
With the optimal hybrid configuration established, the next
step was to evaluate the final performance of the XGBoost
model against the baseline model, ensuring improvements
brought by synthetic data integration were robust and con-
sistent across different datasets.
1) Baseline Model Performance (Validation Results): The
baseline model, trained solely on the original dataset, achieved
an overall accuracy of 0.9817 on the validation set. As shown
in Figure 18, the precision and recall values are well-balanced
across both benign (Class 0) and malicious (Class 1) queries:
Fig.

The top five combina-
tions, as shown in Figures 16 and 17, achieved high accuracy,
precision, recall, and F1-scores. The best-performing model,
utilising 80% U-Net and 70% CWGAN-GP synthetic data,
reached an accuracy of 99.984%, providing balanced detection
for both benign (Class 0) and malicious (Class 1) SQL queries.
While all top combinations showed promising results, U-Net
data generally improved recall for Class 1, whereas CWGAN-
GP data enhanced precision for Class 0. Ultimately, the 80%
U-Net and 70% CWGAN-GP combination was selected for its
overall balanced performance and deemed optimal for further
testing and validation.
G. Final XGBoost Model Performance
With the optimal hybrid configuration established, the next
step was to evaluate the final performance of the XGBoost
model against the baseline model, ensuring improvements
brought by synthetic data integration were robust and con-
sistent across different datasets.
1) Baseline Model Performance (Validation Results): The
baseline model, trained solely on the original dataset, achieved
an overall accuracy of 0.9817 on the validation set. As shown
in Figure 18, the precision and recall values are well-balanced
across both benign (Class 0) and malicious (Class 1) queries:
Fig. 18.

The best-performing model,
utilising 80% U-Net and 70% CWGAN-GP synthetic data,
reached an accuracy of 99.984%, providing balanced detection
for both benign (Class 0) and malicious (Class 1) SQL queries.
While all top combinations showed promising results, U-Net
data generally improved recall for Class 1, whereas CWGAN-
GP data enhanced precision for Class 0. Ultimately, the 80%
U-Net and 70% CWGAN-GP combination was selected for its
overall balanced performance and deemed optimal for further
testing and validation.
G. Final XGBoost Model Performance
With the optimal hybrid configuration established, the next
step was to evaluate the final performance of the XGBoost
model against the baseline model, ensuring improvements
brought by synthetic data integration were robust and con-
sistent across different datasets.
1) Baseline Model Performance (Validation Results): The
baseline model, trained solely on the original dataset, achieved
an overall accuracy of 0.9817 on the validation set. As shown
in Figure 18, the precision and recall values are well-balanced
across both benign (Class 0) and malicious (Class 1) queries:
Fig. 18. Baseline Model Classification Report
The model exhibited slightly higher precision for Class 1
(malicious queries) at 0.99, while Class 0 (benign queries)
showed a higher recall at 0.99.

Ultimately, the 80%
U-Net and 70% CWGAN-GP combination was selected for its
overall balanced performance and deemed optimal for further
testing and validation.
G. Final XGBoost Model Performance
With the optimal hybrid configuration established, the next
step was to evaluate the final performance of the XGBoost
model against the baseline model, ensuring improvements
brought by synthetic data integration were robust and con-
sistent across different datasets.
1) Baseline Model Performance (Validation Results): The
baseline model, trained solely on the original dataset, achieved
an overall accuracy of 0.9817 on the validation set. As shown
in Figure 18, the precision and recall values are well-balanced
across both benign (Class 0) and malicious (Class 1) queries:
Fig. 18. Baseline Model Classification Report
The model exhibited slightly higher precision for Class 1
(malicious queries) at 0.99, while Class 0 (benign queries)
showed a higher recall at 0.99. This indicates that the model
was particularly effective in minimising false positives for
malicious queries but showed a slight reduction in detecting
all benign queries.
Fig.

Final XGBoost Model Performance
With the optimal hybrid configuration established, the next
step was to evaluate the final performance of the XGBoost
model against the baseline model, ensuring improvements
brought by synthetic data integration were robust and con-
sistent across different datasets.
1) Baseline Model Performance (Validation Results): The
baseline model, trained solely on the original dataset, achieved
an overall accuracy of 0.9817 on the validation set. As shown
in Figure 18, the precision and recall values are well-balanced
across both benign (Class 0) and malicious (Class 1) queries:
Fig. 18. Baseline Model Classification Report
The model exhibited slightly higher precision for Class 1
(malicious queries) at 0.99, while Class 0 (benign queries)
showed a higher recall at 0.99. This indicates that the model
was particularly effective in minimising false positives for
malicious queries but showed a slight reduction in detecting
all benign queries.
Fig. 19.

As shown
in Figure 18, the precision and recall values are well-balanced
across both benign (Class 0) and malicious (Class 1) queries:
Fig. 18. Baseline Model Classification Report
The model exhibited slightly higher precision for Class 1
(malicious queries) at 0.99, while Class 0 (benign queries)
showed a higher recall at 0.99. This indicates that the model
was particularly effective in minimising false positives for
malicious queries but showed a slight reduction in detecting
all benign queries.
Fig. 19. Baseline Model Confusion Matrix
To further illustrate the distribution of true positives, false
positives, false negatives, and true negatives for both classes,
the confusion matrix in Figure 19 highlights the classification
performance in terms of correctly and incorrectly classified
instances:
While the overall performance was strong, a minor imbal-
ance in recall for benign queries suggests potential areas for
further improvement in optimising benign query detection.
2) Final Model: The final model was developed by lever-
aging the optimal data proportions of 80% U-Net and 70%
CWGAN-GP synthetic data, as identified during the hybrid
data synthesis process.

18. Baseline Model Classification Report
The model exhibited slightly higher precision for Class 1
(malicious queries) at 0.99, while Class 0 (benign queries)
showed a higher recall at 0.99. This indicates that the model
was particularly effective in minimising false positives for
malicious queries but showed a slight reduction in detecting
all benign queries.
Fig. 19. Baseline Model Confusion Matrix
To further illustrate the distribution of true positives, false
positives, false negatives, and true negatives for both classes,
the confusion matrix in Figure 19 highlights the classification
performance in terms of correctly and incorrectly classified
instances:
While the overall performance was strong, a minor imbal-
ance in recall for benign queries suggests potential areas for
further improvement in optimising benign query detection.
2) Final Model: The final model was developed by lever-
aging the optimal data proportions of 80% U-Net and 70%
CWGAN-GP synthetic data, as identified during the hybrid
data synthesis process. This model was fine-tuned using hy-
perparameter optimisation, enhancing its ability to detect SQL
Injection Attacks (SQLIA) with high accuracy and generali-
sation capability.

Baseline Model Classification Report
The model exhibited slightly higher precision for Class 1
(malicious queries) at 0.99, while Class 0 (benign queries)
showed a higher recall at 0.99. This indicates that the model
was particularly effective in minimising false positives for
malicious queries but showed a slight reduction in detecting
all benign queries.
Fig. 19. Baseline Model Confusion Matrix
To further illustrate the distribution of true positives, false
positives, false negatives, and true negatives for both classes,
the confusion matrix in Figure 19 highlights the classification
performance in terms of correctly and incorrectly classified
instances:
While the overall performance was strong, a minor imbal-
ance in recall for benign queries suggests potential areas for
further improvement in optimising benign query detection.
2) Final Model: The final model was developed by lever-
aging the optimal data proportions of 80% U-Net and 70%
CWGAN-GP synthetic data, as identified during the hybrid
data synthesis process. This model was fine-tuned using hy-
perparameter optimisation, enhancing its ability to detect SQL
Injection Attacks (SQLIA) with high accuracy and generali-
sation capability. The hyperparameters were optimised using
Stratified K-Fold Cross-Validation, resulting in the following
parameters:
•Best Parameters: {subsample : 1.0,nestimators :
500,min child weight : 1,max depth : 3,learning rate:
0.3,gamma : 0,colsample bytree : 0.8}
The final performance of the model on the validation set is
depicted in Figure 20, where it achieved an accuracy of 0.98.
Precision, recall, and F1-scores for both Class 0 and Class 1
were well-balanced, demonstrating the efficiency of the model
in detecting both benign and malicious queries.
Fig.

This indicates that the model
was particularly effective in minimising false positives for
malicious queries but showed a slight reduction in detecting
all benign queries.
Fig. 19. Baseline Model Confusion Matrix
To further illustrate the distribution of true positives, false
positives, false negatives, and true negatives for both classes,
the confusion matrix in Figure 19 highlights the classification
performance in terms of correctly and incorrectly classified
instances:
While the overall performance was strong, a minor imbal-
ance in recall for benign queries suggests potential areas for
further improvement in optimising benign query detection.
2) Final Model: The final model was developed by lever-
aging the optimal data proportions of 80% U-Net and 70%
CWGAN-GP synthetic data, as identified during the hybrid
data synthesis process. This model was fine-tuned using hy-
perparameter optimisation, enhancing its ability to detect SQL
Injection Attacks (SQLIA) with high accuracy and generali-
sation capability. The hyperparameters were optimised using
Stratified K-Fold Cross-Validation, resulting in the following
parameters:
•Best Parameters: {subsample : 1.0,nestimators :
500,min child weight : 1,max depth : 3,learning rate:
0.3,gamma : 0,colsample bytree : 0.8}
The final performance of the model on the validation set is
depicted in Figure 20, where it achieved an accuracy of 0.98.
Precision, recall, and F1-scores for both Class 0 and Class 1
were well-balanced, demonstrating the efficiency of the model
in detecting both benign and malicious queries.
Fig. 20.

19. Baseline Model Confusion Matrix
To further illustrate the distribution of true positives, false
positives, false negatives, and true negatives for both classes,
the confusion matrix in Figure 19 highlights the classification
performance in terms of correctly and incorrectly classified
instances:
While the overall performance was strong, a minor imbal-
ance in recall for benign queries suggests potential areas for
further improvement in optimising benign query detection.
2) Final Model: The final model was developed by lever-
aging the optimal data proportions of 80% U-Net and 70%
CWGAN-GP synthetic data, as identified during the hybrid
data synthesis process. This model was fine-tuned using hy-
perparameter optimisation, enhancing its ability to detect SQL
Injection Attacks (SQLIA) with high accuracy and generali-
sation capability. The hyperparameters were optimised using
Stratified K-Fold Cross-Validation, resulting in the following
parameters:
•Best Parameters: {subsample : 1.0,nestimators :
500,min child weight : 1,max depth : 3,learning rate:
0.3,gamma : 0,colsample bytree : 0.8}
The final performance of the model on the validation set is
depicted in Figure 20, where it achieved an accuracy of 0.98.
Precision, recall, and F1-scores for both Class 0 and Class 1
were well-balanced, demonstrating the efficiency of the model
in detecting both benign and malicious queries.
Fig. 20. Classification Report for Final Model on Validation Data
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 12
Fig.

Baseline Model Confusion Matrix
To further illustrate the distribution of true positives, false
positives, false negatives, and true negatives for both classes,
the confusion matrix in Figure 19 highlights the classification
performance in terms of correctly and incorrectly classified
instances:
While the overall performance was strong, a minor imbal-
ance in recall for benign queries suggests potential areas for
further improvement in optimising benign query detection.
2) Final Model: The final model was developed by lever-
aging the optimal data proportions of 80% U-Net and 70%
CWGAN-GP synthetic data, as identified during the hybrid
data synthesis process. This model was fine-tuned using hy-
perparameter optimisation, enhancing its ability to detect SQL
Injection Attacks (SQLIA) with high accuracy and generali-
sation capability. The hyperparameters were optimised using
Stratified K-Fold Cross-Validation, resulting in the following
parameters:
•Best Parameters: {subsample : 1.0,nestimators :
500,min child weight : 1,max depth : 3,learning rate:
0.3,gamma : 0,colsample bytree : 0.8}
The final performance of the model on the validation set is
depicted in Figure 20, where it achieved an accuracy of 0.98.
Precision, recall, and F1-scores for both Class 0 and Class 1
were well-balanced, demonstrating the efficiency of the model
in detecting both benign and malicious queries.
Fig. 20. Classification Report for Final Model on Validation Data
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 12
Fig. 21.

This model was fine-tuned using hy-
perparameter optimisation, enhancing its ability to detect SQL
Injection Attacks (SQLIA) with high accuracy and generali-
sation capability. The hyperparameters were optimised using
Stratified K-Fold Cross-Validation, resulting in the following
parameters:
•Best Parameters: {subsample : 1.0,nestimators :
500,min child weight : 1,max depth : 3,learning rate:
0.3,gamma : 0,colsample bytree : 0.8}
The final performance of the model on the validation set is
depicted in Figure 20, where it achieved an accuracy of 0.98.
Precision, recall, and F1-scores for both Class 0 and Class 1
were well-balanced, demonstrating the efficiency of the model
in detecting both benign and malicious queries.
Fig. 20. Classification Report for Final Model on Validation Data
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 12
Fig. 21. Confusion Matrix for Final Model
The confusion matrix in Figure 21 highlights the reliable
classification of the model with minimal false positives and
false negatives.

The hyperparameters were optimised using
Stratified K-Fold Cross-Validation, resulting in the following
parameters:
•Best Parameters: {subsample : 1.0,nestimators :
500,min child weight : 1,max depth : 3,learning rate:
0.3,gamma : 0,colsample bytree : 0.8}
The final performance of the model on the validation set is
depicted in Figure 20, where it achieved an accuracy of 0.98.
Precision, recall, and F1-scores for both Class 0 and Class 1
were well-balanced, demonstrating the efficiency of the model
in detecting both benign and malicious queries.
Fig. 20. Classification Report for Final Model on Validation Data
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 12
Fig. 21. Confusion Matrix for Final Model
The confusion matrix in Figure 21 highlights the reliable
classification of the model with minimal false positives and
false negatives. It correctly classified 162 benign queries (Class
0) and 158 malicious queries (Class 1), showcasing the effec-
tiveness of hyperparameter tuning in reducing classification
errors.
a)Comparison with Baseline Model :When compared
to the baseline model, the final model exhibited a substantial
improvement, particularly in the recall for Class 1 (malicious
queries), which is critical for SQLIA detection.

20. Classification Report for Final Model on Validation Data
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 12
Fig. 21. Confusion Matrix for Final Model
The confusion matrix in Figure 21 highlights the reliable
classification of the model with minimal false positives and
false negatives. It correctly classified 162 benign queries (Class
0) and 158 malicious queries (Class 1), showcasing the effec-
tiveness of hyperparameter tuning in reducing classification
errors.
a)Comparison with Baseline Model :When compared
to the baseline model, the final model exhibited a substantial
improvement, particularly in the recall for Class 1 (malicious
queries), which is critical for SQLIA detection. The baseline
model, trained solely on real data, had a lower recall for
Class 1, leading to more false negatives.

Classification Report for Final Model on Validation Data
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 12
Fig. 21. Confusion Matrix for Final Model
The confusion matrix in Figure 21 highlights the reliable
classification of the model with minimal false positives and
false negatives. It correctly classified 162 benign queries (Class
0) and 158 malicious queries (Class 1), showcasing the effec-
tiveness of hyperparameter tuning in reducing classification
errors.
a)Comparison with Baseline Model :When compared
to the baseline model, the final model exhibited a substantial
improvement, particularly in the recall for Class 1 (malicious
queries), which is critical for SQLIA detection. The baseline
model, trained solely on real data, had a lower recall for
Class 1, leading to more false negatives. By incorporating
synthetic data and applying hyperparameter tuning, the final
model significantly reduced these errors, providing better de-
tection of malicious SQL queries while maintaining balanced
performance for benign queries (Class 0).
b)Cross-Validation Performance :Cross-validation re-
sults demonstrated the robustness of the final model, as
depicted in the box plot (Figure 22).

21. Confusion Matrix for Final Model
The confusion matrix in Figure 21 highlights the reliable
classification of the model with minimal false positives and
false negatives. It correctly classified 162 benign queries (Class
0) and 158 malicious queries (Class 1), showcasing the effec-
tiveness of hyperparameter tuning in reducing classification
errors.
a)Comparison with Baseline Model :When compared
to the baseline model, the final model exhibited a substantial
improvement, particularly in the recall for Class 1 (malicious
queries), which is critical for SQLIA detection. The baseline
model, trained solely on real data, had a lower recall for
Class 1, leading to more false negatives. By incorporating
synthetic data and applying hyperparameter tuning, the final
model significantly reduced these errors, providing better de-
tection of malicious SQL queries while maintaining balanced
performance for benign queries (Class 0).
b)Cross-Validation Performance :Cross-validation re-
sults demonstrated the robustness of the final model, as
depicted in the box plot (Figure 22). Minimal variance was
observed across accuracy, precision, recall, F1-score, and
sensitivity metrics, further reinforcing the reliability of the
model for SQL Injection detection in real-world scenarios.
Fig.

Confusion Matrix for Final Model
The confusion matrix in Figure 21 highlights the reliable
classification of the model with minimal false positives and
false negatives. It correctly classified 162 benign queries (Class
0) and 158 malicious queries (Class 1), showcasing the effec-
tiveness of hyperparameter tuning in reducing classification
errors.
a)Comparison with Baseline Model :When compared
to the baseline model, the final model exhibited a substantial
improvement, particularly in the recall for Class 1 (malicious
queries), which is critical for SQLIA detection. The baseline
model, trained solely on real data, had a lower recall for
Class 1, leading to more false negatives. By incorporating
synthetic data and applying hyperparameter tuning, the final
model significantly reduced these errors, providing better de-
tection of malicious SQL queries while maintaining balanced
performance for benign queries (Class 0).
b)Cross-Validation Performance :Cross-validation re-
sults demonstrated the robustness of the final model, as
depicted in the box plot (Figure 22). Minimal variance was
observed across accuracy, precision, recall, F1-score, and
sensitivity metrics, further reinforcing the reliability of the
model for SQL Injection detection in real-world scenarios.
Fig. 22.

It correctly classified 162 benign queries (Class
0) and 158 malicious queries (Class 1), showcasing the effec-
tiveness of hyperparameter tuning in reducing classification
errors.
a)Comparison with Baseline Model :When compared
to the baseline model, the final model exhibited a substantial
improvement, particularly in the recall for Class 1 (malicious
queries), which is critical for SQLIA detection. The baseline
model, trained solely on real data, had a lower recall for
Class 1, leading to more false negatives. By incorporating
synthetic data and applying hyperparameter tuning, the final
model significantly reduced these errors, providing better de-
tection of malicious SQL queries while maintaining balanced
performance for benign queries (Class 0).
b)Cross-Validation Performance :Cross-validation re-
sults demonstrated the robustness of the final model, as
depicted in the box plot (Figure 22). Minimal variance was
observed across accuracy, precision, recall, F1-score, and
sensitivity metrics, further reinforcing the reliability of the
model for SQL Injection detection in real-world scenarios.
Fig. 22. Cross-Validation Box Plot for Final Model Performance Metrics
V.CONCLUSION
Overall, the final XGBoost model outperformed the baseline
model, particularly in terms of recall and sensitivity formalicious queries.

The baseline
model, trained solely on real data, had a lower recall for
Class 1, leading to more false negatives. By incorporating
synthetic data and applying hyperparameter tuning, the final
model significantly reduced these errors, providing better de-
tection of malicious SQL queries while maintaining balanced
performance for benign queries (Class 0).
b)Cross-Validation Performance :Cross-validation re-
sults demonstrated the robustness of the final model, as
depicted in the box plot (Figure 22). Minimal variance was
observed across accuracy, precision, recall, F1-score, and
sensitivity metrics, further reinforcing the reliability of the
model for SQL Injection detection in real-world scenarios.
Fig. 22. Cross-Validation Box Plot for Final Model Performance Metrics
V.CONCLUSION
Overall, the final XGBoost model outperformed the baseline
model, particularly in terms of recall and sensitivity formalicious queries. The integration of synthetic data, gener-
ated through U-Net and CWGAN-GP models, significantly
enhanced the generalisation ability of the model.

By incorporating
synthetic data and applying hyperparameter tuning, the final
model significantly reduced these errors, providing better de-
tection of malicious SQL queries while maintaining balanced
performance for benign queries (Class 0).
b)Cross-Validation Performance :Cross-validation re-
sults demonstrated the robustness of the final model, as
depicted in the box plot (Figure 22). Minimal variance was
observed across accuracy, precision, recall, F1-score, and
sensitivity metrics, further reinforcing the reliability of the
model for SQL Injection detection in real-world scenarios.
Fig. 22. Cross-Validation Box Plot for Final Model Performance Metrics
V.CONCLUSION
Overall, the final XGBoost model outperformed the baseline
model, particularly in terms of recall and sensitivity formalicious queries. The integration of synthetic data, gener-
ated through U-Net and CWGAN-GP models, significantly
enhanced the generalisation ability of the model. Hyperparam-
eter tuning further optimised the performance of the model,
resulting in a highly accurate and reliable solution for detect-
ing SQLIA in real-world scenarios.

Minimal variance was
observed across accuracy, precision, recall, F1-score, and
sensitivity metrics, further reinforcing the reliability of the
model for SQL Injection detection in real-world scenarios.
Fig. 22. Cross-Validation Box Plot for Final Model Performance Metrics
V.CONCLUSION
Overall, the final XGBoost model outperformed the baseline
model, particularly in terms of recall and sensitivity formalicious queries. The integration of synthetic data, gener-
ated through U-Net and CWGAN-GP models, significantly
enhanced the generalisation ability of the model. Hyperparam-
eter tuning further optimised the performance of the model,
resulting in a highly accurate and reliable solution for detect-
ing SQLIA in real-world scenarios. This study successfully
demonstrated that combining synthetic data with real data
and using advanced machine learning techniques can provide
an effective and robust solution for modern cybersecurity
challenges.
VI.

22. Cross-Validation Box Plot for Final Model Performance Metrics
V.CONCLUSION
Overall, the final XGBoost model outperformed the baseline
model, particularly in terms of recall and sensitivity formalicious queries. The integration of synthetic data, gener-
ated through U-Net and CWGAN-GP models, significantly
enhanced the generalisation ability of the model. Hyperparam-
eter tuning further optimised the performance of the model,
resulting in a highly accurate and reliable solution for detect-
ing SQLIA in real-world scenarios. This study successfully
demonstrated that combining synthetic data with real data
and using advanced machine learning techniques can provide
an effective and robust solution for modern cybersecurity
challenges.
VI. LIMITATIONS AND FUTURE SCOPE
While the final model demonstrated significant improve-
ments, several limitations were identified.

Cross-Validation Box Plot for Final Model Performance Metrics
V.CONCLUSION
Overall, the final XGBoost model outperformed the baseline
model, particularly in terms of recall and sensitivity formalicious queries. The integration of synthetic data, gener-
ated through U-Net and CWGAN-GP models, significantly
enhanced the generalisation ability of the model. Hyperparam-
eter tuning further optimised the performance of the model,
resulting in a highly accurate and reliable solution for detect-
ing SQLIA in real-world scenarios. This study successfully
demonstrated that combining synthetic data with real data
and using advanced machine learning techniques can provide
an effective and robust solution for modern cybersecurity
challenges.
VI. LIMITATIONS AND FUTURE SCOPE
While the final model demonstrated significant improve-
ments, several limitations were identified. The CWGAN-GP
model, although effective, struggled to capture the complete
diversity of SQL query patterns, leading to underrepresen-
tation of complex or rare SQL Injection Attack (SQLIA)
types.

The integration of synthetic data, gener-
ated through U-Net and CWGAN-GP models, significantly
enhanced the generalisation ability of the model. Hyperparam-
eter tuning further optimised the performance of the model,
resulting in a highly accurate and reliable solution for detect-
ing SQLIA in real-world scenarios. This study successfully
demonstrated that combining synthetic data with real data
and using advanced machine learning techniques can provide
an effective and robust solution for modern cybersecurity
challenges.
VI. LIMITATIONS AND FUTURE SCOPE
While the final model demonstrated significant improve-
ments, several limitations were identified. The CWGAN-GP
model, although effective, struggled to capture the complete
diversity of SQL query patterns, leading to underrepresen-
tation of complex or rare SQL Injection Attack (SQLIA)
types. Furthermore, the computational cost associated with
generating synthetic data was high, making real-time deploy-
ment challenging, particularly in resource-constrained environ-
ments.

Hyperparam-
eter tuning further optimised the performance of the model,
resulting in a highly accurate and reliable solution for detect-
ing SQLIA in real-world scenarios. This study successfully
demonstrated that combining synthetic data with real data
and using advanced machine learning techniques can provide
an effective and robust solution for modern cybersecurity
challenges.
VI. LIMITATIONS AND FUTURE SCOPE
While the final model demonstrated significant improve-
ments, several limitations were identified. The CWGAN-GP
model, although effective, struggled to capture the complete
diversity of SQL query patterns, leading to underrepresen-
tation of complex or rare SQL Injection Attack (SQLIA)
types. Furthermore, the computational cost associated with
generating synthetic data was high, making real-time deploy-
ment challenging, particularly in resource-constrained environ-
ments. Another limitation was the challenge of maintaining a
balanced ratio of benign and malicious queries in the synthetic
dataset, which was critical to avoid model overfitting.
Future work could focus on refining the CWGAN-GP model
to better capture diverse SQL patterns and improve scalability.
Exploring other GAN variants (e.g., CatGAN, SentiGAN) and
hybrid models with Variational Autoencoders (V AEs) could
further enhance the quality of synthetic data.

This study successfully
demonstrated that combining synthetic data with real data
and using advanced machine learning techniques can provide
an effective and robust solution for modern cybersecurity
challenges.
VI. LIMITATIONS AND FUTURE SCOPE
While the final model demonstrated significant improve-
ments, several limitations were identified. The CWGAN-GP
model, although effective, struggled to capture the complete
diversity of SQL query patterns, leading to underrepresen-
tation of complex or rare SQL Injection Attack (SQLIA)
types. Furthermore, the computational cost associated with
generating synthetic data was high, making real-time deploy-
ment challenging, particularly in resource-constrained environ-
ments. Another limitation was the challenge of maintaining a
balanced ratio of benign and malicious queries in the synthetic
dataset, which was critical to avoid model overfitting.
Future work could focus on refining the CWGAN-GP model
to better capture diverse SQL patterns and improve scalability.
Exploring other GAN variants (e.g., CatGAN, SentiGAN) and
hybrid models with Variational Autoencoders (V AEs) could
further enhance the quality of synthetic data. Additionally,
real-time detection through online learning and optimising
computational efficiency using distributed systems would en-
able broader applications of this approach.

LIMITATIONS AND FUTURE SCOPE
While the final model demonstrated significant improve-
ments, several limitations were identified. The CWGAN-GP
model, although effective, struggled to capture the complete
diversity of SQL query patterns, leading to underrepresen-
tation of complex or rare SQL Injection Attack (SQLIA)
types. Furthermore, the computational cost associated with
generating synthetic data was high, making real-time deploy-
ment challenging, particularly in resource-constrained environ-
ments. Another limitation was the challenge of maintaining a
balanced ratio of benign and malicious queries in the synthetic
dataset, which was critical to avoid model overfitting.
Future work could focus on refining the CWGAN-GP model
to better capture diverse SQL patterns and improve scalability.
Exploring other GAN variants (e.g., CatGAN, SentiGAN) and
hybrid models with Variational Autoencoders (V AEs) could
further enhance the quality of synthetic data. Additionally,
real-time detection through online learning and optimising
computational efficiency using distributed systems would en-
able broader applications of this approach. Developing a self-
learning detection system that autonomously adapts to new
SQLIA types would also improve the resilience of the model
to emerging threats.
REFERENCES
[1] OWASP, “Owasp top ten,” 2021, accessed: 2024-09-29.

The CWGAN-GP
model, although effective, struggled to capture the complete
diversity of SQL query patterns, leading to underrepresen-
tation of complex or rare SQL Injection Attack (SQLIA)
types. Furthermore, the computational cost associated with
generating synthetic data was high, making real-time deploy-
ment challenging, particularly in resource-constrained environ-
ments. Another limitation was the challenge of maintaining a
balanced ratio of benign and malicious queries in the synthetic
dataset, which was critical to avoid model overfitting.
Future work could focus on refining the CWGAN-GP model
to better capture diverse SQL patterns and improve scalability.
Exploring other GAN variants (e.g., CatGAN, SentiGAN) and
hybrid models with Variational Autoencoders (V AEs) could
further enhance the quality of synthetic data. Additionally,
real-time detection through online learning and optimising
computational efficiency using distributed systems would en-
able broader applications of this approach. Developing a self-
learning detection system that autonomously adapts to new
SQLIA types would also improve the resilience of the model
to emerging threats.
REFERENCES
[1] OWASP, “Owasp top ten,” 2021, accessed: 2024-09-29. [Online].
Available: https://owasp.org/www-project-top-ten/
[2] C.

Furthermore, the computational cost associated with
generating synthetic data was high, making real-time deploy-
ment challenging, particularly in resource-constrained environ-
ments. Another limitation was the challenge of maintaining a
balanced ratio of benign and malicious queries in the synthetic
dataset, which was critical to avoid model overfitting.
Future work could focus on refining the CWGAN-GP model
to better capture diverse SQL patterns and improve scalability.
Exploring other GAN variants (e.g., CatGAN, SentiGAN) and
hybrid models with Variational Autoencoders (V AEs) could
further enhance the quality of synthetic data. Additionally,
real-time detection through online learning and optimising
computational efficiency using distributed systems would en-
able broader applications of this approach. Developing a self-
learning detection system that autonomously adapts to new
SQLIA types would also improve the resilience of the model
to emerging threats.
REFERENCES
[1] OWASP, “Owasp top ten,” 2021, accessed: 2024-09-29. [Online].
Available: https://owasp.org/www-project-top-ten/
[2] C. Anley, “Advanced sql injection in sql server applications,” Advanced
SQL injection in SQL server applications , 2002.
[3] A.

Another limitation was the challenge of maintaining a
balanced ratio of benign and malicious queries in the synthetic
dataset, which was critical to avoid model overfitting.
Future work could focus on refining the CWGAN-GP model
to better capture diverse SQL patterns and improve scalability.
Exploring other GAN variants (e.g., CatGAN, SentiGAN) and
hybrid models with Variational Autoencoders (V AEs) could
further enhance the quality of synthetic data. Additionally,
real-time detection through online learning and optimising
computational efficiency using distributed systems would en-
able broader applications of this approach. Developing a self-
learning detection system that autonomously adapts to new
SQLIA types would also improve the resilience of the model
to emerging threats.
REFERENCES
[1] OWASP, “Owasp top ten,” 2021, accessed: 2024-09-29. [Online].
Available: https://owasp.org/www-project-top-ten/
[2] C. Anley, “Advanced sql injection in sql server applications,” Advanced
SQL injection in SQL server applications , 2002.
[3] A. Sadeghian, M.

Additionally,
real-time detection through online learning and optimising
computational efficiency using distributed systems would en-
able broader applications of this approach. Developing a self-
learning detection system that autonomously adapts to new
SQLIA types would also improve the resilience of the model
to emerging threats.
REFERENCES
[1] OWASP, “Owasp top ten,” 2021, accessed: 2024-09-29. [Online].
Available: https://owasp.org/www-project-top-ten/
[2] C. Anley, “Advanced sql injection in sql server applications,” Advanced
SQL injection in SQL server applications , 2002.
[3] A. Sadeghian, M. Zamani, and S.

Developing a self-
learning detection system that autonomously adapts to new
SQLIA types would also improve the resilience of the model
to emerging threats.
REFERENCES
[1] OWASP, “Owasp top ten,” 2021, accessed: 2024-09-29. [Online].
Available: https://owasp.org/www-project-top-ten/
[2] C. Anley, “Advanced sql injection in sql server applications,” Advanced
SQL injection in SQL server applications , 2002.
[3] A. Sadeghian, M. Zamani, and S. Ibrahim, “Sql injection is still alive:
a study on sql injection signature evasion techniques,” in 2013 Inter-
national Conference on Informatics and Creative Multimedia.

[Online].
Available: https://owasp.org/www-project-top-ten/
[2] C. Anley, “Advanced sql injection in sql server applications,” Advanced
SQL injection in SQL server applications , 2002.
[3] A. Sadeghian, M. Zamani, and S. Ibrahim, “Sql injection is still alive:
a study on sql injection signature evasion techniques,” in 2013 Inter-
national Conference on Informatics and Creative Multimedia. IEEE,
2013, pp. 265–268.
[4] W. G. Halfond, J. Viegas, A. Orso et al.

265–268.
[4] W. G. Halfond, J. Viegas, A. Orso et al. , “A classification of sql injection
attacks and countermeasures.” in ISSSE , 2006.
[5] A. Joshi and V. Geetha, “Sql injection detection using machine learning,”
in2014 international conference on control, instrumentation, communi-
cation and computational technologies (ICCICCT). IEEE, 2014, pp.
1111–1115.
[6] S. O. Uwagbole, W. J. Buchanan, and L.

IEEE, 2014, pp.
1111–1115.
[6] S. O. Uwagbole, W. J. Buchanan, and L. Fan, “Applied machine learning
predictive analytics to sql injection attack detection and prevention,”
in2017 IFIP/IEEE Symposium on Integrated Network and Service
Management (IM). IEEE, 2017, pp. 1087–1090.
[7] U. Farooq, “Ensemble machine learning approaches for detection of sql
injection attack,” Tehni ˇcki glasnik , vol. 15, no. 1, pp. 112–120, 2021.
[8] M. Kiani, A. Clark, and G.

15, no. 1, pp. 112–120, 2021.
[8] M. Kiani, A. Clark, and G. Mohay, “Evaluation of anomaly based
character distribution models in the detection of sql injection attacks,”
in2008 Third International Conference on Availability, Reliability and
Security. IEEE, 2008, pp. 47–55.
[9] L. K. Shar, H. B. K. Tan, and L. C. Briand, “Mining sql injection and
cross site scripting vulnerabilities using hybrid program analysis,” in
2013 35th International Conference on Software Engineering (ICSE) .
IEEE, 2013, pp.

B. K. Tan, and L. C. Briand, “Mining sql injection and
cross site scripting vulnerabilities using hybrid program analysis,” in
2013 35th International Conference on Software Engineering (ICSE) .
IEEE, 2013, pp. 642–651.
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 13
[10] A. Ciampa, C. A. Visaggio, and M. Di Penta, “A heuristic-based
approach for detecting sql-injection vulnerabilities in web applications,”
inProceedings of the 2010 ICSE Workshop on Software Engineering
for Secure Systems , 2010, pp.

642–651.
JOURNAL OF CYBERSECURITY AND DATA SCIENCE, JANUARY 2025 13
[10] A. Ciampa, C. A. Visaggio, and M. Di Penta, “A heuristic-based
approach for detecting sql-injection vulnerabilities in web applications,”
inProceedings of the 2010 ICSE Workshop on Software Engineering
for Secure Systems , 2010, pp. 43–49.
[11] M. Hasan, Z. Balbahaith, and M.

Visaggio, and M. Di Penta, “A heuristic-based
approach for detecting sql-injection vulnerabilities in web applications,”
inProceedings of the 2010 ICSE Workshop on Software Engineering
for Secure Systems , 2010, pp. 43–49.
[11] M. Hasan, Z. Balbahaith, and M. Tarique, “Detection of sql injection
attacks: a machine learning approach,” in 2019 International Conference
on Electrical and Computing Technologies and Applications (ICECTA) .
IEEE, 2019, pp. 1–6.
[12] D. Chen, Q. Yan, C. Wu, and J.

Tarique, “Detection of sql injection
attacks: a machine learning approach,” in 2019 International Conference
on Electrical and Computing Technologies and Applications (ICECTA) .
IEEE, 2019, pp. 1–6.
[12] D. Chen, Q. Yan, C. Wu, and J. Zhao, “Sql injection attack detection
and prevention techniques using deep learning,” in Journal of Physics:
Conference Series , vol. 1757, no. 1. IOP Publishing, 2021, p. 012055.
[13] P. Skondras, P. Zervas, and G.

1. IOP Publishing, 2021, p. 012055.
[13] P. Skondras, P. Zervas, and G. Tzimas, “Generating synthetic resume
data with large language models for enhanced job description classifi-
cation,” Future Internet , vol. 15, no. 11, p. 363, 2023.
[14] A. A. Awan, “A complete guide to data augmentation,”
Nov. 2022. [Online]. Available: https://www.datacamp.com/tutorial/
complete-guide-data-augmentation
[15] C. Shorten, T. M. Khoshgoftaar, and B. Furht, “Text data augmentation
for deep learning,” Journal of big Data , vol. 8, no. 1, p.

M. Khoshgoftaar, and B. Furht, “Text data augmentation
for deep learning,” Journal of big Data , vol. 8, no. 1, p. 101, 2021.
[16] J. Lovelace, S. Ray, K. Kim, K. Q. Weinberger, and F. Wu,
“Sample-efficient diffusion for text-to-speech synthesis,” arXiv preprint
arXiv:2409.03717 , 2024.
[17] V. Labs, “What is synthetic data in machine learning and how to
generate it,” 2022. [Online]. Available: https://www.v7labs.com/blog/
synthetic-data-guide
[18] D. Stoller, M. Tian, S. Ewert, and S.

[Online]. Available: https://www.v7labs.com/blog/
synthetic-data-guide
[18] D. Stoller, M. Tian, S. Ewert, and S. Dixon, “Seq-u-net: A one-
dimensional causal u-net for efficient sequence modelling,” arXiv
preprint arXiv:1911.06393 , 2019.
[19] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer, “Smote:
synthetic minority over-sampling technique,” Journal of artificial intel-
ligence research , vol. 16, pp. 321–357, 2002.
[20] ResidentMario, “Oversampling with smote and adasyn,”
2022. [Online].

P. Kegelmeyer, “Smote:
synthetic minority over-sampling technique,” Journal of artificial intel-
ligence research , vol. 16, pp. 321–357, 2002.
[20] ResidentMario, “Oversampling with smote and adasyn,”
2022. [Online]. Available: https://www.kaggle.com/code/residentmario/
oversampling-with-smote-and-adasyn
[21] J. Brandt and E. Lanz ´en, “A comparative review of smote and adasyn
in imbalanced data classification,” Comparative review of SMOTE and
ADASYN , 2021.
[22] M. Zeng, B. Zou, F. Wei, X. Liu, and L.

Lanz ´en, “A comparative review of smote and adasyn
in imbalanced data classification,” Comparative review of SMOTE and
ADASYN , 2021.
[22] M. Zeng, B. Zou, F. Wei, X. Liu, and L. Wang, “Effective prediction of
three common diseases by combining smote with tomek links technique
for imbalanced medical data,” in 2016 IEEE International Conference
of Online Analysis and Computing Science (ICOACS). IEEE, 2016, pp.
225–228.
[23] W. Zhang, Y. Li, X. Li, M. Shao, Y. Mi, H. Zhang, and G.

Li, X. Li, M. Shao, Y. Mi, H. Zhang, and G. Zhi,
“Deep neural network-based sql injection detection method,” Security
and Communication Networks , vol. 2022, no. 1, p. 4836289, 2022.
[24] G. San Martin, E. L ´opez Droguett, V. Meruane, and M. das Cha-
gas Moura, “Deep variational auto-encoders: A promising tool for
dimensionality reduction and ball bearing elements fault diagnosis,”
Structural Health Monitoring , vol. 18, no. 4, pp. 1092–1128, 2019.
[25] O. Ronneberger, P. Fischer, and T.

18, no. 4, pp. 1092–1128, 2019.
[25] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks
for biomedical image segmentation,” in Medical image computing and
computer-assisted intervention–MICCAI 2015: 18th international con-
ference, Munich, Germany, October 5-9, 2015, proceedings, part III 18 .
Springer, 2015, pp. 234–241.
[26] M. Zheng, T. Li, R. Zhu, Y. Tang, M. Tang, L. Lin, and Z.

Li, R. Zhu, Y. Tang, M. Tang, L. Lin, and Z. Ma, “Condi-
tional wasserstein generative adversarial network-gradient penalty-based
approach to alleviating imbalanced data classification,” Information
Sciences , vol. 512, pp. 1009–1023, 2020.
[27] J. Xu, X. Ren, J. Lin, and X. Sun, “Diversity-promoting gan: A
cross-entropy based generative adversarial network for diversified text
generation,” in Proceedings of the 2018 conference on empirical methods
in natural language processing , 2018, pp. 3940–3949.
[28] A. S. Imran, R.

Lin, and X. Sun, “Diversity-promoting gan: A
cross-entropy based generative adversarial network for diversified text
generation,” in Proceedings of the 2018 conference on empirical methods
in natural language processing , 2018, pp. 3940–3949.
[28] A. S. Imran, R. Yang, Z. Kastrati, S. M. Daudpota, and S. Shaikh,
“The impact of synthetic text generation for sentiment analysis using
gan based models,” Egyptian Informatics Journal , vol. 23, no. 3, pp.
547–557, 2022.
[29] R.

M. Daudpota, and S. Shaikh,
“The impact of synthetic text generation for sentiment analysis using
gan based models,” Egyptian Informatics Journal , vol. 23, no. 3, pp.
547–557, 2022.
[29] R. Atienza, Advanced Deep Learning with Keras: Apply deep learning
techniques, autoencoders, GANs, variational autoencoders, deep rein-
forcement learning, policy gradients, and more. Packt Publishing Ltd,
2018.
[30] J. Goldstein, M. Kantrowitz, V. Mittal, and J.

Atienza, Advanced Deep Learning with Keras: Apply deep learning
techniques, autoencoders, GANs, variational autoencoders, deep rein-
forcement learning, policy gradients, and more. Packt Publishing Ltd,
2018.
[30] J. Goldstein, M. Kantrowitz, V. Mittal, and J. Carbonell, “Summarizing
text documents: Sentence selection and evaluation metrics,” in Pro-
ceedings of the 22nd annual international ACM SIGIR conference on
Research and development in information retrieval , 1999, pp. 121–128..

